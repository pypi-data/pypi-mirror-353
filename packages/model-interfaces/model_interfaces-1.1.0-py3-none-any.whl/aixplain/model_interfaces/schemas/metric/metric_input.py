__author__ = "aiXplain"

from aixplain.model_interfaces.utils.data_utils import download_data
from http import HTTPStatus
from typing import Optional, Any
from pydantic import BaseModel, validator
from typing import Dict, List, Optional, Union

import aixplain.model_interfaces.utils.metric_utils as utils
import json
import os
import tornado.web
import validators


class MetricInput(BaseModel):
    """The standardized schema of the aiXplain's Metric Scoring API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :type language:
        str
    """

    hypotheses: Any
    supplier: str
    metric: str
    version: Optional[str] = ""
    language: Optional[str] = ""

class MetricAggregate(BaseModel):
    """The standardized schema of the aiXplain's Metric Aggregation API input and output.

    :param data:
        Processed output data from the aggregation of supplier metric scores.
        Aggregation function should update data while combining MetricAggregations. Optional
    :type data:
        Any
    :param aggregation_metadata:
        Metadata generated by the scoring method to be used for aggregation.
        Each metadata item can be represented as a key-value pair in this dict with a string-based key.
        Aggregation function should update aggregation_metadata while combining MetricAggregations.
    :type aggregation_metadata:
        Dict[str, Any]
    :param hypotheses_count:
        Count of hypotheses to be aggregated.
        Aggregation function should update hypotheses_count while combining MetricAggregations.
    :type hypotheses_count:
        int
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    """
    data: Optional[Any] = {}
    aggregation_metadata: List[Dict[str, Any]] = {}
    supplier: str
    metric: str
    version: Optional[str] = ""


class TextGenerationSettings(BaseModel):
    """The standardized schema of the aiXplain's Metric API settings.
    """
    pass


class AudioGenerationSettings(BaseModel):
    """The standardized schema of the aiXplain's  Audio Generation Metric API settings."""  # TODO: add settings if there is any needed
    pass


class TextGenerationMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's Text Generation Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param references:
        Input references to the model.
    :type references:
        Any
    :param sources:
        Input sources to the model. Optional
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :param options:
        settings
    :type options:
        TextGenerationSettings
    """

    references: Any
    sources: Optional[Any] = None
    options: Optional[TextGenerationSettings] = None

    @validator("sources")
    def check_sources(cls, v):
        if v is not None:
            try:
                if isinstance(v, list) is True:
                    sources = v
                elif validators.url(v) is True:
                    path = download_data(v)
                    with open(path) as f:
                        sources = json.load(f)
                    os.remove(path)
                else:
                    path = v
                    with open(path) as f:
                        sources = json.load(f)
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid source link. Error: {e}")

            try:
                assert len(sources) > 0
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
            return sources
        else:
            return None

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, list) is True:
                hypotheses = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    hypotheses = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    hypotheses = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        return hypotheses

    @validator("references")
    def check_references(cls, v):
        try:
            if isinstance(v, list) is True:
                references = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    references = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    references = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid references link. Error: {e}")

        try:
            assert len(references) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of references must not be empty. Error: {e}")

        # the reference must be a list of lists to accept multiple valid references
        if not any(isinstance(ref, list) for ref in references):
            for i, ref in enumerate(references):
                references[i] = [ref]

        # Make sure at least one reference is provided for each hypotheses
        try:
            assert min([len(ref) for ref in references]) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"At least one reference should be provided. Error: {e}")

        nreferences = max([len(ref) for ref in references])
        for i, ref in enumerate(references):
            references[i] = ref + ([""] * (nreferences - len(ref)))
        return references


class TextGenerationMetricInput(TextGenerationMetricInputSchema):
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except ValueError:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="Incorrect types passed into TextGenerationMetricInput.")

    def parse(self):
        # Make sure the number of sentences is the same in the hypotheses and the reference lists
        try:
            if self.sources is not None:
                assert len(self.hypotheses) == len(self.references) == len(self.sources)
            else:
                assert len(self.hypotheses) == len(self.references)
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources, hypotheses and references must be the same.")

        if self.options is None:
            self.options = TextGenerationSettings()



class ReferencelessTextGenerationMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's Referenceless Text Generation Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param sources:
        Input sources to the model.
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :param options:
        settings
    :type options:
        TextGenerationSettings
    """

    sources: Any
    options: Optional[TextGenerationSettings] = None

    @validator("sources")
    def check_sources(cls, v):
        try:
            if isinstance(v, list) is True:
                sources = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    sources = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    sources = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid source link. Error: {e}")

        try:
            assert len(sources) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
        return sources

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, list) is True:
                hypotheses = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    hypotheses = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    hypotheses = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        return hypotheses


class ReferencelessTextGenerationMetricInput(ReferencelessTextGenerationMetricInputSchema):  # BUG: This should be ReferencelessTextGenerationMetricInputSchema
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except ValueError:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="Incorrect types passed into ReferencelessTextGenerationMetricInput.")

    def parse(self):
        # Make sure the number of sentences is the same in the hypotheses and the sources lists
        try:
            assert len(self.hypotheses) == len(self.sources)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources and hypotheses must be the same. Error: {e}")

        if self.options is None:
            self.options = TextGenerationSettings()


class AudioGenerationMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's Audio Generation Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param references:
        Input references to the model.
    :type references:
        Any
    :param sources:
        Input sources to the model. Optional
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :param options:
        settings
    :type options:
        AudioGenerationSettings
    """

    references: List[str]
    sources: Optional[Any] = None
    options: Optional[AudioGenerationSettings] = None

    @validator("sources")
    def check_sources(cls, v):
        try:
            if isinstance(v, list) is True:
                sources = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    sources = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    sources = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid source link. Error: {e}")

        try:
            assert len(sources) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
        return sources

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, list) is True:
                hypotheses = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    hypotheses = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    hypotheses = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        return hypotheses

    @validator("references")
    def check_references(cls, v):
        try:
            if isinstance(v, list) is True:
                references = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    references = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    references = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid references link. Error: {e}")

        try:
            assert len(references) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of references must not be empty. Error: {e}")

        # the reference must be a list of lists to accept multiple valid references
        if not any(isinstance(ref, list) for ref in references):
            for i, ref in enumerate(references):
                references[i] = [ref]

        # Make sure at least one reference is provided for each hypotheses
        try:
            assert min([len(ref) for ref in references]) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"At least one reference should be provided. Error: {e}")

        nreferences = max([len(ref) for ref in references])
        for i, ref in enumerate(references):
            references[i] = ref + ([""] * (nreferences - len(ref)))
        return references

    @validator("options")
    def check_options(cls, v):
        if v is None:
            return AudioGenerationSettings()
        else:
            return v


class AudioGenerationMetricInput(AudioGenerationMetricInputSchema):
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Incorrect types passed into AudioGenerationMetricInput. Error: {e}")

    def parse(self):
        # Make sure the number of sentences is the same in the hypotheses and the reference lists
        try:
            if self.sources is not None:
                assert len(self.hypotheses) == len(self.references) == len(self.sources)
            else:
                assert len(self.hypotheses) == len(self.references)
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources, hypotheses and references must be the same.")


class ReferencelessAudioGenerationMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's Referenceless Text Generation Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param sources:
        Input sources to the model. Optional
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :param options:
        The options for the metric. Optional.
    :type options:
        AudioGenerationSettings
    """

    sources: Optional[Any] = None

    @validator("sources")
    def check_sources(cls, v):
        try:
            if isinstance(v, list) is True:
                sources = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    sources = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    sources = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid source link. Error: {e}")

        try:
            assert len(sources) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
        return sources

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, list) is True:
                hypotheses = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    hypotheses = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    hypotheses = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        return hypotheses


class ReferencelessAudioGenerationMetricInput(ReferencelessAudioGenerationMetricInputSchema):
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except ValueError:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Incorrect types passed into ReferencelessAudioGenerationMetricInput")

    def parse(self):
        # Make sure the number of sentences is the same in the hypotheses and the reference lists
        try:
            if self.sources is not None:
                assert len(self.hypotheses) == len(self.sources)
            else:
                assert len(self.hypotheses) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources and hypotheses must be the same. Error: {e}")


class ClassificationMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's Classification Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param references:
        Input references to the model.
    :type references:
        Any
    :param sources:
        Input sources to the model. Optional
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    """

    references: Any
    sources: Optional[Any] = None

    @validator("sources")
    def check_sources(cls, v):
        if v is not None:
            try:
                if isinstance(v, list) is True:
                    sources = v
                elif validators.url(v) is True:
                    path = download_data(v)
                    with open(path) as f:
                        sources = json.load(f)
                    os.remove(path)
                else:
                    path = v
                    with open(path) as f:
                        sources = json.load(f)
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid source link. Error: {e}")

            try:
                assert len(sources) > 0
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
            return sources
        else:
            return None

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, list) is True:
                hypotheses = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    hypotheses = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    hypotheses = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        # standardize to string labels
        hypotheses = [str(y) for y in hypotheses]
        return hypotheses

    @validator("references")
    def check_references(cls, v):
        try:
            if isinstance(v, list) is True:
                references = v
            elif validators.url(v) is True:
                path = download_data(v)
                with open(path) as f:
                    references = json.load(f)
                os.remove(path)
            else:
                path = v
                with open(path) as f:
                    references = json.load(f)
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid references link. Error: {e}")

        try:
            assert len(references) > 0
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of references must not be empty. Error: {e}")
        # standardize to string labels
        references = [str(y) for y in references]
        return references


class ClassificationMetricInput(ClassificationMetricInputSchema):
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except ValueError:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="Incorrect types passed into ClassificationMetricInput.")

    def parse(self):
        # Make sure the number of sentences is the same in the hypotheses and the reference lists
        try:
            if self.sources is not None:
                assert len(self.hypotheses) == len(self.references) == len(self.sources)
            else:
                assert len(self.hypotheses) == len(self.references)
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources, hypotheses and references must be the same.")


class NamedEntityRecognitionElement(BaseModel):
    """The standardized schema of the NamedEntityRecognitionElement.

    :param text:
        surface string
    :type text:
        str
    :param category:
        entity label
    :type category:
        str
    :param offset:
        surface string starting point in the source
    :type offset:
        int
    :param length:
        character length of surface string
    :type length:
        int
    :param confidence_score:
        confidence score. Optional
    :type confidence_score:
        float
    """

    text: str
    category: str
    offset: int
    length: int
    confidence_score: Optional[float] = 100


class NamedEntityRecognitionMetricInputSchema(MetricInput):
    """The standardized schema of the aiXplain's NER Metric API input.

    :param hypotheses:
        Input hypotheses to the model.
    :type hypotheses:
        Any
    :param references:
        Input references to the model.
    :type references:
        Any
    :param sources:
        Input sources to the model.
    :type sources:
        Any
    :param supplier:
        Supplier name.
    :type supplier:
        str
    :param metric:
        Metric name
    :type metric:
        str
    :param version:
        The version number of the metric if the supplier has multiple
        implementations of the metrics. Optional.
    :type version:
        str
    :param language:
        The language the metric processes (if relevant). Optional.
    :type language:
        str
    :param threshold:
        Confidence score threshold. Optional.
    :type threshold:
        str
    """

    hypotheses: Union[str, List[List[NamedEntityRecognitionElement]]]
    references: Union[str, List[List[NamedEntityRecognitionElement]]]
    sources: Optional[str] = None
    threshold: Optional[float] = 0.0

    @validator("sources")
    def check_sources(cls, v):
        if v is not None:
            try:
                if isinstance(v, str) is True:
                    path = download_data(v)
                    with open(path) as f:
                        sources = json.load(f)
                    os.remove(path)
                else:
                    sources = v
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid sources link. Error: {e}")

            try:
                assert len(sources) > 0
            except Exception as e:
                raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of sources must not be empty. Error: {e}")
            return sources
        else:
            return None

    @validator("hypotheses")
    def check_hypotheses(cls, v):
        try:
            if isinstance(v, str) is True:
                if validators.url(v):
                    path = download_data(v)
                    with open(path) as f:
                        hypotheses = json.load(f)
                    os.remove(path)
                else:
                    path = v
                    with open(path) as f:
                        hypotheses = json.load(f)
            else:
                hypotheses = v

            hypotheses = [[NamedEntityRecognitionElement(**hyp) for hyp in doc] for doc in hypotheses]
        except Exception as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Invalid hypotheses link. Error: {e}")

        try:
            assert len(hypotheses) > 0
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"List of hypotheses must not be empty.")
        return hypotheses

    @validator("references")
    def check_references(cls, v):
        try:
            if isinstance(v, str) is True:
                if validators.url(v):
                    path = download_data(v)
                    with open(path) as f:
                        references = json.load(f)
                    os.remove(path)
                else:
                    path = v

                    with open(path) as f:
                        references = json.load(f)
            else:
                references = v
            references = [[NamedEntityRecognitionElement(**ref) for ref in doc] for doc in references]
        except:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="Invalid references link.")

        try:
            assert len(references) > 0
        except:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="List of references must not be empty.")
        return references


class NamedEntityRecognitionMetricInput(NamedEntityRecognitionMetricInputSchema):
    def __init__(self, **input):
        try:
            super().__init__(**input)
            self.parse()
        except ValueError:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason="Incorrect types passed into NamedEntityRecognitionMetricInput.")

    def parse(self):
        # Make sure the number of elements is the same in the hypotheses and the reference lists
        try:
            if self.sources is not None:
                assert len(self.hypotheses) == len(self.references) == len(self.sources)
            else:
                assert len(self.hypotheses) == len(self.references)
            self.hypotheses = [[hyp for hyp in doc if hyp.confidence_score >= self.threshold] for doc in self.hypotheses]
        except AssertionError as e:
            raise tornado.web.HTTPError(status_code=HTTPStatus.BAD_REQUEST, reason=f"Number of sources, hypotheses and references must be the same.")
