Metadata-Version: 2.1
Name: ref-man-py
Version: 0.8.0
Summary: Ref Man Python Module
Home-page: https://github.com/akshaybadola/ref-man-py
License: MIT
Keywords: emacs,semanticscholar,bibliography,ref-man
Author: Akshay
Author-email: akshay.badola.cs@gmail.com
Requires-Python: >=3.8,<4.0
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.7
Classifier: Topic :: Education
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Text Editors :: Emacs
Requires-Dist: MarkupSafe (==2.0.1)
Requires-Dist: PyYAML (>=6.0.0,<7.0.0)
Requires-Dist: aiohttp (>=3.8.1,<4.0.0)
Requires-Dist: beautifulsoup4 (>=4.9.1,<5.0.0)
Requires-Dist: common_pyutil (>=0.8.5,<1.0.0)
Requires-Dist: file-magic (>=0.4.1,<0.5.0)
Requires-Dist: flask (>=1.1.2,<2.0.0)
Requires-Dist: lxml (>=4.6.4,<5.0.0)
Requires-Dist: psutil (>=5.8.0,<6.0.0)
Requires-Dist: requests (>=2.31.0,<3.0.0)
Requires-Dist: s2cache (>=0.3.9,<0.4.0)
Description-Content-Type: text/plain

* ref-man-py

  Python Module for ~ref-man~ (See https://github.com/akshaybadola/ref-man).

  Network requests and xml parsing can be annoying in emacs, so ref-man uses a
  separate python process for efficient (and sometimes parallel) fetching of
  network requests.

* Features

** Persistent Service with Flask
   - Can easily integrate with other applications
   - Parallel fetching of large number of entries from supported websites
     (DBLP, ArXiv etc.)

** HTTP integration with Semantic Scholar API (https://www.semanticscholar.org/product/api)
   - Fetch with multiple IDs like arxiv, ACL etc.
   - Local files based cache to avoid redundant requests
   - +Fetches all metadata in one go (Will change soon as Semantic Scholar is
     updating its API)+
   - Now uses the Semantic Scholar Graph API

** Experimental (and undocumented) Semantic Scholar Search API
   - Mostly gleaned through analyzing network requests. Helpful for searching
     articles.

** HTTP integration with DBLP and ArXiv
   - Supports multiple parallel requests for batch updates

** Fetch PDF from a given URL
   - Easier to fetch using python than with Emacs's callbacks

** Option for proxying requests
   - Particularly useful for PDFs if you're tunneling to your institution from
     home or some other location and the article you want is with institutional
     (IP based) access only.

* Roadmap

** More Tests
   - Coverage is low.
   - Need to remove some code which isn't used.
   - Some parts need to be rewritten.

** Change to new Semantic Scholar API (*Done*)
   Semantic Scholar is changing its API. See https://www.semanticscholar.org/product/api
   we should migrate to new ~graph/v1/paper~ API.

** Integrate ~common_pyutil.net.Get~
   It has support for progress tracking. Helpful when network is slow and when
   downloading large files.

** ASGI server
   With websockets for better Async integration.

** Integrate more services
   There're semi-working/broken functions for CrossRef and some other services in
   ~ref-man~. They can be exported to python perhaps.

* Wishlist

** Serve Org files on the fly as html
   Will help in integrating a larger userbase. Perhaps also with a py-to-lisp
   (hy like maybe) interface so that elementary scripting on the org backend can
   be done.

** Ultimately integrate ~pndconf~ also
   A document preparation toolchain (See https://github.com/akshaybadola/pndconf),
   which is integrated with ~ref-man~.

* License

  All the code in this repo except for external services and libraries are
  licensed under the MIT License. See ~LICENSE.md~ in this repo.

  Some commits in the repository may be under a different license. If you use
  those, you would have see the details of that License.

