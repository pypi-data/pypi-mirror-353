Metadata-Version: 2.4
Name: tupac
Version: 0.1.0
Summary: A GPT wrapper CLI with proper MCP tool & resource support
Author-email: Tim Kellogg <timothy.kellogg@gmail.com>
License-File: LICENSE
Requires-Python: >=3.12
Requires-Dist: fastmcp>=2.7.0
Requires-Dist: openai>=1.84.0
Requires-Dist: python-dotenv>=1.1.0
Requires-Dist: rich>=14.0.0
Requires-Dist: typer>=0.16.0
Description-Content-Type: text/markdown

# tupac
A GPT wrapper with MCP support. It's a thin layer around the OpenAI [responses][api] API
with functions being specified as MCP config.

You can write a simple "LLM app" very quickly, by specifying MCP config and a system prompt.

MCP functionality supported:
* ✅ tools
* ✅ resources — but only as far as they're being returned from tools. No listing or fetching.

Nothing else. It's what I consider to be an absolute [bare-bones][blog] MCP app.

## Usage: LLM app

```bash
uvx tupac configs/web-search.json "When are we getting to Mars?"
```

Configuration files may contain `${VARNAME}` placeholders which are expanded
from the environment before parsing. Environment variables can also be loaded
from a `.env` file via `python-dotenv`. See `configs/web-search.json` for an
example using `${EXA_API_KEY}`.

Configuration format follows the standard MCP schema:

```json
{
  "instructions": "Use search to answer questions.",
  "model": "o3",
  "mcpServers": {
    "exa": {
      "type": "url",
      "url": "https://mcp.exa.ai/mcp?exaApiKey=${EXA_API_KEY}"
    }
  }
}
```

You can use that `${EXA_API_KEY}` syntax to reference environment variables. It
does load [`.env` files][env].

 [api]: https://platform.openai.com/docs/api-reference/responses
 [env]: https://pypi.org/project/python-dotenv/
 [blog]: https://timkellogg.me/blog/2025/06/05/mcp-resources
