# Copyright International Business Machines Corp, 2025
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
import asyncio

class BqueuesCollector:
    """
    Collection module for bqueues commands
    """
    def __init__(self, metrics_generator) -> None:

        # Command used to collect data
        self.command = "bqueues"

        # Class used to create and manage metrics
        self.metrics_generator = metrics_generator

        # Tuple's List of: metric name, metric description, metric type (Gauge, Info, Counter), metric labels list to create metric, metric label to fetch data
        self.metrics_list = [("ibm_lsf_queue", "Queue Total Jobs", "Gauge", ['queue', 'state', 'cluster_name'], "")]

        # Metrics list generated by metrics_generator class
        self.metrics = self.metrics_generator.create_metrics(self.metrics_list)

    def fetch(self, cluster_info):
        """
        Collects info from bqueues -json -o queue_name:12 njobs pend run susp rsv ususp ssusp status
        """
        asyncio.run(self.fetch_async(cluster_info), debug=self.metrics_generator.debug)

    async def fetch_async(self, cluster_info):
        """
        Collects info from bqueues -json -o queue_name:12 njobs pend run susp rsv ususp ssusp status
        """
        cluster_name = cluster_info["cluster_name"]
        time_nanosec = time.time_ns()
        cmd = [self.command, '-json', '-o', '\"queue_name:12 njobs pend run susp rsv ususp ssusp status\"']
        data_queues, _, return_bool = await self.metrics_generator.collect_data_async(cmd, "", "ibm_lsf_queue", "lsf_queue unvailable")

        if return_bool:
            iterations = data_queues["QUEUES"]
            queue_status = ["NJOBS","PEND","RUN","SUSP","RSV","USUSP","SSUSP"]
            if self.metrics_generator.debug:
                print(time_nanosec, "-----------------------------------------------------------------------")
            for (metric, name, _) in self.metrics:
                # First of all clean up the metric
                metric.clear()
                for n in range(iterations):
                    if data_queues['RECORDS'][n]['STATUS'] != "Closed:Active":
                        for status in queue_status:
                            # Update Prometheus metrics with application metrics
                            metric.labels(data_queues['RECORDS'][n]['QUEUE_NAME'], status, cluster_name).set(data_queues['RECORDS'][n][status])
                        if self.metrics_generator.debug:
                            print("lsf_queues,", f"cluster_name={cluster_name}", "name=", data_queues['RECORDS'][n]['QUEUE_NAME'], " njobs=", data_queues['RECORDS'][n]['NJOBS'],"i,",
                                      "pend=", data_queues['RECORDS'][n]['PEND'],"i,",
                                      "run=", data_queues['RECORDS'][n]['RUN'],"i,",
                                      "susp=", data_queues['RECORDS'][n]['SUSP'],"i,",
                                      "rsv=", data_queues['RECORDS'][n]['RSV'],"i,",
                                      "ususp=", data_queues['RECORDS'][n]['USUSP'],"i,",
                                      "ssusp=", data_queues['RECORDS'][n]['SSUSP'],"i ",
                                      time_nanosec, sep='')