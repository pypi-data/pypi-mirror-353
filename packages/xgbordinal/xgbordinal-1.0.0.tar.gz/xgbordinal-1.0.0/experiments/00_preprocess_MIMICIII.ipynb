{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0789e85-9ad9-4bd5-82bc-25952851469f",
   "metadata": {},
   "source": [
    "#### Title: 00_preprocess_MIMICIII.ipynb\n",
    "\n",
    "#### Description: Create dataset for predicting Glasgow Coma Scale based on MIMIC-III database \n",
    "\n",
    "#### Author: Fabian Kahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b12381-d6ab-488d-9768-c68019e84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Source: https://physionet.org/content/mimiciii/1.4/\n",
    "data_path = '../data/physionet.org/files/mimiciii/1.4/'\n",
    "\n",
    "# Function to merge GCS (Glasgow Coma Scale) scores with backward tolerance for matching chart events\n",
    "def get_values_backward(df_gcs, items_ids, df, df_ids, tolerance = pd.Timedelta('24h')):\n",
    "    df_out = df_gcs[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score']].copy()\n",
    "    df.sort_values(['CHARTTIME'], inplace=True)\n",
    "    df['CHARTTIME'] = pd.to_datetime(df['CHARTTIME'])\n",
    "    df = df.dropna(subset=['CHARTTIME'])\n",
    "    for i in items_ids:\n",
    "        df_i = df[df['ITEMID'] == i]\n",
    "        item_name = df_ids[df_ids['ITEMID'] == i]['LABEL'].iloc[0]\n",
    "        df_i = df_i.rename(columns={'VALUE': item_name})\n",
    "        df_i = df_i[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', item_name]]\n",
    "        df_out = pd.merge_asof(df_out, df_i,\n",
    "                                on='CHARTTIME',\n",
    "                                by=['SUBJECT_ID', 'HADM_ID'],\n",
    "                                direction='backward', tolerance=tolerance)\n",
    "    return df_out\n",
    "\n",
    "# Function to merge GCS scores with corresponding item values without time-based tolerance\n",
    "def get_values(df_gcs, items_ids, df, df_ids):\n",
    "    df_out = df_gcs[['SUBJECT_ID', 'HADM_ID', 'gcs_score']].copy()\n",
    "    df.sort_values(['SUBJECT_ID', 'HADM_ID'], inplace=True)\n",
    "    df_out.sort_values(['SUBJECT_ID', 'HADM_ID'], inplace=True)\n",
    "    for i in items_ids:\n",
    "        df_i = df[df['ITEMID'] == i]\n",
    "        item_name = df_ids[df_ids['ITEMID'] == i]['LABEL'].iloc[0]\n",
    "        df_i = df_i.rename(columns={'VALUE': item_name})\n",
    "        df_i = df_i[['SUBJECT_ID', 'HADM_ID', item_name]]\n",
    "        df_out = df_out.merge(df_i, on=['SUBJECT_ID', 'HADM_ID'], how='left')\n",
    "    return df_out\n",
    "    \n",
    "# Load data, partially in chunks due to large size of files\n",
    "chunk_size = 10**6\n",
    "chartevents_chunks = pd.read_csv(data_path+'CHARTEVENTS.csv.gz', low_memory=False, chunksize=chunk_size)\n",
    "d_items = pd.read_csv(data_path+'D_ITEMS.csv.gz', low_memory=False)\n",
    "icustays = pd.read_csv(data_path+'ICUSTAYS.csv.gz', low_memory=False)\n",
    "labevents = pd.read_csv(data_path+'LABEVENTS.csv.gz', low_memory=False)\n",
    "d_labitems = pd.read_csv(data_path+'D_LABITEMS.csv.gz', low_memory=False)\n",
    "inputevents = pd.read_csv(data_path+'INPUTEVENTS_CV.csv.gz', low_memory=False)\n",
    "prescriptions = pd.read_csv(data_path+'PRESCRIPTIONS.csv.gz', low_memory=False)\n",
    "diagnoses_icd = pd.read_csv(data_path+'DIAGNOSES_ICD.csv.gz', low_memory=False)\n",
    "d_icd_diagnoses = pd.read_csv(data_path+'D_ICD_DIAGNOSES.csv.gz', low_memory=False)\n",
    "\n",
    "# Heart Rate, Arterial BP Mean, Non Invasive Blood Pressure systolic, SpO2, Respiratory Rate, Temperature C\n",
    "vital_signs_ids = [211, 220045, 51, 52, 220179, 646, 220277, 618, 619, 224690, 676, 223762]\n",
    "\n",
    "# Identify GCS-related item IDs\n",
    "gcs_items = d_items[d_items['LABEL'].str.contains('GCS Total', case=False, na=False)]\n",
    "gcs_item_ids = gcs_items['ITEMID'].tolist()\n",
    "\n",
    "# Filter for GCS events and vital signs events\n",
    "gcs_events_list = []\n",
    "vital_signs_list = []\n",
    "i = 0\n",
    "for chunk in chartevents_chunks:\n",
    "    i+=1\n",
    "    # Filter the chunk for GCS-related events\n",
    "    gcs_chunk = chunk[chunk['ITEMID'].isin(gcs_item_ids)]\n",
    "    vital_signs_chunk = chunk[chunk['ITEMID'].isin(vital_signs_ids)]\n",
    "    gcs_events_list.append(gcs_chunk)\n",
    "    vital_signs_list.append(vital_signs_chunk)\n",
    "\n",
    "# Concatenate the filtered GCS and vital sign events into full dataframes\n",
    "gcs_events = pd.concat(gcs_events_list, ignore_index=True)\n",
    "vital_signs = pd.concat(vital_signs_list, ignore_index=True)\n",
    "\n",
    "# Define lab item IDs for Glucose, Sodium, Potassium, Bicarbonate, pH\n",
    "lab_items_ids = [50809, 50824, 50822, 50882, 50820]\n",
    "\n",
    "# Heart Rate, Arterial BP Mean, Non Invasive Blood Pressure systolic, SpO2, Respiratory Rate, Temperature C\n",
    "# Without duplicates\n",
    "vital_signs_ids = [220045, 52, 220179, 646, 618, 676]\n",
    "# Heart Rate, Arterial BP Mean, Non Invasive Blood Pressure systolic, SpO2, Respiratory Rate, Temperature C\n",
    "\n",
    "# Clean the dataframes by removing and correcting erroneous data\n",
    "labevents.dropna(subset=['HADM_ID'], inplace=True)\n",
    "labevents['HADM_ID'] = labevents['HADM_ID'].astype(int)\n",
    "gcs_events['CHARTTIME'] = pd.to_datetime(gcs_events['CHARTTIME'])\n",
    "gcs_events = gcs_events.rename(columns={'VALUE': 'gcs_score'})\n",
    "gcs_events.dropna(subset=['gcs_score'], inplace=True)\n",
    "gcs_events.drop_duplicates(subset=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score'], keep='first', inplace=True)\n",
    "gcs_events['gcs_score'] = gcs_events['gcs_score'].astype(int)\n",
    "gcs_events.sort_values(['CHARTTIME'], inplace=True)\n",
    "vital_signs_adjusted = vital_signs.copy()\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(211, 220045) # Heart Rate --> Heart Rate\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(51, 52) # Arterial BP [Systolic] --> Arterial BP Mean\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(619, 618) # Respiratory Rate Set --> Respiratory Rate\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(224690, 618) # Respiratory Rate (Total) --> Respiratory Rate\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(223762, 676) # Temperature Celsius --> Temperature C\n",
    "vital_signs_adjusted['ITEMID'] = vital_signs_adjusted['ITEMID'].replace(220277, 646) # O2 saturation pulseoxymetry --> SpO2\n",
    "labevents.replace('GREATER THAN 999', 1000, inplace=True)\n",
    "labevents.replace('>500', 501, inplace=True)\n",
    "labevents.replace('<10', 9, inplace=True)\n",
    "labevents.replace('GREATER THAN 500', 501, inplace=True)\n",
    "labevents.replace('ERROR', np.nan, inplace=True)\n",
    "labevents.replace('INTERFERING SUBSTANCES', np.nan, inplace=True)\n",
    "labevents.replace('DISREGARD PREVIOUS RESULT OF 88', 88, inplace=True)\n",
    "labevents.replace('ERROR, DISREGARD PREVIOUS RESULT OF 131', 131, inplace=True)\n",
    "labevents.replace('LESS THAN 10', 9, inplace=True)\n",
    "labevents.replace('UNABLE TO MEASURE POTASSIUM, OUT OF REPORTABLE RANGE', np.nan, inplace=True)\n",
    "labevents.replace('GREATER THAN 10', 11, inplace=True)\n",
    "labevents.replace('DISREGARD PREVIOUS RESULT OF 3.5', 3.5, inplace=True)\n",
    "labevents.replace('ERROR, DISREGARD PREVIOUS RESULT OF 4.6', 4.6, inplace=True)\n",
    "labevents.replace('GREATER THAN 45', 46, inplace=True)\n",
    "labevents.replace('GREATER THAN 40', 41, inplace=True)\n",
    "labevents.replace('LESS THAN 5', 4, inplace=True)\n",
    "labevents.replace('<5', 4, inplace=True)\n",
    "labevents.replace('GREATER THAN 50', 51, inplace=True)\n",
    "labevents.replace('LESS THAN 5.0', 4, inplace=True)\n",
    "labevents.replace('>50', 51, inplace=True)\n",
    "labevents.replace('VERIFIED BY REPLICATE ANALYSIS', np.nan, inplace=True)\n",
    "labevents.replace('<5.0', 4, inplace=True)\n",
    "labevents.replace('VERIFIED BY REPEAT ANALYSIS', np.nan, inplace=True)\n",
    "labevents.replace('DISREGARD PREVIOUS RESULT 24,SPECIMEN MISLABELLED', 24, inplace=True)\n",
    "labevents.replace('7.45 PLEURAL FLUID', 7.45, inplace=True)\n",
    "labevents.replace('DISREGARD', np.nan, inplace=True)\n",
    "labevents.replace('DISREGARD PREVIOUSLY REPORTED RESULT OF 7.29', 7.29, inplace=True)\n",
    "labevents.replace('QUANTITY NOT SUFFICIENT', np.nan, inplace=True)\n",
    "labevents.replace('DISREGARD RESULTS', np.nan, inplace=True)\n",
    "labevents.replace('DISREGARD PREVIOUS RESULT OF 7.44', 7.44, inplace=True)\n",
    "labevents.replace('GREATER THAN 7.55', 7.56, inplace=True)\n",
    "labevents.dropna(subset=['VALUE'], inplace=True)\n",
    "\n",
    "# Filter for sedative drugs and create a feature indicating sedative use\n",
    "sedative_drugs = ['Midazolam', 'Propofol', 'Morphine', 'Fentanyl']\n",
    "sedative = prescriptions[['SUBJECT_ID', 'HADM_ID', 'ENDDATE', 'DRUG']].copy()\n",
    "sedative['VALUE'] = sedative['DRUG'].isin(sedative_drugs).astype(int)\n",
    "sedative['ITEMID'] = 'is_sedative'\n",
    "sedative = sedative[sedative['VALUE'] == 1].drop(['DRUG'], axis=1)\n",
    "sedative = sedative.rename(columns={'ENDDATE': 'CHARTTIME'})\n",
    "\n",
    "# Extract diagnosis information for specific neurological conditions\n",
    "diagnosis_substrings = ['intracranial hemorrhage', 'encephalitis', 'concussion', 'meningitis', 'epilepsy', 'hydrocephalus']\n",
    "diagnoses = None\n",
    "for i in diagnosis_substrings:\n",
    "    relevant_diagnoses = d_icd_diagnoses[d_icd_diagnoses['LONG_TITLE'].str.contains(i, case=False)]\n",
    "    diagnosis_codes = list(relevant_diagnoses['ICD9_CODE'])\n",
    "    diagnosis = diagnoses_icd[diagnoses_icd['ICD9_CODE'].isin(diagnosis_codes)].copy()\n",
    "    diagnosis['ITEMID'] = i\n",
    "    diagnosis['VALUE'] = 1\n",
    "    if diagnoses is None:\n",
    "        diagnoses = diagnosis\n",
    "    else:\n",
    "        diagnoses = pd.concat([diagnoses, diagnosis], ignore_index=True)\n",
    "diagnoses.drop(['ROW_ID', 'SEQ_NUM', 'ICD9_CODE'], axis=1, inplace=True)\n",
    "diagnoses.drop_duplicates(inplace=True)\n",
    "\n",
    "# Extract lab test features\n",
    "lab_tests_features = get_values_backward(gcs_events, lab_items_ids, labevents, d_labitems)\n",
    "lab_tests_features['Glucose'] = lab_tests_features['Glucose'].astype(float)\n",
    "lab_tests_features['Sodium, Whole Blood'] = lab_tests_features['Sodium, Whole Blood'].astype(float)\n",
    "lab_tests_features['Potassium, Whole Blood'] = lab_tests_features['Potassium, Whole Blood'].astype(float)\n",
    "lab_tests_features['Bicarbonate'] = lab_tests_features['Bicarbonate'].astype(float)\n",
    "lab_tests_features['pH'] = lab_tests_features['pH'].astype(float)\n",
    "\n",
    "# Extract vital signs features\n",
    "vital_signs_features = get_values_backward(gcs_events, vital_signs_ids, vital_signs_adjusted, d_items)\n",
    "vital_signs_features['Heart Rate'] = vital_signs_features['Heart Rate'].astype(float)\n",
    "vital_signs_features['Arterial BP Mean'] = vital_signs_features['Arterial BP Mean'].astype(float)\n",
    "vital_signs_features['Non Invasive Blood Pressure systolic'] = vital_signs_features['Non Invasive Blood Pressure systolic'].astype(float)\n",
    "vital_signs_features['SpO2'] = vital_signs_features['SpO2'].astype(float)\n",
    "vital_signs_features['Respiratory Rate'] = vital_signs_features['Respiratory Rate'].astype(float)\n",
    "vital_signs_features['Temperature C'] = vital_signs_features['Temperature C'].astype(float)\n",
    "\n",
    "# Extract sedative features\n",
    "dummy = pd.DataFrame(columns=['ITEMID', 'LABEL'], data=[['is_sedative','is_sedative']])\n",
    "sedative_features = get_values_backward(gcs_events, ['is_sedative'], sedative, dummy)\n",
    "\n",
    "# Extract diagnosis features\n",
    "dummy = pd.DataFrame({'ITEMID': diagnosis_substrings,\n",
    "                     'LABEL': diagnosis_substrings})\n",
    "diagnosis_features = get_values(gcs_events, diagnosis_substrings, diagnoses, dummy)\n",
    "\n",
    "# Merge all features to one dataset\n",
    "dataset = gcs_events[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score']]\n",
    "dataset = pd.merge(dataset, lab_tests_features, on=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score'], how='left')\n",
    "dataset = pd.merge(dataset, vital_signs_features, on=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score'], how='left')\n",
    "dataset = pd.merge(dataset, sedative_features, on=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'gcs_score'], how='left')\n",
    "\n",
    "# Shuffle the dataset to ensure random selection of duplicates\n",
    "dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Drop duplicates based on 'SUBJECT_ID', keeping the first occurrence after shuffling\n",
    "dataset.drop_duplicates(subset=['SUBJECT_ID'], keep='first', inplace=True)\n",
    "dataset.columns = dataset.columns.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataset.to_csv(data_path+'dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thrombophilia",
   "language": "python",
   "name": "thrombophilia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
