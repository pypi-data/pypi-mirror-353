"""
ä½œè€…ï¼šXiaoqiang
å¾®ä¿¡å…¬ä¼—å·ï¼šXiaoqiangClub
åˆ›å»ºæ—¶é—´ï¼š2025/6/7 10:41
æ–‡ä»¶æè¿°ï¼šé«˜æ•ˆã€æ˜“ç”¨çš„ OpenRouter API Python å®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒæ­¥ä¸å¼‚æ­¥è°ƒç”¨ã€‚
æ–‡ä»¶è·¯å¾„ï¼š/src/openrouter/openrouter.py
"""
import logging
import httpx
from .utils import read_str_or_file, logger_init
from typing import Optional, List, Dict, Any, Literal, Union
import random


class OpenRouterSync:
    def __init__(
            self,
            api_key: Union[str, List[str]],
            random_key: bool = False,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            base_url: str = "https://openrouter.ai/api/v1",
            logger: Optional[logging.Logger] = None,
            system_prompt: Optional[str] = None,
            assistant_prompt: Optional[str] = None,
            console_log_level: str = "INFO",
            log_file_level: str = "WARNING",
            log_file: Optional[str] = None
    ) -> None:
        """
        OpenRouter çš„ Python å®¢æˆ·ç«¯

        :param api_key: OpenRouter çš„ API Key
        :param random_key: å¤škeyæ—¶æ˜¯å¦éšæœºé€‰æ‹©keyï¼ŒTrueä¸ºéšæœºï¼ŒFalseä¸ºé¡ºåº
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œå¿…å¡«
        :param backup_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤å¼€å¯
        :param base_url: OpenRouter çš„ API åœ°å€
        :param logger: å¯é€‰ï¼Œä¼ å…¥è‡ªå®šä¹‰æ—¥å¿—å¯¹è±¡
        :param system_prompt: å¯é€‰ï¼Œç³»ç»Ÿè§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param assistant_prompt: å¯é€‰ï¼ŒåŠ©æ‰‹è§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param console_log_level: æ§åˆ¶å°æ—¥å¿—çº§åˆ«
        :param log_file_level: æ–‡ä»¶æ—¥å¿—çº§åˆ«
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        self.base_url = base_url
        self.primary_model = primary_model
        self.logger = logger or logger_init(
            name="OpenRouter",
            console_log_level=console_log_level,
            log_file_level=log_file_level,
            log_file=log_file
        )
        self.system_prompt = read_str_or_file(system_prompt) if system_prompt else None
        self.assistant_prompt = read_str_or_file(assistant_prompt) if assistant_prompt else None
        self._current_model = primary_model
        self._backup_models = backup_models or []
        self.auto_fallback = auto_fallback
        self._api_keys = api_key if isinstance(api_key, list) else [api_key]
        self._random_key = random_key
        self._api_key_index = 0

    def set_backup_models(self, models: List[str]):
        """
        è®¾ç½®å¤‡ç”¨æ¨¡å‹åˆ—è¡¨
        :param models: å¤‡ç”¨æ¨¡å‹IDåˆ—è¡¨
        """
        self._backup_models = models or []

    def chat(
            self,
            content: str,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            fallback_max: int = 2,
            reset_user_model: bool = True,
            headers_extra: Optional[Dict[str, str]] = None,
            body_extra: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        èŠå¤©æ¥å£ï¼Œä¸»æ¨¡å‹-å¤‡ç”¨æ¨¡å‹-å…è´¹æ¨¡å‹é¡ºåºå…œåº•

        :param content: ç”¨æˆ·çš„æ¶ˆæ¯å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œè‹¥ä¸ºNoneåˆ™ç”¨å®ä¾‹çš„primary_model
        :param backup_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤True
        :param fallback_max: å…è´¹æ¨¡å‹æœ€å¤§å°è¯•æ¬¡æ•°
        :param reset_user_model: è‹¥ä½¿ç”¨å¤‡ç”¨æ¨¡å‹æˆåŠŸå“åº”ï¼Œä¸‹æ¬¡æ˜¯å¦æ¢å¤ç”¨æˆ·è®¾å®šçš„æ¨¡å‹
        :param headers_extra: å¯é€‰ï¼Œé¢å¤–çš„è¯·æ±‚å¤´ï¼ˆç”¨äº Referer æˆ– X-Titleï¼‰
        :param body_extra: å¯é€‰ï¼Œé¢å¤–çš„ body å‚æ•°
        :return: æ¨¡å‹å›å¤çš„å†…å®¹å­—ç¬¦ä¸²
        """
        chosen_model = primary_model or self.primary_model
        backup_models_list = backup_models or self._backup_models
        auto_fallback = auto_fallback or self.auto_fallback
        model_try_list = []
        if chosen_model:
            model_try_list.append(chosen_model)
        if backup_models_list:
            model_try_list.extend(backup_models_list)

        # å…ˆé¡ºåºå°è¯•ä¸»æ¨¡å‹å’Œæ‰€æœ‰å¤‡ç”¨æ¨¡å‹
        for idx, try_model in enumerate(model_try_list):
            key_used = self._get_next_api_key()
            if idx == 0 and chosen_model:
                self.logger.info(f"ğŸš€ ä½¿ç”¨ä¸»æ¨¡å‹ï¼š{try_model}")
            else:
                self.logger.warning(f"ğŸ¯ å°è¯•å¤‡ç”¨æ¨¡å‹ï¼š{try_model}")
            url = f"{self.base_url}/chat/completions"
            messages = []
            if self.system_prompt:
                messages.append({"role": "system", "content": self.system_prompt})
            if self.assistant_prompt:
                messages.append({"role": "assistant", "content": self.assistant_prompt})
            user_content = read_str_or_file(content)
            messages.append({"role": "user", "content": user_content})
            payload = {
                "model": try_model,
                "messages": messages
            }
            if body_extra:
                payload.update(body_extra)
            headers = {
                "Authorization": f"Bearer {key_used}",
                "Content-Type": "application/json"
            }
            if headers_extra:
                headers.update(headers_extra)
            self.logger.debug(f"ğŸ”‘ æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨çš„API Key: sk-******{key_used[-5:]}")
            self.logger.debug(f"ğŸ“¤ æ­£åœ¨å‘é€è¯·æ±‚ï¼ˆç¬¬{idx + 1}æ¬¡ï¼Œæ¨¡å‹ï¼š{try_model}ï¼‰")
            try:
                with httpx.Client(timeout=30) as client:
                    response = client.post(url, json=payload, headers=headers)
                    response.raise_for_status()
                    result = response.json()
                    message = result["choices"][0]["message"]["content"]
                    self.logger.debug(f"ğŸ“¥ æ¥æ”¶åˆ°å›å¤ï¼š{message}")
                    if reset_user_model and primary_model:
                        self._current_model = primary_model
                    return message
            except httpx.HTTPStatusError as e:
                status = e.response.status_code
                if status == 402:
                    self.logger.error(
                        f"âŒ 402 Payment Requiredï¼šæ¨¡å‹IDé”™è¯¯æˆ–é¢åº¦ä¸è¶³ã€‚è¯·æ£€æŸ¥æ¨¡å‹IDæˆ–è´¦æˆ·ä½™é¢ã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                elif status == 429:
                    self.logger.error(
                        f"âŒ 429 Too Many Requestsï¼šè®¿é—®é€Ÿç‡è¿‡å¿«ï¼Œè¯·ç­‰å¾…æˆ–æ›´æ¢API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                elif 400 <= status < 500:
                    self.logger.error(f"âŒ {status} å®¢æˆ·ç«¯é”™è¯¯ï¼šè¯·æ£€æŸ¥è¯·æ±‚å‚æ•°æˆ–API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                else:
                    self.logger.error(f"âŒ æ¨¡å‹ {try_model} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
            except Exception as e:
                self.logger.error(f"âŒ æ¨¡å‹ {try_model} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")

        # æ‰€æœ‰ä¸»æ¨¡å‹å’Œå¤‡ç”¨æ¨¡å‹éƒ½å¤±è´¥åï¼Œå°è¯•å…è´¹æ¨¡å‹
        if auto_fallback or not model_try_list:
            free_models = self.get_free_models(fallback_max, only_id=True, random_pick=True)
            for i, m_id in enumerate(free_models):
                key_used = self._get_next_api_key()
                self.logger.warning(f"ğŸˆ å°è¯•å…è´¹æ¨¡å‹ï¼š{m_id}")
                url = f"{self.base_url}/chat/completions"
                messages = []
                if self.system_prompt:
                    messages.append({"role": "system", "content": self.system_prompt})
                if self.assistant_prompt:
                    messages.append({"role": "assistant", "content": self.assistant_prompt})
                user_content = read_str_or_file(content)
                messages.append({"role": "user", "content": user_content})
                payload = {
                    "model": m_id,
                    "messages": messages
                }
                if body_extra:
                    payload.update(body_extra)
                headers = {
                    "Authorization": f"Bearer {key_used}",
                    "Content-Type": "application/json"
                }
                if headers_extra:
                    headers.update(headers_extra)
                self.logger.debug(f"ğŸ”‘ æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨çš„API Key: sk-******{key_used[-5:]}")
                self.logger.debug(f"ğŸ“¤ æ­£åœ¨å‘é€è¯·æ±‚ï¼ˆå…è´¹æ¨¡å‹ç¬¬{i + 1}æ¬¡ï¼Œæ¨¡å‹ï¼š{m_id}ï¼‰")
                try:
                    with httpx.Client(timeout=30) as client:
                        response = client.post(url, json=payload, headers=headers)
                        response.raise_for_status()
                        result = response.json()
                        message = result["choices"][0]["message"]["content"]
                        self.logger.debug(f"ğŸ“¥ æ¥æ”¶åˆ°å›å¤ï¼š{message}")
                        return message
                except httpx.HTTPStatusError as e:
                    status = e.response.status_code
                    if status == 402:
                        self.logger.error(
                            f"âŒ 402 Payment Requiredï¼šå¯èƒ½æ˜¯æ¨¡å‹IDé”™è¯¯ã€æ¨¡å‹ä¸ºä»˜è´¹æ¨¡å‹æˆ–é¢åº¦ä¸è¶³ã€‚è¯·æ£€æŸ¥æ¨¡å‹IDæˆ–è´¦æˆ·ä½™é¢ã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    elif status == 429:
                        self.logger.error(
                            f"âŒ 429 Too Many Requestsï¼šè®¿é—®é€Ÿç‡è¿‡å¿«æˆ–è´¦æˆ·è¢«é™ï¼Œè¯·ç­‰å¾…æˆ–æ›´æ¢API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    elif 400 <= status < 500:
                        self.logger.error(f"âŒ {status} å®¢æˆ·ç«¯é”™è¯¯ï¼šè¯·æ£€æŸ¥è¯·æ±‚å‚æ•°æˆ–API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    else:
                        self.logger.error(f"âŒ å…è´¹æ¨¡å‹ {m_id} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
                except Exception as e:
                    self.logger.error(f"âŒ å…è´¹æ¨¡å‹ {m_id} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")

        return "è¯·æ±‚å¤±è´¥"

    def search_models(
            self,
            sort_by: Literal[
                "newest",
                "pricing_low",
                "pricing_high",
                "context_high",
                "throughput_high",
                "latency_low"
            ] = "newest",
            only_free: bool = False,
            keyword: Optional[str] = None,
            input_modalities: Optional[List[str]] = None,
            output_modalities: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢å¹¶ç­›é€‰æ¨¡å‹åˆ—è¡¨

        :param sort_by: æ’åºæ–¹å¼ï¼Œå¯é€‰å€¼åŒ…æ‹¬ï¼š
            - "newest": æœ€æ–°æ¨¡å‹ä¼˜å…ˆ
            - "pricing_low": ä»·æ ¼ä½ä¼˜å…ˆï¼ˆprompt + completionï¼‰
            - "pricing_high": ä»·æ ¼é«˜ä¼˜å…ˆ
            - "context_high": ä¸Šä¸‹æ–‡é•¿åº¦é«˜ä¼˜å…ˆ
            - "throughput_high": æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•°ä¼˜å…ˆ
            - "latency_low": å»¶è¿Ÿä½ä¼˜å…ˆï¼ˆç”¨ä»·æ ¼è¿‘ä¼¼ï¼‰
        :param only_free: æ˜¯å¦åªç­›é€‰å…è´¹æ¨¡å‹ï¼ˆæ¨¡å‹ ID å« ":free" æˆ–åç§°å« "(free)"ï¼‰
        :param keyword: å…³é”®è¯ï¼ŒåŒ¹é…æ¨¡å‹ ID æˆ–åç§°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        :param input_modalities: è¾“å…¥æ¨¡æ€åˆ—è¡¨ï¼Œå¦‚ ["text", "image"]ï¼Œè¦æ±‚æ¨¡å‹æ”¯æŒå…¨éƒ¨æ¨¡æ€
        :param output_modalities: è¾“å‡ºæ¨¡æ€åˆ—è¡¨ï¼Œå¦‚ ["text"]ï¼Œè¦æ±‚æ¨¡å‹æ”¯æŒå…¨éƒ¨æ¨¡æ€
        :return: æ»¡è¶³æ¡ä»¶çš„æ¨¡å‹å­—å…¸åˆ—è¡¨
        """
        self.logger.info(f"ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹ï¼ˆæ’åºï¼š{sort_by}ï¼Œåªçœ‹å…è´¹ï¼š{only_free}ï¼Œå…³é”®è¯ï¼š{keyword}ï¼‰")

        try:
            response = httpx.get(
                f"{self.base_url}/models",
                headers={
                    "Authorization": f"Bearer {self._get_next_api_key()}",
                    "Accept": "application/json"
                },
                timeout=10
            )
            response.raise_for_status()
            models = response.json().get("data", [])

            if only_free:
                models = [
                    m for m in models
                    if ":free" in m.get("id", "").lower() or "(free)" in m.get("name", "").lower()
                ]

            if keyword:
                kw = keyword.lower()
                models = [
                    m for m in models
                    if kw in m.get("id", "").lower() or kw in m.get("name", "").lower()
                ]

            if input_modalities:
                models = [
                    m for m in models
                    if self._modality_match(input_modalities, m.get("architecture", {}).get("input_modalities"))
                ]
            if output_modalities:
                models = [
                    m for m in models
                    if self._modality_match(output_modalities, m.get("architecture", {}).get("output_modalities"))
                ]

            def total_price(m: Dict[str, Any]) -> float:
                try:
                    p = float(m.get("pricing", {}).get("prompt", 0))
                    c = float(m.get("pricing", {}).get("completion", 0))
                    return p + c
                except:
                    return float("inf")

            if sort_by == "newest":
                models.sort(key=lambda x: x.get("created", 0), reverse=True)
            elif sort_by == "pricing_low":
                models.sort(key=total_price)
            elif sort_by == "pricing_high":
                models.sort(key=total_price, reverse=True)
            elif sort_by == "context_high":
                models.sort(key=lambda x: x.get("top_provider", {}).get("context_length", 0), reverse=True)
            elif sort_by == "throughput_high":
                models.sort(key=lambda x: x.get("top_provider", {}).get("max_completion_tokens") or 0, reverse=True)
            elif sort_by == "latency_low":
                models.sort(key=total_price)

            self.logger.info(f"âœ… å…±æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹")

            for i, model in enumerate(models[:3]):
                self.logger.debug(
                    f"ğŸ§  æ¨¡å‹ {i + 1}ï¼šID={model.get('id')}ï¼Œåç§°={model.get('name', 'æœªçŸ¥')}ï¼Œ"
                    f"è¾“å…¥={model.get('architecture', {}).get('input_modalities')}ï¼Œ"
                    f"è¾“å‡º={model.get('architecture', {}).get('output_modalities')}ï¼Œ"
                    f"ä»·æ ¼={total_price(model):.8f}"
                )

            return models

        except Exception as e:
            self.logger.error(f"âŒ æœç´¢å¤±è´¥ï¼š{str(e)}")
            return []

    @staticmethod
    def _modality_match(keywords: Optional[List[str]], target: Optional[List[str]]) -> bool:
        """
        åˆ¤æ–­æ¨¡æ€æ˜¯å¦åŒ¹é…ï¼ˆç§æœ‰æ–¹æ³•ï¼‰

        :param keywords: ç”¨æˆ·æä¾›çš„æ¨¡æ€å…³é”®è¯åˆ—è¡¨
        :param target: æ¨¡å‹æ”¯æŒçš„æ¨¡æ€åˆ—è¡¨
        :return: æ˜¯å¦åŒ¹é…
        """
        if not keywords:
            return True
        if not target:
            return False
        return all(m in target for m in keywords)

    def get_free_models(self, limit: Optional[int] = None, only_id: bool = True, random_pick: bool = False):
        """
        è·å–å…è´¹æ¨¡å‹åˆ—è¡¨
        :param limit: è¿”å›æ¨¡å‹æ•°é‡ï¼ŒNoneä¸ºå…¨éƒ¨
        :param only_id: æ˜¯å¦åªè¿”å›æ¨¡å‹idï¼ŒTrueåªè¿”å›idï¼ŒFalseè¿”å›å®Œæ•´å­—å…¸
        :param random_pick: limitç”Ÿæ•ˆæ—¶ï¼Œæ˜¯å¦éšæœºé€‰å–æŒ‡å®šæ•°é‡ï¼Œé»˜è®¤Falseä¸ºé¡ºåºåˆ‡ç‰‡
        :return: æ¨¡å‹idåˆ—è¡¨æˆ–æ¨¡å‹å­—å…¸åˆ—è¡¨
        """
        models = self.search_models(only_free=True)
        if limit is not None:
            if random_pick:
                models = random.sample(models, min(limit, len(models)))
            else:
                models = models[:limit]
        if only_id:
            return [m["id"] for m in models]
        return models

    def set_system_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®ç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        self.system_prompt = read_str_or_file(prompt) if prompt else None

    def set_assistant_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®åŠ©æ‰‹æç¤ºè¯ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        self.assistant_prompt = read_str_or_file(prompt) if prompt else None

    def set_primary_model(self, model: Optional[str]):
        """
        è®¾ç½®ä¸»æ¨¡å‹
        :param model: ä¸»æ¨¡å‹ID
        """
        self.primary_model = model
        self._current_model = model

    def _get_next_api_key(self):
        """
        è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„API Key
        :return: API Key
        """
        if self._random_key:
            return random.choice(self._api_keys)
        else:
            key = self._api_keys[self._api_key_index]
            self._api_key_index = (self._api_key_index + 1) % len(self._api_keys)
            return key

    def get_key_status(self, api_key: Optional[str] = None) -> dict:
        """
        æŸ¥è¯¢æŒ‡å®šAPI Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯
        :param api_key: å¯é€‰ï¼ŒæŒ‡å®šè¦æŸ¥è¯¢çš„keyï¼Œä¸ä¼ åˆ™ç”¨å½“å‰key
        :return: é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯å­—å…¸
        """
        key = api_key or self._api_keys[self._api_key_index]
        url = f"{self.base_url}/auth/key"
        headers = {"Authorization": f"Bearer {key}"}
        try:
            resp = httpx.get(url, headers=headers, timeout=10)
            resp.raise_for_status()
            return resp.json().get("data", {})
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢API Keyé¢åº¦å¤±è´¥ï¼š{str(e)}")
            return {"error": str(e)}

    def get_keys_status(self) -> List[dict]:
        """
        æŸ¥è¯¢æ‰€æœ‰API Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯
        :return: æ¯ä¸ªkeyçš„é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯åˆ—è¡¨
        """
        return [self.get_key_status(api_key=k) for k in self._api_keys]


class OpenRouterAsync:
    def __init__(
            self,
            api_key: Union[str, List[str]],
            random_key: bool = False,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            base_url: str = "https://openrouter.ai/api/v1",
            logger: Optional[logging.Logger] = None,
            system_prompt: Optional[str] = None,
            assistant_prompt: Optional[str] = None,
            console_log_level: str = "INFO",
            log_file_level: str = "WARNING",
            log_file: Optional[str] = None
    ) -> None:
        """
        OpenRouter çš„ Python å¼‚æ­¥å®¢æˆ·ç«¯

        :param api_key: OpenRouter çš„ API Key
        :param random_key: å¤škeyæ—¶æ˜¯å¦éšæœºé€‰æ‹©keyï¼ŒTrueä¸ºéšæœºï¼ŒFalseä¸ºé¡ºåº
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œå¿…å¡«
        :param backup_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤å¼€å¯
        :param base_url: OpenRouter çš„ API åœ°å€
        :param logger: å¯é€‰ï¼Œä¼ å…¥è‡ªå®šä¹‰æ—¥å¿—å¯¹è±¡
        :param system_prompt: å¯é€‰ï¼Œç³»ç»Ÿè§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param assistant_prompt: å¯é€‰ï¼ŒåŠ©æ‰‹è§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param console_log_level: æ§åˆ¶å°æ—¥å¿—çº§åˆ«
        :param log_file_level: æ–‡ä»¶æ—¥å¿—çº§åˆ«
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        """
        self.base_url = base_url
        self.primary_model = primary_model
        self.logger = logger or logger_init(
            name="OpenRouter",
            console_log_level=console_log_level,
            log_file_level=log_file_level,
            log_file=log_file
        )
        self.system_prompt = read_str_or_file(system_prompt) if system_prompt else None
        self.assistant_prompt = read_str_or_file(assistant_prompt) if assistant_prompt else None
        self._current_model = primary_model
        self._backup_models = backup_models or []
        self.auto_fallback = auto_fallback
        self._api_keys = api_key if isinstance(api_key, list) else [api_key]
        self._random_key = random_key
        self._api_key_index = 0

    def set_backup_models(self, models: List[str]):
        """
        è®¾ç½®å¤‡ç”¨æ¨¡å‹åˆ—è¡¨
        :param models: å¤‡ç”¨æ¨¡å‹IDåˆ—è¡¨
        """
        self._backup_models = models or []

    async def chat(
            self,
            content: str,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            fallback_max: int = 2,
            reset_user_model: bool = True,
            headers_extra: Optional[Dict[str, str]] = None,
            body_extra: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        èŠå¤©æ¥å£ï¼Œä¸»æ¨¡å‹-å¤‡ç”¨æ¨¡å‹-å…è´¹æ¨¡å‹é¡ºåºå…œåº•

        :param content: ç”¨æˆ·çš„æ¶ˆæ¯å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œè‹¥ä¸ºNoneåˆ™ç”¨å®ä¾‹çš„primary_model
        :param backup_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤True
        :param fallback_max: å…è´¹æ¨¡å‹æœ€å¤§å°è¯•æ¬¡æ•°
        :param reset_user_model: è‹¥ä½¿ç”¨å¤‡ç”¨æ¨¡å‹æˆåŠŸå“åº”ï¼Œä¸‹æ¬¡æ˜¯å¦æ¢å¤ç”¨æˆ·è®¾å®šçš„æ¨¡å‹
        :param headers_extra: å¯é€‰ï¼Œé¢å¤–çš„è¯·æ±‚å¤´ï¼ˆç”¨äº Referer æˆ– X-Titleï¼‰
        :param body_extra: å¯é€‰ï¼Œé¢å¤–çš„ body å‚æ•°
        :return: æ¨¡å‹å›å¤çš„å†…å®¹å­—ç¬¦ä¸²
        """
        chosen_model = primary_model or self.primary_model
        backup_models_list = backup_models if backup_models is not None else self._backup_models
        auto_fallback = auto_fallback and self.auto_fallback
        model_try_list = []
        if chosen_model:
            model_try_list.append(chosen_model)
        if backup_models_list:
            model_try_list.extend(backup_models_list)

        # å…ˆé¡ºåºå°è¯•ä¸»æ¨¡å‹å’Œæ‰€æœ‰å¤‡ç”¨æ¨¡å‹
        for idx, try_model in enumerate(model_try_list):
            key_used = self._get_next_api_key()
            if idx == 0 and chosen_model:
                self.logger.info(f"ğŸš€ ä½¿ç”¨ä¸»æ¨¡å‹ï¼š{try_model}")
            else:
                self.logger.warning(f"ğŸ¯ å°è¯•å¤‡ç”¨æ¨¡å‹ï¼š{try_model}")
            url = f"{self.base_url}/chat/completions"
            messages = []
            if self.system_prompt:
                messages.append({"role": "system", "content": self.system_prompt})
            if self.assistant_prompt:
                messages.append({"role": "assistant", "content": self.assistant_prompt})
            user_content = read_str_or_file(content)
            messages.append({"role": "user", "content": user_content})
            payload = {
                "model": try_model,
                "messages": messages
            }
            if body_extra:
                payload.update(body_extra)
            headers = {
                "Authorization": f"Bearer {key_used}",
                "Content-Type": "application/json"
            }
            if headers_extra:
                headers.update(headers_extra)
            self.logger.debug(f"ğŸ”‘ æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨çš„API Key: sk-******{key_used[-5:]}")
            self.logger.debug(f"ğŸ“¤ æ­£åœ¨å‘é€è¯·æ±‚ï¼ˆç¬¬{idx + 1}æ¬¡ï¼Œæ¨¡å‹ï¼š{try_model}ï¼‰")
            try:
                async with httpx.AsyncClient(timeout=30) as client:
                    response = await client.post(url, json=payload, headers=headers)
                    response.raise_for_status()
                    result = response.json()
                    if callable(result):
                        result = await response.json()
                    message = result["choices"][0]["message"]["content"]
                    self.logger.debug(f"ğŸ“¥ æ¥æ”¶åˆ°å›å¤ï¼š{message}")
                    if reset_user_model and primary_model:
                        self._current_model = primary_model
                    return message
            except httpx.HTTPStatusError as e:
                status = e.response.status_code
                if status == 402:
                    self.logger.error(
                        f"âŒ 402 Payment Requiredï¼šå¯èƒ½æ˜¯æ¨¡å‹IDé”™è¯¯ã€æ¨¡å‹ä¸ºä»˜è´¹æ¨¡å‹æˆ–é¢åº¦ä¸è¶³ã€‚è¯·æ£€æŸ¥æ¨¡å‹IDæˆ–è´¦æˆ·ä½™é¢ã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                elif status == 429:
                    self.logger.error(
                        f"âŒ 429 Too Many Requestsï¼šè®¿é—®é€Ÿç‡è¿‡å¿«æˆ–è´¦æˆ·è¢«é™ï¼Œè¯·ç­‰å¾…æˆ–æ›´æ¢API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                elif 400 <= status < 500:
                    self.logger.error(f"âŒ {status} å®¢æˆ·ç«¯é”™è¯¯ï¼šè¯·æ£€æŸ¥è¯·æ±‚å‚æ•°æˆ–API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                else:
                    self.logger.error(f"âŒ æ¨¡å‹ {try_model} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
            except Exception as e:
                self.logger.error(f"âŒ æ¨¡å‹ {try_model} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")

        # æ‰€æœ‰ä¸»æ¨¡å‹å’Œå¤‡ç”¨æ¨¡å‹éƒ½å¤±è´¥åï¼Œå°è¯•å…è´¹æ¨¡å‹
        if auto_fallback or not model_try_list:
            free_models = await self.get_free_models(fallback_max, only_id=True, random_pick=True)

            for i, m_id in enumerate(free_models):
                key_used = self._get_next_api_key()
                self.logger.warning(f"ğŸˆ å°è¯•å…è´¹æ¨¡å‹ï¼š{m_id}")
                url = f"{self.base_url}/chat/completions"
                messages = []
                if self.system_prompt:
                    messages.append({"role": "system", "content": self.system_prompt})
                if self.assistant_prompt:
                    messages.append({"role": "assistant", "content": self.assistant_prompt})
                user_content = read_str_or_file(content)
                messages.append({"role": "user", "content": user_content})
                payload = {
                    "model": m_id,
                    "messages": messages
                }
                if body_extra:
                    payload.update(body_extra)
                headers = {
                    "Authorization": f"Bearer {key_used}",
                    "Content-Type": "application/json"
                }
                if headers_extra:
                    headers.update(headers_extra)
                self.logger.debug(f"ğŸ”‘ æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨çš„API Key: sk-******{key_used[-5:]}")
                self.logger.debug(f"ğŸ“¤ æ­£åœ¨å‘é€è¯·æ±‚ï¼ˆå…è´¹æ¨¡å‹ç¬¬{i + 1}æ¬¡ï¼Œæ¨¡å‹ï¼š{m_id}ï¼‰")
                try:
                    async with httpx.AsyncClient(timeout=30) as client:
                        response = await client.post(url, json=payload, headers=headers)
                        response.raise_for_status()
                        result = response.json()
                        if callable(result):
                            result = await response.json()
                        message = result["choices"][0]["message"]["content"]
                        self.logger.debug(f"ğŸ“¥ æ¥æ”¶åˆ°å›å¤ï¼š{message}")
                        return message
                except httpx.HTTPStatusError as e:
                    status = e.response.status_code
                    if status == 402:
                        self.logger.error(
                            f"âŒ 402 Payment Requiredï¼šå¯èƒ½æ˜¯æ¨¡å‹IDé”™è¯¯ã€æ¨¡å‹ä¸ºä»˜è´¹æ¨¡å‹æˆ–é¢åº¦ä¸è¶³ã€‚è¯·æ£€æŸ¥æ¨¡å‹IDæˆ–è´¦æˆ·ä½™é¢ã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    elif status == 429:
                        self.logger.error(
                            f"âŒ 429 Too Many Requestsï¼šè®¿é—®é€Ÿç‡è¿‡å¿«æˆ–è´¦æˆ·è¢«é™ï¼Œè¯·ç­‰å¾…æˆ–æ›´æ¢API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    elif 400 <= status < 500:
                        self.logger.error(f"âŒ {status} å®¢æˆ·ç«¯é”™è¯¯ï¼šè¯·æ£€æŸ¥è¯·æ±‚å‚æ•°æˆ–API Keyã€‚\nå“åº”å†…å®¹ï¼š{e.response.text}")
                    else:
                        self.logger.error(f"âŒ å…è´¹æ¨¡å‹ {m_id} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
                except Exception as e:
                    self.logger.error(f"âŒ å…è´¹æ¨¡å‹ {m_id} è¯·æ±‚å¤±è´¥ï¼š{str(e)}")

        return "è¯·æ±‚å¤±è´¥"

    async def search_models(
            self,
            sort_by: Literal[
                "newest",
                "pricing_low",
                "pricing_high",
                "context_high",
                "throughput_high",
                "latency_low"
            ] = "newest",
            only_free: bool = False,
            keyword: Optional[str] = None,
            input_modalities: Optional[List[str]] = None,
            output_modalities: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢å¹¶ç­›é€‰æ¨¡å‹åˆ—è¡¨ï¼ˆå¼‚æ­¥ï¼‰

        :param sort_by: æ’åºæ–¹å¼
        :param only_free: æ˜¯å¦åªç­›é€‰å…è´¹æ¨¡å‹
        :param keyword: å…³é”®è¯
        :param input_modalities: è¾“å…¥æ¨¡æ€
        :param output_modalities: è¾“å‡ºæ¨¡æ€
        :return: æ»¡è¶³æ¡ä»¶çš„æ¨¡å‹å­—å…¸åˆ—è¡¨
        """
        self.logger.info(f"ğŸ” æ­£åœ¨æœç´¢æ¨¡å‹ï¼ˆæ’åºï¼š{sort_by}ï¼Œåªçœ‹å…è´¹ï¼š{only_free}ï¼Œå…³é”®è¯ï¼š{keyword}ï¼‰")
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                response = await client.get(
                    f"{self.base_url}/models",
                    headers={
                        "Authorization": f"Bearer {self._get_next_api_key()}",
                        "Accept": "application/json"
                    }
                )
                response.raise_for_status()
                models = response.json().get("data", [])
                if callable(models):
                    models = await response.json()
                    models = models.get("data", [])
                if only_free:
                    models = [
                        m for m in models
                        if ":free" in m.get("id", "").lower() or "(free)" in m.get("name", "").lower()
                    ]
                if keyword:
                    kw = keyword.lower()
                    models = [
                        m for m in models
                        if kw in m.get("id", "").lower() or kw in m.get("name", "").lower()
                    ]
                if input_modalities:
                    models = [
                        m for m in models
                        if OpenRouterSync._modality_match(input_modalities,
                                                          m.get("architecture", {}).get("input_modalities"))
                    ]
                if output_modalities:
                    models = [
                        m for m in models
                        if OpenRouterSync._modality_match(output_modalities,
                                                          m.get("architecture", {}).get("output_modalities"))
                    ]

                def total_price(m: Dict[str, Any]) -> float:
                    try:
                        p = float(m.get("pricing", {}).get("prompt", 0))
                        c = float(m.get("pricing", {}).get("completion", 0))
                        return p + c
                    except:
                        return float("inf")

                if sort_by == "newest":
                    models.sort(key=lambda x: x.get("created", 0), reverse=True)
                elif sort_by == "pricing_low":
                    models.sort(key=total_price)
                elif sort_by == "pricing_high":
                    models.sort(key=total_price, reverse=True)
                elif sort_by == "context_high":
                    models.sort(key=lambda x: x.get("top_provider", {}).get("context_length", 0), reverse=True)
                elif sort_by == "throughput_high":
                    models.sort(key=lambda x: x.get("top_provider", {}).get("max_completion_tokens") or 0, reverse=True)
                elif sort_by == "latency_low":
                    models.sort(key=total_price)
                self.logger.info(f"âœ… å…±æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹")
                for i, model in enumerate(models[:3]):
                    self.logger.debug(
                        f"ğŸ§  æ¨¡å‹ {i + 1}ï¼šID={model.get('id')}ï¼Œåç§°={model.get('name', 'æœªçŸ¥')}ï¼Œ"
                        f"è¾“å…¥={model.get('architecture', {}).get('input_modalities')}ï¼Œ"
                        f"è¾“å‡º={model.get('architecture', {}).get('output_modalities')}ï¼Œ"
                        f"ä»·æ ¼={total_price(model):.8f}"
                    )
                return models
        except Exception as e:
            self.logger.error(f"âŒ æœç´¢å¤±è´¥ï¼š{str(e)}")
            return []

    async def get_free_models(self, limit: Optional[int] = None, only_id: bool = True, random_pick: bool = False):
        """
        è·å–å…è´¹æ¨¡å‹åˆ—è¡¨ï¼ˆå¼‚æ­¥ï¼‰

        :param limit: è¿”å›æ¨¡å‹æ•°é‡ï¼ŒNoneä¸ºå…¨éƒ¨
        :param only_id: æ˜¯å¦åªè¿”å›æ¨¡å‹idï¼ŒTrueåªè¿”å›idï¼ŒFalseè¿”å›å®Œæ•´å­—å…¸
        :param random_pick: limitç”Ÿæ•ˆæ—¶ï¼Œæ˜¯å¦éšæœºé€‰å–æŒ‡å®šæ•°é‡ï¼Œé»˜è®¤Falseä¸ºé¡ºåºåˆ‡ç‰‡
        :return: æ¨¡å‹idåˆ—è¡¨æˆ–æ¨¡å‹å­—å…¸åˆ—è¡¨
        """
        models = await self.search_models(only_free=True)
        if limit is not None:
            if random_pick:
                models = random.sample(models, min(limit, len(models)))
            else:
                models = models[:limit]
        if only_id:
            return [m["id"] for m in models]
        return models

    def set_system_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®ç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰

        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        self.system_prompt = read_str_or_file(prompt) if prompt else None

    def set_assistant_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®åŠ©æ‰‹æç¤ºè¯ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰

        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        self.assistant_prompt = read_str_or_file(prompt) if prompt else None

    def set_primary_model(self, model: Optional[str]):
        """
        è®¾ç½®ä¸»æ¨¡å‹

        :param model: ä¸»æ¨¡å‹ID
        """
        self.primary_model = model
        self._current_model = model

    def _get_next_api_key(self):
        """
        è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„API Key
        :return: API Key
        """
        if self._random_key:
            return random.choice(self._api_keys)
        else:
            key = self._api_keys[self._api_key_index]
            self._api_key_index = (self._api_key_index + 1) % len(self._api_keys)
            return key

    async def get_key_status(self, api_key: Optional[str] = None) -> dict:
        """
        æŸ¥è¯¢æŒ‡å®šAPI Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰
        :param api_key: å¯é€‰ï¼ŒæŒ‡å®šè¦æŸ¥è¯¢çš„keyï¼Œä¸ä¼ åˆ™ç”¨å½“å‰key
        :return: é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯å­—å…¸
        """
        key = api_key or self._api_keys[self._api_key_index]
        url = f"{self.base_url}/auth/key"
        headers = {"Authorization": f"Bearer {key}"}
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.get(url, headers=headers)
                resp.raise_for_status()
                return resp.json().get("data", {})
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢API Keyé¢åº¦å¤±è´¥ï¼š{str(e)}")
            return {"error": str(e)}

    async def get_keys_status(self) -> List[dict]:
        """
        æŸ¥è¯¢æ‰€æœ‰API Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰
        :return: æ¯ä¸ªkeyçš„é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯åˆ—è¡¨
        """
        return [await self.get_key_status(api_key=k) for k in self._api_keys]


class OpenRouter:
    def __init__(
            self,
            api_key: Union[str, List[str]],
            random_key: bool = False,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            base_url: str = "https://openrouter.ai/api/v1",
            logger: Optional[logging.Logger] = None,
            system_prompt: Optional[str] = None,
            assistant_prompt: Optional[str] = None,
            async_mode: bool = False,
            console_log_level: str = "INFO",
            log_file_level: str = "WARNING",
            log_file: Optional[str] = None,
            not_print_welcome: bool = False
    ):
        """
        OpenRouter çš„ Python SDKï¼Œç”¨äºä¸ OpenRouter çš„ API è¿›è¡Œäº¤äº’

        :param api_key: OpenRouter çš„ API Keyï¼Œå¿…å¡«
        :param random_key: å¤škeyæ—¶æ˜¯å¦éšæœºé€‰æ‹©keyï¼ŒTrueä¸ºéšæœºï¼ŒFalseä¸ºé¡ºåº
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œå¿…å¡«
        :param backup_models: å¤‡ç”¨æ¨¡å‹IDåˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤å¼€å¯
        :param base_url: OpenRouter çš„ API åœ°å€ï¼Œé»˜è®¤ https://openrouter.ai/api/v1
        :param logger: å¯é€‰ï¼Œä¼ å…¥è‡ªå®šä¹‰æ—¥å¿—å¯¹è±¡
        :param system_prompt: å¯é€‰ï¼Œç³»ç»Ÿè§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param assistant_prompt: å¯é€‰ï¼ŒåŠ©æ‰‹è§’è‰²çš„é»˜è®¤æç¤ºï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param async_mode: Trueä¸ºå¼‚æ­¥ï¼ŒFalseä¸ºåŒæ­¥ï¼Œé»˜è®¤False
        :param console_log_level: æ§åˆ¶å°æ—¥å¿—çº§åˆ«
        :param log_file_level: æ–‡ä»¶æ—¥å¿—çº§åˆ«
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå½“log_fileä¸ºNoneæ—¶ï¼Œå°†ä¸ä¿å­˜æ—¥å¿—æ–‡ä»¶ï¼Œlog_file_levelå‚æ•°å°†æ— æ•ˆ
        :param not_print_welcome: æ˜¯å¦æ‰“å°æ¬¢è¿ä¿¡æ¯ï¼Œé»˜è®¤False
        """
        self.async_mode = async_mode
        if not async_mode:
            self._impl = OpenRouterSync(
                api_key=api_key,
                random_key=random_key,
                primary_model=primary_model,
                backup_models=backup_models,
                auto_fallback=auto_fallback,
                base_url=base_url,
                logger=logger,
                system_prompt=system_prompt,
                assistant_prompt=assistant_prompt,
                console_log_level=console_log_level,
                log_file_level=log_file_level,
                log_file=log_file
            )
        else:
            self._impl = OpenRouterAsync(
                api_key=api_key,
                random_key=random_key,
                primary_model=primary_model,
                backup_models=backup_models,
                auto_fallback=auto_fallback,
                base_url=base_url,
                logger=logger,
                system_prompt=system_prompt,
                assistant_prompt=assistant_prompt,
                console_log_level=console_log_level,
                log_file_level=log_file_level,
                log_file=log_file
            )
        if not not_print_welcome:
            print(f"ğŸš€ æ¬¢è¿ä½¿ç”¨ç”±å¾®ä¿¡å…¬ä¼—å·ï¼šXiaoqiangClub ç¼–å†™çš„ OpenRouter æµ‹è¯•å·¥å…·ï¼Œå·¥å…·ä»…ç”¨äºå­¦ä¹ æµ‹è¯•ï¼Œè¯·åˆæ³•ä½¿ç”¨ï¼")

    def chat(
            self,
            content: str,
            primary_model: Optional[str] = None,
            backup_models: Optional[List[str]] = None,
            auto_fallback: bool = True,
            fallback_max: int = 2,
            reset_user_model: bool = True,
            headers_extra: Optional[Dict[str, str]] = None,
            body_extra: Optional[Dict[str, Any]] = None
    ):
        """
        èŠå¤©æ¥å£ï¼Œä¸»æ¨¡å‹-å¤‡ç”¨æ¨¡å‹-å…è´¹æ¨¡å‹é¡ºåºå…œåº•

        :param content: ç”¨æˆ·çš„æ¶ˆæ¯å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        :param primary_model: ä¸»æ¨¡å‹ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼Œè‹¥ä¸ºNoneåˆ™ç”¨å®ä¾‹çš„primary_model
        :param backup_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œä¸»æ¨¡å‹å¤±æ•ˆæ—¶è‡ªåŠ¨å°è¯•
        :param auto_fallback: å¯ç”¨æœ€æ–°å…è´¹æ¨¡å‹ä½œä¸ºæœ€åçš„å®¹ç¾æ¨¡å‹ï¼Œé»˜è®¤True
        :param fallback_max: è‡ªåŠ¨ä½¿ç”¨å…è´¹æ¨¡å‹çš„å°è¯•æ¬¡æ•°
        :param reset_user_model: è‹¥ä½¿ç”¨å¤‡ç”¨æ¨¡å‹æˆåŠŸå“åº”ï¼Œä¸‹æ¬¡æ˜¯å¦æ¢å¤ç”¨æˆ·è®¾å®šçš„æ¨¡å‹
        :param headers_extra: å¯é€‰ï¼Œé¢å¤–çš„è¯·æ±‚å¤´ï¼ˆç”¨äº Referer æˆ– X-Titleï¼‰
        :param body_extra: å¯é€‰ï¼Œé¢å¤–çš„ body å‚æ•°
        :return: æ¨¡å‹å›å¤çš„å†…å®¹å­—ç¬¦ä¸²ï¼ˆåŒæ­¥ä¸ºstrï¼Œå¼‚æ­¥ä¸ºcoroutineï¼‰
        """
        return self._impl.chat(
            content=content,
            primary_model=primary_model,
            backup_models=backup_models,
            auto_fallback=auto_fallback,
            fallback_max=fallback_max,
            reset_user_model=reset_user_model,
            headers_extra=headers_extra,
            body_extra=body_extra
        )

    def set_primary_model(self, model: Optional[str]):
        """
        è®¾ç½®ä¸»æ¨¡å‹ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param model: ä¸»æ¨¡å‹ID
        """
        return self._impl.set_primary_model(model)

    def set_backup_models(self, models: List[str]):
        """
        è®¾ç½®å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param models: å¤‡ç”¨æ¨¡å‹IDåˆ—è¡¨
        """
        return self._impl.set_backup_models(models)

    def set_system_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        return self._impl.set_system_prompt(prompt)

    def set_assistant_prompt(self, prompt: Optional[str]):
        """
        è®¾ç½®åŠ©æ‰‹æç¤ºè¯ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param prompt: å­—ç¬¦ä¸²æˆ–æ–‡ä»¶è·¯å¾„
        """
        return self._impl.set_assistant_prompt(prompt)

    def search_models(
            self,
            sort_by: Literal[
                "newest",
                "pricing_low",
                "pricing_high",
                "context_high",
                "throughput_high",
                "latency_low"
            ] = "newest",
            only_free: bool = False,
            keyword: Optional[str] = None,
            input_modalities: Optional[List[str]] = None,
            output_modalities: Optional[List[str]] = None
    ):
        """
        æœç´¢å¹¶ç­›é€‰æ¨¡å‹åˆ—è¡¨ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param sort_by: æ’åºæ–¹å¼
        :param only_free: æ˜¯å¦åªç­›é€‰å…è´¹æ¨¡å‹
        :param keyword: å…³é”®è¯
        :param input_modalities: è¾“å…¥æ¨¡æ€
        :param output_modalities: è¾“å‡ºæ¨¡æ€
        :return: æ»¡è¶³æ¡ä»¶çš„æ¨¡å‹å­—å…¸åˆ—è¡¨ï¼ˆåŒæ­¥ä¸ºListï¼Œå¼‚æ­¥ä¸ºcoroutineï¼‰
        """
        return self._impl.search_models(
            sort_by=sort_by,
            only_free=only_free,
            keyword=keyword,
            input_modalities=input_modalities,
            output_modalities=output_modalities
        )

    def get_free_models(self, limit: Optional[int] = None, only_id: bool = True, random_pick: bool = False):
        """
        è·å–å…è´¹æ¨¡å‹åˆ—è¡¨ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰

        :param limit: è¿”å›æ¨¡å‹æ•°é‡ï¼ŒNoneä¸ºå…¨éƒ¨
        :param only_id: æ˜¯å¦åªè¿”å›æ¨¡å‹idï¼ŒTrueåªè¿”å›idï¼ŒFalseè¿”å›å®Œæ•´å­—å…¸
        :param random_pick: limitç”Ÿæ•ˆæ—¶ï¼Œæ˜¯å¦éšæœºé€‰å–æŒ‡å®šæ•°é‡ï¼Œé»˜è®¤Falseä¸ºé¡ºåºåˆ‡ç‰‡
        :return: æ¨¡å‹idåˆ—è¡¨æˆ–æ¨¡å‹å­—å…¸åˆ—è¡¨ï¼ˆåŒæ­¥ä¸ºlistï¼Œå¼‚æ­¥ä¸ºcoroutineï¼‰
        """
        return self._impl.get_free_models(limit=limit, only_id=only_id, random_pick=random_pick)

    def get_key_status(self, api_key: Optional[str] = None):
        """
        æŸ¥è¯¢æŒ‡å®šAPI Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰
        :param api_key: å¯é€‰ï¼ŒæŒ‡å®šè¦æŸ¥è¯¢çš„keyï¼Œä¸ä¼ åˆ™ç”¨å½“å‰key
        :return: é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯å­—å…¸ï¼ˆåŒæ­¥ä¸ºdictï¼Œå¼‚æ­¥ä¸ºcoroutineï¼‰
        """
        return self._impl.get_key_status(api_key=api_key)

    def get_keys_status(self):
        """
        æŸ¥è¯¢æ‰€æœ‰API Keyçš„é¢åº¦å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯ï¼ˆåŒæ­¥/å¼‚æ­¥ç»Ÿä¸€æ¥å£ï¼‰
        :return: æ¯ä¸ªkeyçš„é¢åº¦å’Œé€Ÿç‡ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒæ­¥ä¸ºlistï¼Œå¼‚æ­¥ä¸ºcoroutineï¼‰
        """
        return self._impl.get_keys_status()

    def __getattr__(self, item):
        return getattr(self._impl, item)

    def __dir__(self):
        # è®©ç¼–è¾‘å™¨èƒ½è‡ªåŠ¨æç¤ºOpenRouterSync/Asyncçš„æ‰€æœ‰æ–¹æ³•å’Œå±æ€§
        return list(set(dir(self._impl)) | set(super().__dir__()))
