#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import subprocess
import sys
import os
import json
from pathlib import Path

# Nomes de arquivo padr√£o intermedi√°rios e finais
DEFAULT_CORPUS_CONSOLIDATED = "corpus_consolidated.md"
DEFAULT_RAW_DOCS = "raw_docs.json"
DEFAULT_EMBEDDINGS = "embeddings.json" # Conforme sua solicita√ß√£o
DEFAULT_EVAL_RESULTS = "evaluation_results.json"
DEFAULT_QA_PROCESSED = "gartner_filtrado_processed.csv" # Sa√≠da do limpa_csv e entrada do evaluate
DEFAULT_MD_REPORT = "coverage_report.md"
DEFAULT_HTML_REPORT = "coverage_report.html"

# Configura√ß√£o da API
CONFIG_DIR = Path.home() / ".docs-cli"
CONFIG_FILE = CONFIG_DIR / "config.json"

def ensure_config_dir():
    """Garante que o diret√≥rio de configura√ß√£o existe."""
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)

def load_config():
    """Carrega a configura√ß√£o do arquivo config.json."""
    ensure_config_dir()
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, 'r') as f:
                return json.load(f)
        except json.JSONDecodeError:
            return {}
    return {}

def save_config(config):
    """Salva a configura√ß√£o no arquivo config.json."""
    ensure_config_dir()
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=4)

def run_script(command_args):
    """Executa um script (entry point) como um subprocesso."""
    # Espera que command_args[0] seja um execut√°vel no PATH (ex: 'docs-tc-extract-data')
    command = command_args
    print(f"üöÄ Executando: {' '.join(command)}")
    try:
        process = subprocess.run(command, capture_output=True, text=True, encoding=sys.stdout.encoding or 'latin-1', errors='replace')

        if process.stdout:
            print("Output:\n", process.stdout)
        if process.stderr:
            print("Errors:\n", process.stderr, file=sys.stderr)

        if process.returncode != 0:
            print(f"‚ùå Erro ao executar {' '.join(command)}. C√≥digo de sa√≠da: {process.returncode}", file=sys.stderr)
            return None # Indica falha para as fun√ß√µes run_step_or_exit

        print(f"‚úÖ Script {' '.join(command_args)} conclu√≠do com sucesso.")
        return process

    except FileNotFoundError:
        print(f"üö® Erro: Comando '{command[0]}' n√£o encontrado. Verifique se o docs-cli est√° instalado corretamente e se os scripts dos subcomandos (ex: {command[0]}.exe) foram criados na pasta Scripts do seu ambiente virtual e se o ambiente virtual est√° ativo.", file=sys.stderr)
        sys.exit(1) # Falha cr√≠tica se o comando do script n√£o for encontrado
    except Exception as e:
        print(f"üö® Exce√ß√£o ao executar o subprocesso {' '.join(command)}: {e}", file=sys.stderr)
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="Docs Toolkit CLI - Orquestrador de scripts de processamento de documenta√ß√£o.")
    
    # Adiciona argumento global para a chave da API
    parser.add_argument("--api", help="Chave da API do Google Gemini (opcional, pode ser fornecida via GOOGLE_API_KEY no .env)")
    
    subparsers = parser.add_subparsers(dest="command", help="Comandos dispon√≠veis", required=True)

    # --- Subparser para configura√ß√£o da API ---
    parser_api = subparsers.add_parser("api", help="Configura a chave da API do Google Gemini.")
    # Torna o argumento da chave opcional para permitir 'docs-cli api --show'
    parser_api.add_argument(
        "api_key",
        nargs="?",
        default=None,
        help="Chave da API do Google Gemini para ser salva globalmente."
    )
    parser_api.add_argument(
        "--show",
        action="store_true",
        help="Mostra a chave da API atual (parcialmente mascarada)."
    )

    # --- Subparser para merge_markdown.py ---
    parser_merge = subparsers.add_parser("merge", help="Consolida arquivos Markdown de um diret√≥rio.")
    parser_merge.add_argument("input_dir", help="Diret√≥rio de entrada contendo os arquivos .md.")
    parser_merge.add_argument("--output_file", default=DEFAULT_CORPUS_CONSOLIDATED,
                              help=f"Arquivo de sa√≠da para o Markdown consolidado (padr√£o: {DEFAULT_CORPUS_CONSOLIDATED}).")

    # --- Subparser para extract_data_from_markdown.py ---
    parser_extract = subparsers.add_parser("extract", help="Extrai dados estruturados do Markdown consolidado.")
    parser_extract.add_argument("--input_file", default=DEFAULT_CORPUS_CONSOLIDATED,
                                help=f"Arquivo Markdown consolidado de entrada (padr√£o: {DEFAULT_CORPUS_CONSOLIDATED}).")
    parser_extract.add_argument("--output_file", default=DEFAULT_RAW_DOCS,
                                help=f"Arquivo JSON de sa√≠da para os documentos brutos (padr√£o: {DEFAULT_RAW_DOCS}).")

    # --- Subparser para generate_embeddings.py ---
    parser_generate = subparsers.add_parser("generate_embeddings", help="Gera embeddings para os documentos processados.")
    parser_generate.add_argument("--input_file", default=DEFAULT_RAW_DOCS,
                                 help=f"Arquivo JSON de entrada com os documentos brutos (padr√£o: {DEFAULT_RAW_DOCS}).")
    parser_generate.add_argument("--output_file", default=DEFAULT_EMBEDDINGS,
                                 help=f"Arquivo JSON de sa√≠da para os embeddings (padr√£o: {DEFAULT_EMBEDDINGS}).")
    parser_generate.add_argument(
        "--provider",
        choices=["gemini", "deepinfra", "maritaca", "openai"],
        default="gemini",
        help="Provedor de embeddings: gemini (padr√£o), deepinfra, maritaca ou openai.",
    )
    parser_generate.add_argument(
        "--deepinfra-api-key",
        help="Chave da API DeepInfra/Maritaca (opcional, pode ser fornecida via .env)",
    )
    parser_generate.add_argument(
        "--openai-api-key",
        help="Chave da API OpenAI (opcional, pode ser fornecida via .env)",
    )

    # --- Subparser para limpa_csv.py ---
    parser_clean_csv = subparsers.add_parser("clean_csv", help="Limpa o arquivo CSV de Perguntas e Respostas.")
    parser_clean_csv.add_argument("input_file", help="Arquivo CSV de entrada a ser limpo (ex: qa-data.csv).")
    parser_clean_csv.add_argument("--output_file", default=DEFAULT_QA_PROCESSED,
                                  help=f"Arquivo CSV de sa√≠da limpo (padr√£o: {DEFAULT_QA_PROCESSED}).")
    parser_clean_csv.add_argument("--question_col", default="question",
                                  help="Nome da coluna de perguntas (padr√£o: question)")
    parser_clean_csv.add_argument("--response_col", default="response",
                                  help="Nome da coluna de respostas (padr√£o: response)")
    parser_clean_csv.add_argument("--encoding", default="utf-8",
                                  help="Encoding do arquivo CSV (padr√£o: utf-8)")
    parser_clean_csv.add_argument("--min_length", type=int, default=10,
                                  help="Tamanho m√≠nimo para respostas v√°lidas (padr√£o: 10)")
    parser_clean_csv.add_argument("--no_clean_text", action="store_true",
                                  help="N√£o limpar o texto das respostas")
    parser_clean_csv.add_argument("--invalid_patterns", nargs="+",
                                  help="Lista de padr√µes inv√°lidos para remover")

    # --- Subparser para evaluate_coverage.py ---
    parser_evaluate = subparsers.add_parser("evaluate", help="Avalia a cobertura da documenta√ß√£o.")
    parser_evaluate.add_argument("qa_file",
                                 help="Caminho para o arquivo CSV limpo com perguntas e respostas.")
    parser_evaluate.add_argument("embeddings_file",
                                 help="Caminho para o arquivo JSON com chunks processados e embeddings.")
    parser_evaluate.add_argument("-k", "--top_k", type=int, default=5,
                                 help="N√∫mero de chunks mais relevantes a considerar (padr√£o: 5).")
    parser_evaluate.add_argument("-o", "--output", default=DEFAULT_EVAL_RESULTS,
                                 help=f"Arquivo de sa√≠da para os resultados da avalia√ß√£o (padr√£o: {DEFAULT_EVAL_RESULTS}).")

    # --- Subparser para generate_report.py (Markdown) ---
    parser_report_md = subparsers.add_parser("report_md", help="Gera o relat√≥rio de cobertura em Markdown.")
    parser_report_md.add_argument("--input_file", default=DEFAULT_EVAL_RESULTS,
                                  help=f"Arquivo JSON de entrada com os resultados da avalia√ß√£o (padr√£o: {DEFAULT_EVAL_RESULTS}).")
    parser_report_md.add_argument("--output_file", default=DEFAULT_MD_REPORT,
                                  help=f"Arquivo Markdown de sa√≠da para o relat√≥rio (padr√£o: {DEFAULT_MD_REPORT}).")
    parser_report_md.add_argument("--top_k_chunks", type=int, default=5,
                                  help="Valor de top_k_chunks usado na avalia√ß√£o (para consist√™ncia do relat√≥rio, padr√£o: 5).")

    # --- Subparser para generate_report_html.py (HTML) ---
    parser_report_html = subparsers.add_parser("report_html", help="Gera o relat√≥rio de cobertura em HTML.")
    parser_report_html.add_argument("--input_file", default=DEFAULT_EVAL_RESULTS,
                                    help=f"Arquivo JSON de entrada com os resultados da avalia√ß√£o (padr√£o: {DEFAULT_EVAL_RESULTS}).")
    parser_report_html.add_argument("--output_file", default=DEFAULT_HTML_REPORT,
                                    help=f"Arquivo HTML de sa√≠da para o relat√≥rio (padr√£o: {DEFAULT_HTML_REPORT}).")
    parser_report_html.add_argument("--top_k_chunks", type=int, default=5,
                                    help="Valor de top_k_chunks usado na avalia√ß√£o (para consist√™ncia do relat√≥rio, padr√£o: 5).")

    # --- Subparser para o fluxo completo ---
    parser_full_flow = subparsers.add_parser("full_flow", help="Executa o fluxo completo de processamento e avalia√ß√£o.")
    parser_full_flow.add_argument("doc_input_dir", help="Diret√≥rio de entrada dos arquivos .md originais.")
    parser_full_flow.add_argument("qa_input_file", help="Arquivo CSV de entrada original com Perguntas e Respostas (ex: qa-data.csv).")
    parser_full_flow.add_argument("--eval_top_k", type=int, default=5, help="Top K para a etapa de avalia√ß√£o (padr√£o: 5).")
    parser_full_flow.add_argument("--corpus_file", default=DEFAULT_CORPUS_CONSOLIDATED)
    parser_full_flow.add_argument("--raw_docs_file", default=DEFAULT_RAW_DOCS)
    parser_full_flow.add_argument("--embeddings_file", default=DEFAULT_EMBEDDINGS)
    parser_full_flow.add_argument("--cleaned_qa_file", default=DEFAULT_QA_PROCESSED)
    parser_full_flow.add_argument("--eval_results_file", default=DEFAULT_EVAL_RESULTS)
    parser_full_flow.add_argument("--md_report_file", default=DEFAULT_MD_REPORT)
    parser_full_flow.add_argument("--html_report_file", default=DEFAULT_HTML_REPORT)


    # --- Subparser para fluxo customizado ---
    parser_custom_flow = subparsers.add_parser("custom_flow", help="Executa uma sequ√™ncia customizada de scripts.")
    parser_custom_flow.add_argument("steps", nargs='+', choices=['merge', 'extract', 'generate_embeddings', 'clean_csv', 'evaluate', 'report_md', 'report_html'],
                                    help="Sequ√™ncia de etapas a serem executadas (ex: merge extract generate_embeddings).")

    args = parser.parse_args()

    # Carrega a configura√ß√£o
    config = load_config()

    # Se o comando for 'api', lida com a configura√ß√£o da API
    if args.command == "api":
        if args.show:
            if "api_key" in config:
                masked_key = config["api_key"][:8] + "..." + config["api_key"][-4:]
                print(f"Chave da API atual: {masked_key}")
            else:
                print("Nenhuma chave da API configurada.")
        elif args.api_key:
            config["api_key"] = args.api_key
            save_config(config)
            print("‚úÖ Chave da API configurada com sucesso!")
        else:
            print("√â necess√°rio fornecer a chave da API ou usar --show para exibir a chave atual.")
            parser_api.print_help()
        return

    # Usa a chave da API da configura√ß√£o se n√£o for fornecida via linha de comando
    api_key = args.api or config.get("api_key")

    # Nomes dos entry points (conforme definido em setup.py)
    SCRIPT_MAP = {
        "merge": "docs-tc-merge-markdown",
        "extract": "docs-tc-extract-data",
        "generate_embeddings": "docs-tc-generate-embeddings",
        "clean_csv": "docs-tc-clean-csv",
        "evaluate": "docs-tc-evaluate-coverage",
        "report_md": "docs-tc-generate-report-md",
        "report_html": "docs-tc-generate-report-html"
    }

    if args.command == "merge":
        run_script([SCRIPT_MAP["merge"], args.input_dir, args.output_file])
    elif args.command == "extract":
        run_script([SCRIPT_MAP["extract"], args.input_file, args.output_file])
    elif args.command == "generate_embeddings":
        command_args = [SCRIPT_MAP["generate_embeddings"], args.input_file, args.output_file]
        if api_key:
            command_args.extend(["--gemini-api-key", api_key])
        if hasattr(args, "provider") and args.provider:
            command_args.extend(["--provider", args.provider])
        if hasattr(args, "deepinfra_api_key") and args.deepinfra_api_key:
            command_args.extend(["--deepinfra-api-key", args.deepinfra_api_key])
        if hasattr(args, "openai_api_key") and args.openai_api_key:
            command_args.extend(["--openai-api-key", args.openai_api_key])
        run_script(command_args)
    elif args.command == "clean_csv":
        run_script([SCRIPT_MAP["clean_csv"], args.input_file, args.output_file])
    elif args.command == "evaluate":
        run_script([
            SCRIPT_MAP["evaluate"],
            args.qa_file,
            args.embeddings_file,
            "-k", str(args.top_k),
            "-o", args.output
        ])
    elif args.command == "report_md":
        run_script([
            SCRIPT_MAP["report_md"],
            args.input_file,
            args.output_file,
            str(args.top_k_chunks)
        ])
    elif args.command == "report_html":
        run_script([
            SCRIPT_MAP["report_html"],
            args.input_file,
            args.output_file,
            str(args.top_k_chunks)
        ])
    elif args.command == "full_flow":
        print("üöÄ Iniciando fluxo completo...")
        def run_step_or_exit(step_command_args):
            if run_script(step_command_args) is None:
                print(f"‚ùå Etapa {step_command_args[0]} falhou. Abortando fluxo completo.")
                sys.exit(1)

        run_step_or_exit([SCRIPT_MAP["merge"], args.doc_input_dir, args.corpus_file])
        run_step_or_exit([SCRIPT_MAP["clean_csv"], args.qa_input_file, args.cleaned_qa_file])
        run_step_or_exit([SCRIPT_MAP["extract"], args.corpus_file, args.raw_docs_file])
        
        # Adiciona a chave da API ao comando generate_embeddings se fornecida
        generate_embeddings_args = [SCRIPT_MAP["generate_embeddings"], args.raw_docs_file, args.embeddings_file]
        if api_key:
            generate_embeddings_args.extend(["--gemini-api-key", api_key])
        run_step_or_exit(generate_embeddings_args)
        
        run_step_or_exit([
            SCRIPT_MAP["evaluate"],
            args.cleaned_qa_file,
            args.embeddings_file,
            "-k", str(args.eval_top_k),
            "-o", args.eval_results_file
        ])
        run_step_or_exit([
            SCRIPT_MAP["report_md"],
            args.eval_results_file,
            args.md_report_file,
            str(args.eval_top_k)
        ])
        run_step_or_exit([
            SCRIPT_MAP["report_html"],
            args.eval_results_file,
            args.html_report_file,
            str(args.eval_top_k)
        ])
        print("üéâ Fluxo completo conclu√≠do!")

    elif args.command == "custom_flow":
        print(f"‚ñ∂Ô∏è Iniciando fluxo customizado: {' -> '.join(args.steps)}")
        current_corpus_file = DEFAULT_CORPUS_CONSOLIDATED
        current_raw_docs_file = DEFAULT_RAW_DOCS
        current_embeddings_file = DEFAULT_EMBEDDINGS
        current_cleaned_qa_file = DEFAULT_QA_PROCESSED
        current_eval_results_file = DEFAULT_EVAL_RESULTS
        default_eval_top_k = 5

        def run_custom_step_or_exit(step_command_args):
            if run_script(step_command_args) is None:
                print(f"‚ùå Etapa {step_command_args[0]} falhou. Abortando fluxo customizado.")
                sys.exit(1)

        for step in args.steps:
            print(f"\n--- Executando etapa: {step} ---")
            if step == "merge":
                doc_input_dir = input("Por favor, informe o diret√≥rio de entrada para 'merge' (pressione Enter para usar 'docs' como padr√£o): ") or "docs"
                run_custom_step_or_exit([SCRIPT_MAP["merge"], doc_input_dir, current_corpus_file])
            elif step == "extract":
                 if not os.path.exists(current_corpus_file):
                     current_corpus_file = input(f"Arquivo Corpus ({current_corpus_file}) n√£o encontrado. Informe o caminho correto: ")
                 run_custom_step_or_exit([SCRIPT_MAP["extract"], current_corpus_file, current_raw_docs_file])
            elif step == "generate_embeddings":
                if not os.path.exists(current_raw_docs_file):
                     current_raw_docs_file = input(f"Arquivo Raw Docs ({current_raw_docs_file}) n√£o encontrado. Informe o caminho correto: ")
                command_args = [SCRIPT_MAP["generate_embeddings"], current_raw_docs_file, current_embeddings_file]
                if api_key:
                    command_args.extend(["--gemini-api-key", api_key])
                if hasattr(args, "provider") and args.provider:
                    command_args.extend(["--provider", args.provider])
                if hasattr(args, "deepinfra_api_key") and args.deepinfra_api_key:
                    command_args.extend(["--deepinfra-api-key", args.deepinfra_api_key])
                if hasattr(args, "openai_api_key") and args.openai_api_key:
                    command_args.extend(["--openai-api-key", args.openai_api_key])
                run_custom_step_or_exit(command_args)
            elif step == "clean_csv":
                qa_input_file = input("Por favor, informe o arquivo CSV de Q&A original para 'clean_csv' (pressione Enter para usar 'qa-data.csv'): ") or "qa-data.csv"
                command_args = [SCRIPT_MAP["clean_csv"], qa_input_file]
                
                # Adicionar argumentos opcionais se fornecidos
                if hasattr(args, "output_file") and args.output_file:
                    command_args.extend(["--output_file", args.output_file])
                if hasattr(args, "question_col") and args.question_col:
                    command_args.extend(["--question_col", args.question_col])
                if hasattr(args, "response_col") and args.response_col:
                    command_args.extend(["--response_col", args.response_col])
                if hasattr(args, "encoding") and args.encoding:
                    command_args.extend(["--encoding", args.encoding])
                if hasattr(args, "min_length") and args.min_length:
                    command_args.extend(["--min_length", str(args.min_length)])
                if hasattr(args, "no_clean_text") and args.no_clean_text:
                    command_args.append("--no_clean_text")
                if hasattr(args, "invalid_patterns") and args.invalid_patterns:
                    command_args.extend(["--invalid_patterns"] + args.invalid_patterns)
                
                run_custom_step_or_exit(command_args)
            elif step == "evaluate":
                if not os.path.exists(current_cleaned_qa_file):
                     current_cleaned_qa_file = input(f"Arquivo QA limpo ({current_cleaned_qa_file}) n√£o encontrado. Informe o caminho correto: ")
                if not os.path.exists(current_embeddings_file):
                     current_embeddings_file = input(f"Arquivo de Embeddings ({current_embeddings_file}) n√£o encontrado. Informe o caminho correto: ")
                eval_k_str = input(f"Informe o top_k para evaluate (pressione Enter para usar {default_eval_top_k}): ") or str(default_eval_top_k)
                run_custom_step_or_exit([
                    SCRIPT_MAP["evaluate"],
                    current_cleaned_qa_file, current_embeddings_file,
                    "-k", eval_k_str,
                    "-o", current_eval_results_file
                ])
            elif step == "report_md":
                 if not os.path.exists(current_eval_results_file):
                     current_eval_results_file = input(f"Arquivo de Resultados da Avalia√ß√£o ({current_eval_results_file}) n√£o encontrado. Informe o caminho correto: ")
                 report_k_str = input(f"Informe o top_k_chunks para report_md (pressione Enter para usar {default_eval_top_k}, deve coincidir com o usado na avalia√ß√£o): ") or str(default_eval_top_k)
                 run_custom_step_or_exit([
                    SCRIPT_MAP["report_md"], current_eval_results_file, DEFAULT_MD_REPORT, report_k_str
                ])
            elif step == "report_html":
                if not os.path.exists(current_eval_results_file):
                     current_eval_results_file = input(f"Arquivo de Resultados da Avalia√ß√£o ({current_eval_results_file}) n√£o encontrado. Informe o caminho correto: ")
                report_k_str = input(f"Informe o top_k_chunks para report_html (pressione Enter para usar {default_eval_top_k}, deve coincidir com o usado na avalia√ß√£o): ") or str(default_eval_top_k)
                run_custom_step_or_exit([
                    SCRIPT_MAP["report_html"], current_eval_results_file, DEFAULT_HTML_REPORT, report_k_str
                ])
        print("‚èπÔ∏è Fluxo customizado conclu√≠do.")

if __name__ == "__main__":
    main()