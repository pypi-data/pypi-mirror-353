"""Aggregated Transform entity."""

import itertools
from collections import namedtuple
from typing import List, Optional, Tuple, Union

from pyspark.sql import DataFrame
from pyspark.sql.functions import col, expr, when

from butterfree.transform.transformations.transform_component import TransformComponent
from butterfree.transform.utils.function import Function
from butterfree.transform.utils.window_spec import Window


class AggregatedTransform(TransformComponent):
    """Specifies an aggregation.

    This transformation needs to be used within an AggregatedFeatureSet. Unlike the
    other transformations, this class won't have a transform method implemented.

    The idea behing aggregating is that, in spark, we should execute all aggregation
    functions after a single groupby. So an AggregateFeatureSet will have many Features
    with AggregatedTransform. If each one of them needs to apply a groupby.agg(), then
    we must join all the results in the end, making this computation extremely slow.

    Now, the AggregateFeatureSet will collect all Features' AggregatedTransform
    definitions and run, at once, a groupby.agg(*aggregations).

    This class helps defining on a feature, which aggregation function will be applied
    to build a new aggregated column. Allowed aggregations are registered under the
     allowed_aggregations property.

    Attributes:
        functions: namedtuple with aggregation function and data type.
        filter_expression: sql boolean expression to be used inside agg function.
            The filter expression can be used to aggregate some column only with
            records that obey certain condition. Has the same behaviour of the
            following SQL expression: `agg(case when filter_expression then col end)`

    Example:
        >>> from butterfree.transform.transformations import AggregatedTransform
        >>> from butterfree.transform.features import Feature
        >>> from butterfree.constants import DataType
        >>> from butterfree.transform.utils import Function
        >>> import pyspark.sql.functions as F
        >>> feature = Feature(
        ...     name="feature",
        ...     description="aggregated transform",
        ...     transformation=AggregatedTransform(
        ...         functions=[
        ...                    Function(F.avg, DataType.DOUBLE),
        ...                    Function(F.stddev_pop, DataType.DOUBLE)],
        ...     ),
        ...     from_column="somenumber",
        ...)
        >>> feature.get_output_columns()
        ['feature__avg', 'feature__stddev_pop']
        >>> feature.transform(anydf)
        NotImplementedError: ...
    """

    def __init__(
        self, functions: List[Function], filter_expression: Optional[str] = None
    ):
        super(AggregatedTransform, self).__init__()
        self.functions = functions
        self.filter_expression = filter_expression

    @property
    def aggregations(self) -> List[Tuple]:
        """Aggregated spark columns."""
        column_name = self._parent.from_column or self._parent.name

        # if transform has a filter expression apply inside agg function
        # if not, use just the target column name inside agg function
        expression = (
            when(expr(self.filter_expression), col(column_name))
            if self.filter_expression
            else column_name
        )
        Function = namedtuple("Function", ["function", "data_type"])

        return [
            Function(
                f.func(expression),
                f.data_type.spark,
            )
            for f in self.functions
        ]

    def build_column_name_by_transformation(self, function: object) -> str:
        """Get the name of the output column based on the function present in the transformation.

        Args:
            function: function to be used in the transformation.

        Returns:
            str: output column name based on the function present in the transformation.
            This name will be used to build the FINAL column name. It will be formatted with
            the pivot value and window if they are present.
        """  # noqa: E501

        feature_base_name = self._parent.name

        if not hasattr(function, "__name__"):
            raise AttributeError(
                f"""Anonymous functions are not supported on AggregatedTransform.
                    Check feature {feature_base_name} transforms.
                """
            )

        function_name = str(function.__name__).lower()
        return f"{feature_base_name}__{function_name}"

    @property
    def output_columns(self) -> List[str]:
        """Columns names generated by the transformation."""
        return [
            self.build_column_name_by_transformation(function.func)
            for function in self.functions
        ]

    def transform(self, dataframe: DataFrame) -> DataFrame:
        """(NotImplemented) Performs a transformation to the feature pipeline.

        For the AggregatedTransform, the transformation won't be applied without
        using an AggregatedFeatureSet.

        Args:
            dataframe: input dataframe.

        Raises:
            NotImplementedError.
        """
        raise NotImplementedError(
            "AggregatedTransform won't be used outside an AggregatedFeatureSet, "
            "meaning the responsibility of aggregating and apply the transformation is "
            "now over the FeatureSet component. This should optimize the ETL process."
        )

    def build_final_column_name(
        self,
        column_name_by_transformation: str,
        pivot_value: Optional[Union[float, str]] = None,
        window: Optional[Window] = None,
    ) -> str:
        """
        Build the final column name based on the feature column, pivot value and window.

        REQUIRES the usage of the #build_column_name_by_transformation method.

        Args:
            column_name_by_transformation: name of the feature column.
            pivot_value: value of the pivot.
            window: window of the feature.

        Returns:
            str: final column name.
        """  # noqa: E501
        base_name = column_name_by_transformation
        if pivot_value is not None:
            base_name = f"{pivot_value}_{base_name}"
        if window is not None:
            base_name = f"{base_name}_{window.get_name()}"

        return base_name

    def get_names_and_types(
        self,
        pivot_values: Optional[List[Union[bool, float, int, str]]] = None,
        windows: Optional[List[Window]] = None,
    ) -> List[Tuple[str, str]]:
        """Get the names and types generated by the transformation."""
        pivot_values = pivot_values or [None]
        windows = windows or [None]
        cartesian_product = itertools.product(pivot_values, self.functions, windows)

        names_and_types = []
        for pivot, function, window in cartesian_product:
            column_name_by_transformation = self.build_column_name_by_transformation(
                function.func
            )

            final_name = self.build_final_column_name(
                column_name_by_transformation=column_name_by_transformation,
                pivot_value=pivot,
                window=window,
            )
            data_type = function.data_type.name
            names_and_types.append((final_name, data_type))

        return names_and_types
