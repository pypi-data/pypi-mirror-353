# ğŸš€ OTEL-Lean-Tracer

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![OpenTelemetry](https://img.shields.io/badge/OpenTelemetry-1.25+-green.svg)](https://opentelemetry.io)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**ğŸ¯ Zero-config OpenTelemetry tracing with Lean Production KPIs for LLM/Agent applications**

OTEL-Lean-Tracer seamlessly adds "Lean Production 7 Wastes" metrics to your LLM and Agent execution traces, giving you real-time visibility into bottlenecks and waste in your AI applications through beautiful Grafana dashboards.

## âœ¨ Why OTEL-Lean-Tracer?

### ğŸ” **Instant Visibility**
- **Zero configuration** - Just add one line and start seeing your AI application's performance
- **Real-time bottleneck detection** - Spot queue delays, context waste, and retry loops instantly
- **Beautiful Grafana dashboards** - Pre-built visualizations for immediate insights

### ğŸ“Š **Lean Production Metrics**
Track the 7 wastes of Lean Production applied to LLM applications:
- ğŸ•’ **Queue Time** - Time spent waiting for API responses
- ğŸ”„ **Retry Waste** - Failed generation attempts and retries
- ğŸ“ˆ **Context Waste** - Unused tokens in prompts
- ğŸ’° **Cost Tracking** - Real-time API cost monitoring (generation + evaluation)
- âš¡ **Processing Delays** - Identify slow components
- ğŸ¯ **Quality Issues** - Track acceptance rates and evaluation scores
- ğŸšš **Transport Overhead** - Network and serialization costs

### ğŸ¯ **GenAgent Evaluation Tracking**
Advanced quality monitoring for agents-sdk-models:
- ğŸ“Š **Evaluation Scores** - Track quality scores (0-100) vs thresholds
- ğŸ”„ **Retry Analysis** - Monitor threshold-based retry patterns
- ğŸ’¡ **Improvement Insights** - Capture AI-generated improvement suggestions
- ğŸ’° **Separate Cost Tracking** - Split generation and evaluation costs
- ğŸ“ˆ **Quality Trends** - Visualize quality progression over time
- ğŸ› **Multi-Step Monitoring** - Track quality across Flow pipelines

### ğŸ›  **Developer Friendly**
- **OpenTelemetry compatible** - Works with your existing observability stack
- **Agent SDK integration** - Built for modern LLM frameworks
- **Grafana + Tempo ready** - Enterprise-grade trace storage and visualization

## ğŸš€ Quick Start

### Installation

```bash
# Install via uv (recommended)
uv add otel-lean-tracer

# Or via pip
pip install otel-lean-tracer
```

### âš¡ Super Simple Setup

Add just **one line** to your LLM application:

```python
from otel_lean_tracer import instrument_lean

# Enable lean tracing (that's it!)
instrument_lean()

# Your existing code works unchanged
from agents_sdk_models import create_simple_gen_agent

agent = create_simple_gen_agent(
    name="story_generator",
    instructions="Generate creative stories",
    model="gpt-4o-mini",
    threshold=75  # Quality threshold for evaluation
)

result = await agent.run("Tell me a story about a robot")
```

### ğŸ“Š Instant Dashboard

Your traces automatically include:

**Core Attributes (OTEL Semantic Conventions):**
- `otel.lean.gen.attempt` - Generation attempt number (1, 2, 3...)
- `otel.lean.gen.accepted` - Whether output was accepted
- `llm.evaluation.score` - Quality evaluation score (0-100)
- `llm.evaluation.threshold` - Quality threshold setting
- `llm.evaluation.passed` - Whether evaluation passed
- `otel.lean.retry.reason` - Why retry was needed
- `llm.context.bytes_total` - Total prompt size
- `llm.context.bytes_useful` - Actually referenced content  
- `otel.lean.queue_age_ms` - Time waiting in queues
- `llm.usage.cost_usd` - Generation API costs
- `llm.evaluation.cost_usd` - Evaluation API costs

**Optional Attributes (when available):**
- `model_scale_b` - Model scale in billions of parameters
- `retry_energy_kwh` - Estimated energy consumption for retries

## ğŸ› Supported Environments

| Environment | Status | Version |
|-------------|--------|---------|
| **Python** | âœ… | 3.11+ |
| **OpenTelemetry** | âœ… | 1.25+ |
| **Agents SDK** | âœ… | 0.22+ |
| **Grafana Tempo** | âœ… | Latest |
| **OpenAI** | âœ… | All models |
| **Anthropic** | âœ… | Claude series |
| **Ollama** | âœ… | Local models |

## ğŸ“ˆ Advanced Configuration

### Custom Exporters

```python
from otel_lean_tracer import instrument_lean
from otel_lean_tracer.exporters import create_tempo_exporter

# Configure Tempo backend
exporter = create_tempo_exporter(
    endpoint="http://tempo:3200",
    headers={"Authorization": "Bearer your-token"}
)

instrument_lean(exporter=exporter)
```

### Evaluation Data Tracking

```python
from otel_lean_tracer.attributes import LeanAttributes

# Evaluation data is automatically captured from GenAgent:
# - Quality scores and thresholds
# - Improvement suggestions
# - Retry reasons and patterns
# - Separate cost tracking for generation vs evaluation
```

### Flow Metrics

```python
from otel_lean_tracer.mixins import FlowInstrumentationMixin

class MyAgent(FlowInstrumentationMixin):
    async def process(self, input_data):
        # Automatically measures queue_age_ms and evaluation metrics
        return await self.instrumented_call(input_data)
```

## ğŸ¯ Real-World Benefits

### ğŸ’¡ **Before OTEL-Lean-Tracer**
- âŒ No visibility into LLM application performance
- âŒ Manual cost tracking and estimation
- âŒ Difficult to spot bottlenecks and waste
- âŒ No quality monitoring or evaluation insights
- âŒ Complex observability setup required

### âœ¨ **After OTEL-Lean-Tracer**
- âœ… **Zero-config** observability for LLM apps
- âœ… **Automatic cost tracking** with real-time dashboards
- âœ… **Instant bottleneck detection** using Lean metrics
- âœ… **Quality evaluation monitoring** with improvement insights
- âœ… **Beautiful Grafana dashboards** out of the box

## ğŸ”§ Integration Examples

### With OpenAI Agents SDK + Evaluation

```python
from agents_sdk_models import create_simple_gen_agent, Flow
from otel_lean_tracer import instrument_lean

instrument_lean()

# Create agents with quality thresholds
classifier = create_simple_gen_agent(
    name="intent_classifier",
    instructions="Classify user intent accurately",
    model="gpt-4o-mini",
    threshold=80  # Higher threshold for classification
)

responder = create_simple_gen_agent(
    name="response_generator", 
    instructions="Generate helpful responses",
    model="gpt-4o",
    threshold=75  # Quality threshold for responses
)

# Create flow - evaluation data automatically traced!
flow = Flow(steps=[classifier, responder])
result = await flow.run("Help me plan a vacation")

# Dashboard shows:
# - Quality scores for each step
# - Cost breakdown (generation vs evaluation)
# - Retry patterns and improvement suggestions
# - Multi-step quality progression
```

### With Custom Evaluation Systems

```python
from otel_lean_tracer.processors import LeanTraceProcessor
from opentelemetry import trace

# Custom evaluation data is automatically detected
custom_result = {
    "content": "Generated response",
    "evaluation": {
        "score": 85.5,
        "threshold": 75.0,
        "passed": True,
        "improvements": ["Add more examples", "Improve clarity"]
    }
}

# Lean processor extracts evaluation data automatically
processor = LeanTraceProcessor()
trace.get_tracer_provider().add_span_processor(processor)
```

## ğŸ“Š Grafana Dashboard Setup

Pre-built dashboards included in `/examples/grafana/`:

1. **Lean Production Metrics** - Overview of waste and efficiency
2. **Quality Analysis** - Evaluation scores, trends, and improvement tracking
3. **Cost Analysis** - Real-time API cost breakdown (generation + evaluation)
4. **Performance Monitoring** - Latency and throughput metrics
5. **Error Analysis** - Retry patterns and failure modes

Import `lean-tracer-dashboard.json` into your Grafana instance for instant visualizations!

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your LLM App  â”‚â”€â”€â”€â–¶â”‚ OTEL-Lean-Tracer â”‚â”€â”€â”€â–¶â”‚ Grafana + Tempo â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Lean Metrics â”‚
                       â”‚ â€¢ Queue Time â”‚
                       â”‚ â€¢ Retry Wasteâ”‚
                       â”‚ â€¢ Context    â”‚
                       â”‚ â€¢ Quality    â”‚
                       â”‚ â€¢ Cost       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤ Contributing

We love contributions! Check out our [Contributing Guide](CONTRIBUTING.md) to get started.

### Development Setup

```bash
# Clone the repository
git clone https://github.com/your-org/otel-lean-tracer.git
cd otel-lean-tracer

# Install in development mode
uv pip install -e .

# Install dev dependencies
uv add --group dev pytest pytest-cov pytest-asyncio

# Run tests
pytest
```

## ğŸ“š Documentation

- ğŸ“– [Complete Documentation](docs/)
- ğŸ— [Architecture Guide](docs/architecture.md)
- ğŸ¯ [Use Cases](docs/usecase_spec.md)
- ğŸ”§ [Function Reference](docs/function_spec.md)
- ğŸ“Š [Grafana Setup Guide](examples/grafana/dashboard-setup-guide.md)
- ğŸ“ [Tutorial with Evaluation Examples](docs/tutorial.md)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenTelemetry community for the amazing observability framework
- Grafana team for beautiful visualization tools
- Lean Production methodology for waste reduction principles
- agents-sdk-models for advanced LLM agent capabilities

---

**Made with â¤ï¸ for the LLM/Agent developer community**

*Start tracking your AI application's efficiency AND quality in under 60 seconds! ğŸš€*