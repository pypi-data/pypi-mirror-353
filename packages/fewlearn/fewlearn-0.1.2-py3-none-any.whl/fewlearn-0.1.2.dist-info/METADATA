Metadata-Version: 2.4
Name: fewlearn
Version: 0.1.2
Summary: A Python module for few-shot learning with pretrained models
Home-page: https://github.com/AdityaSharma2485/fewlearn
Author: Aditya Sharma
Author-email: adityasharma.2485@gmail.com
License: MIT License
        
        Copyright (c) 2025 Aditya Sharma
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://github.com/AdityaSharma2485/fewlearn
Project-URL: Bug Tracker, https://github.com/AdityaSharma2485/fewlearn/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Development Status :: 4 - Beta
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Dynamic: author
Dynamic: author-email
Dynamic: home-page
Dynamic: requires-python

# FewLearn

A Python module for few-shot learning with pretrained models, enabling efficient model evaluation and comparison through prototypical networks.

## Overview

FewLearn provides tools for comparing and evaluating multiple pretrained models in parallel using few-shot learning techniques like Prototypical Networks. The framework allows you to:

- Efficiently evaluate multiple backbone models in parallel
- Analyze model performance across various metrics
- Visualize embeddings, confusion matrices, and model comparisons
- Export models for deployment

## Key Components

- **MINDS**: Main framework for coordinating few-shot learning evaluations
- **Prototypical Networks**: Implementation of the few-shot learning algorithm
- **Backbones**: Support for various pre-trained model architectures 
- **Evaluation**: Protocols and metrics for comparing model performance
- **Visualization**: Tools for visualizing embeddings and results

## Installation

```bash
# Basic installation
pip install fewlearn

# With optional dependencies
pip install fewlearn[dev,easyfsl,demo]
```

## Quick Start

```python
import torch
from torchvision.datasets import Omniglot
from torchvision import transforms
from fewlearn import MINDS, PrototypicalNetworks, Evaluator, EpisodicProtocol

# 1. Initialize the MINDS framework
minds = MINDS()

# 2. Add different backbone models to evaluate
minds.add_model("resnet18", PrototypicalNetworks(backbone="resnet18"))
minds.add_model("mobilenet_v2", PrototypicalNetworks(backbone="mobilenet_v2"))
minds.add_model("efficientnet_b0", PrototypicalNetworks(backbone="efficientnet_b0"))

# 3. Prepare dataset
transform = transforms.Compose([
    transforms.Resize((84, 84)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

dataset = Omniglot(root='./data', download=True, transform=transform)

# 4. Create an evaluation protocol
protocol = EpisodicProtocol(n_way=5, n_shot=1, n_query=15, episodes=100)

# 5. Create an evaluator
evaluator = Evaluator(
    protocol=protocol,
    metrics=["accuracy", "f1"],
    parallel=True  # Enable parallel evaluation
)

# 6. Run the evaluation
results = evaluator.evaluate(
    models={name: model for name, model in minds.models.items()},
    dataset=dataset
)

# 7. Get a summary of the results
summary = evaluator.summary()
print(summary)

# 8. Get the best model
best_model_name, best_model = minds.get_best_model(results)
print(f"Best model: {best_model_name}")

# 9. Export the best model for deployment
export_path = minds.export_model(best_model_name, format="onnx")
print(f"Model exported to: {export_path}")
```

## Advanced Features

### Custom Backbone Models

```python
from torch import nn
from fewlearn.backbones import register_backbone

# Define a custom backbone
def my_custom_backbone(pretrained=True):
    # Create your custom model here
    model = nn.Sequential(
        # ...layers
    )
    return model

# Register the backbone
register_backbone("my_custom_model", my_custom_backbone)

# Use it in a few-shot model
model = PrototypicalNetworks(backbone="my_custom_model")
```

### Visualization

```python
from fewlearn.visualization import (
    plot_prototype_embeddings,
    plot_confusion_matrix,
    plot_performance_comparison
)

# Plot model performance comparison
fig = plot_performance_comparison(results)
fig.savefig("model_comparison.png")

# Plot embedding space visualizations
fig = plot_prototype_embeddings(
    support_embeddings,
    support_labels,
    query_embeddings,
    query_labels
)
fig.savefig("embeddings.png")
```

## Development

### Setting Up Development Environment

```bash
# Clone the repository
git clone https://github.com/AdityaSharma2485/fewlearn.git
cd fewlearn

# Install development dependencies
pip install -e ".[dev]"
```

### Running Tests

FewLearn comes with a suite of unit tests to ensure the functionality works as expected:

```bash
# Run all tests
pytest tests/

# Run specific test modules
pytest tests/test_minds.py
pytest tests/test_prototypical.py
```

## Demo Application

A Streamlit-based demo application is available in the `demoapp.py` file. To run it:

```bash
# Install demo dependencies
pip install -e ".[demo]"

# Run the demo app
streamlit run demoapp.py
```

The demo allows you to:
- Compare different backbone models
- Test on the Omniglot dataset
- Upload and test your own custom datasets
- Visualize model performance and predictions

## Contributing

Contributions to FewLearn are welcome! To contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests to ensure they pass (`pytest tests/`)
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

Please ensure your code follows the project's style guidelines and includes appropriate tests.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- PyTorch team for the excellent deep learning framework
- Authors of the paper "Prototypical Networks for Few-shot Learning" for the foundational algorithm
- Contributors and users of the FewLearn library

