Metadata-Version: 2.3
Name: masked_prosody_model
Version: 0.3.0
Author-email: Christoph Minixhofer <christoph.minixhofer@gmail.com>
License: MIT
Requires-Python: >=3.8
Requires-Dist: librosa>=0.9.2
Requires-Dist: nnaudio==0.3.1
Requires-Dist: numpy<2
Requires-Dist: pandas>=2.0.3
Requires-Dist: pyworld-prebuilt>=0.3.2
Requires-Dist: pyyaml>=6.0.1
Requires-Dist: rich>=13.6.0
Requires-Dist: transformers>=4.34.0
Provides-Extra: test
Requires-Dist: pytest-cov>=4.0.0; extra == 'test'
Requires-Dist: pytest>=7.0.0; extra == 'test'
Description-Content-Type: text/markdown

# masked_prosody_model

[![PyPI version](https://badge.fury.io/py/masked-prosody-model.svg)](https://badge.fury.io/py/masked-prosody-model)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://github.com/minixc/masked_prosody_model/actions/workflows/tests.yml/badge.svg)](https://github.com/minixc/masked_prosody_model/actions/workflows/tests.yml)
[![codecov](https://codecov.io/gh/minixc/masked_prosody_model/branch/main/graph/badge.svg)](https://codecov.io/gh/minixc/masked_prosody_model)

[![Model on HF](https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-xl-dark.svg)](https://huggingface.co/cdminix/masked_prosody_model)

A transformer-based model for prosody prediction with masked inputs. This model processes pitch, energy, and voice activity detection features to predict prosodic patterns in speech.

## Installation

```bash
pip install masked_prosody_model
```

Note: `torch` and `torchaudio` need to be installed separately.

## Usage

```python
from masked_prosody_model import MaskedProsodyModel

# Load the pretrained model
model = MaskedProsodyModel.from_pretrained("cdminix/masked_prosody_model")

# Process an audio file and get representations
representation = model.process_audio("some_audio.wav", layer=7)  # layer between 0 and 15, 7 was used in the paper
```

## Acknowledgments

This model was trained using Cloud TPUs supplied by Google's TPU Research Cloud (TRC). We thank them for their support.

