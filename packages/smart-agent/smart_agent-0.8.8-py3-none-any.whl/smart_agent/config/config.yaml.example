# Smart Agent Configuration Example

# LLM API Configuration
llm:
  base_url: "http://localhost:4000"            # Base URL for LLM API (local LiteLLM proxy)
  model: "claude-3-7-sonnet-20250219"          # Model to use for generation
  api_key: "api_key"                           # API key for local LiteLLM proxy
  temperature: 1.0                             # Temperature for generation (0.0-1.0)

# Tools Configuration
tools:
  think:
    enabled: true
    url: http://localhost:8000/sse
    command: "uvx mcp-think"
    transport: sse

# Logging Configuration
logging:
  level: "WARNING"                             # Logging level (DEBUG, INFO, WARNING, ERROR)
  file: null                                   # Set to a path to log to a file

# Monitoring Configuration
# monitoring:
#   langfuse:
#     enabled: false                           # Set to true to enable Langfuse monitoring
#     host: "https://cloud.langfuse.com"       # Langfuse host URL
#     public_key: ""                           # Your Langfuse public key
#     secret_key: ""                           # Your Langfuse secret key

