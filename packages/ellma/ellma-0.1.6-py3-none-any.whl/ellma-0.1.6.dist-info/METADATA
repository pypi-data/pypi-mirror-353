Metadata-Version: 2.3
Name: ellma
Version: 0.1.6
Summary: Evolutionary Local LLM Agent - Self-improving AI assistant
License: Apache-2.0
Keywords: llm,ai,agent,automation,evolution,mistral,local-ai
Author: Tom Sapletta
Author-email: info@softreck.dev
Maintainer: WRONAI Team
Maintainer-email: contact@wronai.dev
Requires-Python: >=3.8
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Quality Assurance
Classifier: Topic :: Software Development :: Build Tools
Classifier: Topic :: Software Development :: Testing
Classifier: Topic :: System :: Systems Administration
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Operating System :: OS Independent
Classifier: Environment :: Console
Classifier: Natural Language :: English
Provides-Extra: audio
Provides-Extra: dev
Provides-Extra: full
Provides-Extra: web
Requires-Dist: aiofiles (>=23.0.0) ; extra == "web"
Requires-Dist: beautifulsoup4 (>=4.11.0) ; extra == "full"
Requires-Dist: black (>=22.0.0) ; extra == "dev"
Requires-Dist: click (>=8.0.0)
Requires-Dist: docker (>=6.0.0) ; extra == "full"
Requires-Dist: fastapi (>=0.100.0) ; extra == "web"
Requires-Dist: flake8 (>=5.0.0) ; extra == "dev"
Requires-Dist: jinja2 (>=3.1.0)
Requires-Dist: librosa (>=0.10.0) ; extra == "audio"
Requires-Dist: llama-cpp-python (>=0.2.0)
Requires-Dist: mypy (>=0.991) ; extra == "dev"
Requires-Dist: numpy (>=1.21.0)
Requires-Dist: paramiko (>=3.0.0) ; extra == "full"
Requires-Dist: pre-commit (>=2.20.0) ; extra == "dev"
Requires-Dist: prompt-toolkit (>=3.0.0)
Requires-Dist: psutil (>=5.9.0)
Requires-Dist: pytest (>=7.0.0) ; extra == "dev"
Requires-Dist: pytest-asyncio (>=0.20.0) ; extra == "dev"
Requires-Dist: pytest-cov (>=4.0.0) ; extra == "dev"
Requires-Dist: pyyaml (>=6.0)
Requires-Dist: requests (>=2.28.0)
Requires-Dist: rich (>=13.0.0)
Requires-Dist: scipy (>=1.9.0) ; extra == "audio"
Requires-Dist: sounddevice (>=0.4.0) ; extra == "audio"
Requires-Dist: uvicorn[standard] (>=0.23.0) ; extra == "web"
Requires-Dist: websockets (>=11.0.0) ; extra == "web"
Requires-Dist: whisper (>=1.0.0) ; extra == "audio"
Project-URL: Bug Tracker, https://github.com/wronai/ellma/issues
Project-URL: Changelog, https://github.com/wronai/ellma/blob/main/CHANGELOG.md
Project-URL: Documentation, https://wronai.github.io/ellma
Project-URL: Homepage, https://github.com/wronai/ellma
Project-URL: Repository, https://github.com/wronai/ellma.git
Project-URL: Source, https://github.com/wronai/ellma
Description-Content-Type: text/markdown

# ğŸ§¬ ELLMa - Evolutionary Local LLM Agent

> **E**volutionary **L**ocal **LLM** **A**gent - Self-improving AI assistant that evolves with your needs

[![PyPI version](https://badge.fury.io/py/ellma.svg)](https://badge.fury.io/py/ellma)
[![Python Support](https://img.shields.io/pypi/pyversions/ellma.svg)](https://pypi.org/project/ellma/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸš€ What is ELLMa?

ELLMa is a revolutionary **self-evolving AI agent** that runs locally on your machine. Unlike traditional AI tools, ELLMa **learns and improves itself** by:

- ğŸ§¬ **Self-Evolution**: Automatically generates new capabilities based on usage patterns
- ğŸ  **Local-First**: Runs entirely on your machine with complete privacy
- ğŸš **Shell-Native**: Integrates seamlessly with your system and workflows  
- ğŸ› ï¸ **Multi-Language**: Generates code in Python, Bash, Groovy, Docker, and more
- ğŸ“¦ **Modular**: Extensible architecture that grows with your needs

## âš¡ Quick Start

### Installation
```bash
pip install ellma
```

### First Steps
```bash
# Initialize ELLMa
ellma init

# Download Mistral 7B model (optional - will auto-download)
ellma setup --download-model

# Start interactive shell
ellma shell

# Or execute commands directly
ellma exec "system.scan"
ellma exec "web.read https://example.com"
```

### Your First Evolution
```bash
# Let ELLMa analyze itself and improve
ellma evolve
```

## ğŸ¯ Core Features

### ğŸ§¬ Self-Evolution Engine
ELLMa continuously improves by analyzing its performance and automatically generating new modules:

```bash
$ ellma evolve
ğŸ§¬ Starting evolution process...
ğŸ“Š Analyzing current capabilities...
ğŸ¯ Identified 3 improvement opportunities:
   âœ… Added: advanced_file_analyzer
   âœ… Added: network_monitoring
   âœ… Added: code_optimizer
ğŸ‰ Evolution complete! 3 new capabilities added.
```

### ğŸš Powerful Shell Interface
Natural language commands that translate to system operations:

```bash
ellma> system scan network ports
ellma> generate bash script for backup
ellma> analyze this log file for errors
ellma> create docker setup for web app
```

### ğŸ› ï¸ Multi-Language Code Generation
Generate production-ready code in multiple languages:

```bash
# Generate Bash scripts
ellma generate bash --task="Monitor system resources and alert on high usage"

# Generate Python code  
ellma generate python --task="Web scraper with rate limiting"

# Generate Docker configurations
ellma generate docker --task="Multi-service web application"

# Generate Groovy for Jenkins
ellma generate groovy --task="CI/CD pipeline with testing stages"
```

### ğŸ“Š Intelligent System Integration
ELLMa understands your system and can:

- Scan and analyze system configurations
- Monitor processes and resources
- Automate repetitive tasks
- Generate custom tools for your workflow

## ğŸ—ï¸ Architecture

```
ellma/
â”œâ”€â”€ core/                   # Core agent and evolution engine
â”‚   â”œâ”€â”€ agent.py           # Main LLM Agent class
â”‚   â”œâ”€â”€ evolution.py       # Self-improvement system
â”‚   â””â”€â”€ shell.py           # Interactive shell interface
â”œâ”€â”€ commands/               # Modular command system
â”‚   â”œâ”€â”€ system.py          # System operations
â”‚   â”œâ”€â”€ web.py             # Web interactions
â”‚   â””â”€â”€ files.py           # File operations
â”œâ”€â”€ generators/             # Code generation engines
â”‚   â”œâ”€â”€ bash.py            # Bash script generator
â”‚   â”œâ”€â”€ python.py          # Python code generator
â”‚   â””â”€â”€ docker.py          # Docker configuration generator
â”œâ”€â”€ modules/                # Dynamic module system
â”‚   â”œâ”€â”€ registry.py        # Module registry and loader
â”‚   â””â”€â”€ [auto-generated]/  # Self-created modules
â””â”€â”€ cli/                   # Command-line interface
    â”œâ”€â”€ main.py            # Main CLI entry point
    â””â”€â”€ shell.py           # Interactive shell
```

## ğŸ“š Usage Examples

### System Administration
```bash
# Monitor system health
ellma exec "system.health"

# Generate monitoring script
ellma generate bash --task="Check disk space and send alerts"

# Analyze log files
ellma exec "files.analyze /var/log/syslog --pattern=error"
```

### Development Tasks
```bash
# Generate project structure
ellma generate python --task="FastAPI project with authentication"

# Create deployment configuration
ellma generate docker --task="Production ready web app with nginx"

# Generate test scripts
ellma generate bash --task="Integration testing for REST API"
```

### Web Automation
```bash
# Read and summarize web content
ellma exec "web.read https://news.ycombinator.com --summarize"

# Generate web scraping code
ellma generate python --task="Scrape product prices with retry logic"
```

## ğŸ”§ Configuration

ELLMa stores its configuration in `~/.ellma/`:

```yaml
# ~/.ellma/config.yaml
model:
  path: ~/.ellma/models/mistral-7b.gguf
  context_length: 4096
  temperature: 0.7

evolution:
  enabled: true
  auto_improve: true
  learning_rate: 0.1

modules:
  auto_load: true
  custom_path: ~/.ellma/modules
```

## ğŸ§¬ How Evolution Works

1. **Performance Analysis**: ELLMa monitors execution times, success rates, and user feedback
2. **Gap Identification**: Identifies missing functionality or optimization opportunities  
3. **Code Generation**: Uses its LLM to generate new modules and improvements
4. **Testing & Integration**: Automatically tests and integrates new capabilities
5. **Continuous Learning**: Learns from each interaction to become more useful

## ğŸš€ Advanced Features

### Custom Module Development
```python
# Create custom modules that ELLMa can use and improve
from ellma.core.module import BaseModule

class MyCustomModule(BaseModule):
    def execute(self, *args, **kwargs):
        # Your custom functionality
        return result
```

### API Integration
```python
from ellma import ELLMa

# Use ELLMa programmatically
agent = ELLMa()
result = agent.execute("system.scan")
code = agent.generate("python", task="Data analysis script")
```

### Web Interface (Optional)
```bash
# Install web dependencies
pip install ellma[web]

# Start web interface
ellma web --port 8000
```

## ğŸ›£ï¸ Roadmap

### Version 0.1.0 - MVP âœ…
- [x] Core agent with Mistral 7B
- [x] Basic command system
- [x] Shell interface
- [x] Evolution foundation

### Version 0.2.0 - Enhanced Shell
- [ ] Advanced command completion
- [ ] Command history and favorites
- [ ] Real-time performance monitoring
- [ ] Module hot-reloading

### Version 0.3.0 - Code Generation
- [ ] Multi-language code generators
- [ ] Template system
- [ ] Code quality analysis
- [ ] Integration testing

### Version 0.4.0 - Advanced Evolution
- [ ] Performance-based learning
- [ ] User feedback integration
- [ ] Predictive capability development
- [ ] Module marketplace

### Version 1.0.0 - Autonomous Agent
- [ ] Full self-management
- [ ] Advanced reasoning capabilities
- [ ] Multi-agent coordination
- [ ] Enterprise features

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup
```bash
# Clone repository
git clone https://github.com/ellma-ai/ellma.git
cd ellma

# Install in development mode
pip install -e .[dev]

# Run tests
pytest

# Run linting
black ellma/
flake8 ellma/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built on top of [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- Inspired by the vision of autonomous AI agents
- Powered by the amazing Mistral 7B model

## ğŸ“ Support

- ğŸ“– [Documentation](https://ellma.readthedocs.io/)
- ğŸ› [Issue Tracker](https://github.com/ellma-ai/ellma/issues)
- ğŸ’¬ [Discussions](https://github.com/ellma-ai/ellma/discussions)
- ğŸ“§ [Email Support](mailto:support@ellma.dev)

---

**ELLMa: The AI agent that grows with you** ğŸŒ±â†’ğŸŒ³
