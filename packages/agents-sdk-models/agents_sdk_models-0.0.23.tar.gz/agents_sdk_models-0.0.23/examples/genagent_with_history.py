"""
GenAgent example with conversation history
ä¼šè©±å±¥æ­´ï¼ˆhistoryï¼‰ã‚’æ´»ç”¨ã—ãŸGenAgentã®ä¾‹

This example demonstrates how to use GenAgent with conversation history (Flow/Step architecture).
ã“ã®ä¾‹ã¯ã€ä¼šè©±å±¥æ­´æ©Ÿèƒ½ä»˜ãGenAgentï¼ˆFlow/Stepã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ã®ä½¿ç”¨æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
"""

import asyncio
from agents_sdk_models import GenAgent, create_simple_flow

async def main():
    """
    Main function demonstrating GenAgent with conversation history
    ä¼šè©±å±¥æ­´ä»˜ãGenAgentã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    
    print("=== GenAgent with Conversation History Example ===")

    # Method 1: Single agent with history management
    # æ–¹æ³•1: å±¥æ­´ç®¡ç†ä»˜ãå˜ä¸€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    print("\n--- Single Agent with History Management ---")
    
    gen_agent = GenAgent(
        name="history_agent",
        generation_instructions="""
        You are a helpful assistant. Answer concisely and remember the conversation context.
        ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã«ç­”ãˆã€ä¼šè©±ã®æ–‡è„ˆã‚’è¦šãˆã¦ãã ã•ã„ã€‚
        
        Reference previous exchanges when relevant to provide coherent responses.
        é–¢é€£ã™ã‚‹å ´åˆã¯ä»¥å‰ã®ã‚„ã‚Šå–ã‚Šã‚’å‚ç…§ã—ã¦ã€ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        """,
        model="gpt-4o",
        history_size=3,  # ç›´è¿‘3ä»¶ã®ã¿å±¥æ­´ã«å«ã‚ã‚‹ / Keep only recent 3 entries in history
        store_result_key="history_result"
    )

    flow = create_simple_flow(gen_agent)
    
    # é€£ç¶šã—ãŸä¼šè©±ã‚’å®Ÿæ–½ / Conduct continuous conversation
    conversation_inputs = [
        "What is the capital of France?",
        "And what is the population?", 
        "What about the famous landmarks there?",
        "What was my first question?",
        "Summarize our conversation so far in one sentence."
    ]

    for i, user_input in enumerate(conversation_inputs, 1):
        print(f"\n[{i}] User: {user_input}")
        try:
            result = await flow.run(input_data=user_input)
            response = result.get_result("history_result")
            print(f"AI: {response}")
            
            # Show current history size
            # ç¾åœ¨ã®å±¥æ­´ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
            history = gen_agent.get_pipeline_history()
            print(f"   (History entries: {len(history)})")
            
        except Exception as e:
            print(f"âŒ Error: {e}")

    # Method 2: Flow with multiple agents sharing context
    # æ–¹æ³•2: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å…±æœ‰ã™ã‚‹è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ•ãƒ­ãƒ¼
    print("\n\n--- Multi-Agent Flow with Shared Context ---")
    
    from agents_sdk_models import Flow
    
    # Agent 1: Information gatherer
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1: æƒ…å ±åé›†è€…
    info_agent = GenAgent(
        name="info_gatherer",
        generation_instructions="""
        You are an information gathering specialist. Collect and provide factual information.
        ã‚ãªãŸã¯æƒ…å ±åé›†ã®å°‚é–€å®¶ã§ã™ã€‚äº‹å®Ÿã«åŸºã¥ãæƒ…å ±ã‚’åé›†ã—ã€æä¾›ã—ã¦ãã ã•ã„ã€‚
        
        Remember what information you've already provided to avoid repetition.
        é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€ã™ã§ã«æä¾›ã—ãŸæƒ…å ±ã‚’è¦šãˆã¦ãŠã„ã¦ãã ã•ã„ã€‚
        """,
        model="gpt-4o-mini",
        history_size=5,
        store_result_key="gathered_info",
        next_step="analyst"
    )
    
    # Agent 2: Information analyst
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2: æƒ…å ±åˆ†æè€…
    analyst_agent = GenAgent(
        name="analyst",
        generation_instructions="""
        You are an information analyst. Analyze and synthesize information provided by the info gatherer.
        ã‚ãªãŸã¯æƒ…å ±åˆ†æè€…ã§ã™ã€‚æƒ…å ±åé›†è€…ã«ã‚ˆã£ã¦æä¾›ã•ã‚ŒãŸæƒ…å ±ã‚’åˆ†æã—ã€çµ±åˆã—ã¦ãã ã•ã„ã€‚
        
        Build upon previous analyses and show how new information relates to what was discussed before.
        ä»¥å‰ã®åˆ†æã‚’åŸºã«ã€æ–°ã—ã„æƒ…å ±ãŒä»¥å‰ã«è­°è«–ã•ã‚ŒãŸã“ã¨ã«ã©ã†é–¢é€£ã™ã‚‹ã‹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
        """,
        model="gpt-4o-mini",
        history_size=5,
        store_result_key="analysis_result"
    )
    
    # Create multi-agent flow
    # ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ
    multi_flow = Flow("context_sharing_flow")
    multi_flow.add_step(info_agent)
    multi_flow.add_step(analyst_agent)
    
    flow_inputs = [
        "Tell me about renewable energy technologies.",
        "How do solar panels compare to wind turbines?",
        "What are the environmental impacts we discussed?",
        "Compare the cost-effectiveness of the technologies mentioned."
    ]
    
    for i, user_input in enumerate(flow_inputs, 1):
        print(f"\n[Flow {i}] User: {user_input}")
        try:
            result = await multi_flow.run(input_data=user_input)
            
            # Show results from both agents
            # ä¸¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®çµæœã‚’è¡¨ç¤º
            info = result.get_result("gathered_info")
            analysis = result.get_result("analysis_result")
            
            print(f"ğŸ“Š Info Gatherer: {info}")
            print(f"ğŸ” Analyst: {analysis}")
            
            # Show history status
            # å±¥æ­´çŠ¶æ³ã‚’è¡¨ç¤º
            info_history = info_agent.get_pipeline_history()
            analyst_history = analyst_agent.get_pipeline_history()
            print(f"   (Info history: {len(info_history)}, Analyst history: {len(analyst_history)})")
            
        except Exception as e:
            print(f"âŒ Flow Error: {e}")

    # Method 3: Demonstrating history management methods
    # æ–¹æ³•3: å±¥æ­´ç®¡ç†ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print("\n\n--- History Management Methods ---")
    
    demo_agent = GenAgent(
        name="demo_agent",
        generation_instructions="""
        You are a demo assistant. Respond briefly to demonstrate history functionality.
        ã‚ãªãŸã¯ãƒ‡ãƒ¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å±¥æ­´æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãŸã‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚
        """,
        model="gpt-4o-mini",
        history_size=2,
        store_result_key="demo_result"
    )
    
    demo_flow = create_simple_flow(demo_agent)
    
    # Build up some history
    # å±¥æ­´ã‚’è“„ç©
    print("Building conversation history...")
    setup_inputs = ["Hello", "What's 2+2?", "Tell me a joke"]
    
    for setup_input in setup_inputs:
        await demo_flow.run(input_data=setup_input)
    
    # Show current history
    # ç¾åœ¨ã®å±¥æ­´ã‚’è¡¨ç¤º
    current_history = demo_agent.get_pipeline_history()
    print(f"\nCurrent history ({len(current_history)} entries):")
    for i, entry in enumerate(current_history, 1):
        print(f"  {i}. Input: {entry.get('input', 'N/A')}")
        print(f"     Output: {entry.get('output', 'N/A')[:50]}...")

    # Test session history
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ãƒ†ã‚¹ãƒˆ
    session_history = demo_agent.get_session_history()
    print(f"\nSession history: {session_history}")
    
    # Clear history demonstration
    # å±¥æ­´ã‚¯ãƒªã‚¢ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print(f"\nHistory before clear: {len(demo_agent.get_pipeline_history())} entries")
    demo_agent.clear_history()
    print(f"History after clear: {len(demo_agent.get_pipeline_history())} entries")
    
    # Test conversation after clear
    # ã‚¯ãƒªã‚¢å¾Œã®ä¼šè©±ã‚’ãƒ†ã‚¹ãƒˆ
    print("\nTesting conversation after history clear:")
    result = await demo_flow.run(input_data="Do you remember our previous conversation?")
    response = result.get_result("demo_result")
    print(f"Response: {response}")

def sync_main():
    """
    Synchronous wrapper for the async main function
    éåŒæœŸmainé–¢æ•°ã®åŒæœŸãƒ©ãƒƒãƒ‘ãƒ¼
    """
    asyncio.run(main())

if __name__ == "__main__":
    sync_main() 