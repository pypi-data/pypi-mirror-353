"""
Example script demonstrating how to get available models from different providers.

English:
Example script demonstrating how to get available models from different providers.

æ—¥æœ¬èª:
ç•°ãªã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
"""

import asyncio
import sys
import os

# Add the src directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from agents_sdk_models.llm import get_available_models, get_available_models_async


async def main():
    """
    Main function to demonstrate getting available models.
    
    English:
    Main function to demonstrate getting available models.
    
    æ—¥æœ¬èª:
    åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®å–å¾—ã‚’å®Ÿæ¼”ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    """
    print("ğŸš€ Getting available models from different providers...")
    print("=" * 60)
    
    # Example 1: Get models from all providers
    print("\nğŸ“‹ Example 1: Getting models from all providers")
    try:
        all_providers = ["openai", "google", "anthropic", "ollama"]
        models = await get_available_models_async(all_providers)
        
        for provider, model_list in models.items():
            print(f"\nğŸ”¹ {provider.upper()} Models:")
            if model_list:
                for model in model_list:
                    print(f"  â€¢ {model}")
            else:
                print(f"  âš ï¸  No models available (provider may be offline)")
    except Exception as e:
        print(f"âŒ Error getting all models: {e}")
    
    # Example 2: Get models from specific providers only
    print("\nğŸ“‹ Example 2: Getting models from OpenAI and Google only")
    try:
        specific_providers = ["openai", "google"]
        models = await get_available_models_async(specific_providers)
        
        for provider, model_list in models.items():
            print(f"\nğŸ”¹ {provider.upper()} Models:")
            for model in model_list:
                print(f"  â€¢ {model}")
    except Exception as e:
        print(f"âŒ Error getting specific models: {e}")
    
    # Example 3: Get Ollama models with custom base URL
    print("\nğŸ“‹ Example 3: Getting Ollama models with custom base URL")
    try:
        custom_ollama_url = "http://localhost:11434"  # Default Ollama URL
        models = await get_available_models_async(["ollama"], ollama_base_url=custom_ollama_url)
        
        print(f"\nğŸ”¹ OLLAMA Models (from {custom_ollama_url}):")
        if models["ollama"]:
            for model in models["ollama"]:
                print(f"  â€¢ {model}")
        else:
            print("  âš ï¸  No Ollama models found (Ollama may not be running)")
    except Exception as e:
        print(f"âŒ Error getting Ollama models: {e}")
    
    # Example 4: Using synchronous version
    print("\nğŸ“‹ Example 4: Using synchronous version")
    try:
        models = get_available_models(["openai"])
        print(f"\nğŸ”¹ OPENAI Models (sync):")
        for model in models["openai"]:
            print(f"  â€¢ {model}")
    except Exception as e:
        print(f"âŒ Error getting models synchronously: {e}")
    
    print("\nâœ… Examples completed!")


def sync_example():
    """
    Synchronous example for users who prefer sync code.
    
    English:
    Synchronous example for users who prefer sync code.
    
    æ—¥æœ¬èª:
    åŒæœŸã‚³ãƒ¼ãƒ‰ã‚’å¥½ã‚€ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®åŒæœŸä¾‹ã€‚
    """
    print("\nğŸ”„ Synchronous Example")
    print("=" * 30)
    
    try:
        # Get models from multiple providers synchronously
        providers = ["openai", "google", "anthropic"]
        models = get_available_models(providers)
        
        for provider, model_list in models.items():
            print(f"\nğŸ”¹ {provider.upper()} Models:")
            for model in model_list:
                print(f"  â€¢ {model}")
                
    except Exception as e:
        print(f"âŒ Error in sync example: {e}")


if __name__ == "__main__":
    print("ğŸ¯ Available Models Example")
    print("This example demonstrates how to get available models from different LLM providers.")
    print("ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€ç•°ãªã‚‹ LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚")
    
    # Run async examples
    asyncio.run(main())
    
    # Run sync example
    sync_example()
    
    print("\nğŸ’¡ Tips:")
    print("  â€¢ For Ollama, make sure the Ollama server is running")
    print("  â€¢ You can set OLLAMA_BASE_URL environment variable for custom Ollama URLs")
    print("  â€¢ Use the sync version if you're working in a non-async context")
    print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
    print("  â€¢ Ollama ã®å ´åˆã€Ollama ã‚µãƒ¼ãƒãƒ¼ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    print("  â€¢ ã‚«ã‚¹ã‚¿ãƒ  Ollama URL ã«ã¯ OLLAMA_BASE_URL ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã§ãã¾ã™")
    print("  â€¢ éåŒæœŸã§ãªã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ä½œæ¥­ã—ã¦ã„ã‚‹å ´åˆã¯ã€åŒæœŸç‰ˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„") 