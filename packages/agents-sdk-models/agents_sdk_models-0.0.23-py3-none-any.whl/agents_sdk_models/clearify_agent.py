from __future__ import annotations

"""ClearifyAgent â€” Interactive Requirements Clarification Agent for Flow workflows.

ClearifyAgentã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±ã‚’é€šã˜ã¦å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã®æƒ…å ±ã‚’åé›†ã™ã‚‹Stepã‚¯ãƒ©ã‚¹ã§ã™ã€‚
GenAgentã‚’å‚è€ƒã«ä½œæˆã•ã‚Œã¦ãŠã‚Šã€Flowãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†…ã§ä½¿ç”¨ã§ãã¾ã™ã€‚
"""

import asyncio
from typing import Any, Callable, List, Dict, Optional, Type, TypeVar, Generic
from dataclasses import dataclass
import json

from .step import Step
from .context import Context
from .llm_pipeline import LLMPipeline, LLMResult

try:
    from pydantic import BaseModel  # type: ignore
except ImportError:
    BaseModel = object  # type: ignore

# English: Generic type variable for user requirement type
# æ—¥æœ¬èª: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚å‹ç”¨ã®ã‚¸ã‚§ãƒãƒªãƒƒã‚¯å‹å¤‰æ•°
T = TypeVar('T')


class ClearifyBase(BaseModel):
    """
    Base class for requirement clarification output
    è¦ä»¶æ˜ç¢ºåŒ–å‡ºåŠ›ã®ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
    
    Attributes:
        clearity: True if requirements are confirmed / è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆTrue
    """
    clearity: bool  # True if requirements are confirmed / è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆTrue


class ClearifyGeneric(ClearifyBase, Generic[T]):
    """
    Generic clarification output with typed user requirement
    å‹ä»˜ããƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’æŒã¤ã‚¸ã‚§ãƒãƒªãƒƒã‚¯æ˜ç¢ºåŒ–å‡ºåŠ›
    
    Attributes:
        clearity: True if requirements are confirmed / è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆTrue  
        user_requirement: Confirmed user requirement / ç¢ºå®šã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚
    """
    user_requirement: Optional[T] = None  # Confirmed user requirement / ç¢ºå®šã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚


class Clearify(ClearifyBase):
    """
    Default clarification output with string user requirement
    æ–‡å­—åˆ—ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’æŒã¤ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ˜ç¢ºåŒ–å‡ºåŠ›
    
    Attributes:
        clearity: True if requirements are confirmed / è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆTrue
        user_requirement: Confirmed user requirement as string / æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®šã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚
    """
    user_requirement: Optional[str] = None  # Confirmed user requirement as string / æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®šã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚


@dataclass
class ClarificationQuestion:
    """
    Represents a clarification question from the pipeline
    ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®æ˜ç¢ºåŒ–è³ªå•ã‚’è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    Attributes:
        question: The clarification question text / æ˜ç¢ºåŒ–è³ªå•ãƒ†ã‚­ã‚¹ãƒˆ
        turn: Current turn number / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·
        remaining_turns: Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°
    """
    question: str  # The clarification question text / æ˜ç¢ºåŒ–è³ªå•ãƒ†ã‚­ã‚¹ãƒˆ
    turn: int  # Current turn number / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·
    remaining_turns: int  # Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°
    
    def __str__(self) -> str:
        """
        String representation of the clarification question
        æ˜ç¢ºåŒ–è³ªå•ã®æ–‡å­—åˆ—è¡¨ç¾
        
        Returns:
            str: Formatted question with turn info / ã‚¿ãƒ¼ãƒ³æƒ…å ±ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿è³ªå•
        """
        return f"[ã‚¿ãƒ¼ãƒ³ {self.turn}/{self.turn + self.remaining_turns}] {self.question}"


class ClearifyPipeline:
    """
    ClearifyPipeline class for requirements clarification using modern LLM Pipeline
    ãƒ¢ãƒ€ãƒ³ãªLLMãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãŸè¦ä»¶æ˜ç¢ºåŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    This class wraps LLMPipeline to handle:
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯LLMPipelineã‚’ãƒ©ãƒƒãƒ—ã—ã¦ä»¥ä¸‹ã‚’å‡¦ç†ã—ã¾ã™ï¼š
    - Iterative requirement clarification / åå¾©çš„ãªè¦ä»¶æ˜ç¢ºåŒ–
    - Type-safe output wrapping / å‹å®‰å…¨ãªå‡ºåŠ›ãƒ©ãƒƒãƒ”ãƒ³ã‚°
    - Maximum turn control / æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°åˆ¶å¾¡
    - Structured requirement extraction / æ§‹é€ åŒ–ã•ã‚ŒãŸè¦æ±‚æŠ½å‡º
    """
    
    def __init__(
        self,
        name: str,
        generation_instructions: str,
        output_data: Optional[Type[Any]] = None,
        clerify_max_turns: int = 20,
        evaluation_instructions: Optional[str] = None,
        model: Optional[str] = None,
        evaluation_model: Optional[str] = None,
        threshold: int = 85,
        retries: int = 3,
        **kwargs
    ) -> None:
        """
        Initialize the ClearifyPipeline with configuration parameters
        è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ClearifyPipelineã‚’åˆæœŸåŒ–ã™ã‚‹
        
        Args:
            name: Pipeline name / ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å
            generation_instructions: System prompt for generation / ç”Ÿæˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            output_data: Output data model type / å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å‹
            clerify_max_turns: Maximum number of clarification turns / æœ€å¤§æ˜ç¢ºåŒ–ã‚¿ãƒ¼ãƒ³æ•°
            evaluation_instructions: System prompt for evaluation / è©•ä¾¡ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            model: LLM model name / LLMãƒ¢ãƒ‡ãƒ«å
            evaluation_model: Evaluation model name / è©•ä¾¡ãƒ¢ãƒ‡ãƒ«å
            threshold: Evaluation threshold / è©•ä¾¡é–¾å€¤
            retries: Number of retries / ãƒªãƒˆãƒ©ã‚¤å›æ•°
            **kwargs: Additional arguments for GenAgent / GenAgentç”¨è¿½åŠ å¼•æ•°
        """
        
        # English: Store original output data type before wrapping
        # æ—¥æœ¬èª: ãƒ©ãƒƒãƒ”ãƒ³ã‚°å‰ã®å…ƒã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å‹ã‚’ä¿å­˜
        self.original_output_data = output_data
        self.clerify_max_turns = clerify_max_turns
        self._turn_count = 0
        self._conversation_history = []
        
        # English: Create wrapped output model based on provided type
        # æ—¥æœ¬èª: æä¾›ã•ã‚ŒãŸå‹ã«åŸºã¥ã„ã¦ãƒ©ãƒƒãƒ—ã•ã‚ŒãŸå‡ºåŠ›ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        if output_data is not None:
            # English: For typed output, create generic wrapper
            # æ—¥æœ¬èª: å‹ä»˜ãå‡ºåŠ›ã®å ´åˆã€ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½œæˆ
            wrapped_output_model = self._create_wrapped_model(output_data)
        else:
            # English: For untyped output, use default string wrapper
            # æ—¥æœ¬èª: å‹ãªã—å‡ºåŠ›ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ–‡å­—åˆ—ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½¿ç”¨
            wrapped_output_model = Clearify
        
        # English: Enhanced generation instructions for clarification
        # æ—¥æœ¬èª: æ˜ç¢ºåŒ–ç”¨ã®æ‹¡å¼µç”ŸæˆæŒ‡ç¤º
        enhanced_instructions = self._build_clarification_instructions(
            generation_instructions, 
            output_data
        )
        
        # English: Create internal LLMPipeline instance
        # æ—¥æœ¬èª: å†…éƒ¨LLMPipelineã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        self.llm_pipeline = LLMPipeline(
            name=f"{name}_pipeline",
            generation_instructions=enhanced_instructions,
            evaluation_instructions=evaluation_instructions,
            output_model=wrapped_output_model,
            model=model,
            evaluation_model=evaluation_model,
            threshold=threshold,
            max_retries=retries,
            **kwargs
        )
    
    def _create_wrapped_model(self, output_data_type: Type[Any]) -> Type[BaseModel]:
        """
        Create a wrapped output model for the given type
        æŒ‡å®šã•ã‚ŒãŸå‹ç”¨ã®ãƒ©ãƒƒãƒ—ã•ã‚ŒãŸå‡ºåŠ›ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹
        
        Args:
            output_data_type: Original output data type / å…ƒã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å‹
            
        Returns:
            Type[BaseModel]: Wrapped model type / ãƒ©ãƒƒãƒ—ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å‹
        """
        # English: Create dynamic Pydantic model that wraps the original type
        # æ—¥æœ¬èª: å…ƒã®å‹ã‚’ãƒ©ãƒƒãƒ—ã™ã‚‹å‹•çš„Pydanticãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        
        class WrappedClearify(BaseModel):
            clearity: bool  # True if requirements are confirmed / è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆTrue
            user_requirement: Optional[output_data_type] = None  # Confirmed user requirement / ç¢ºå®šã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚
        
        return WrappedClearify
    
    def _build_clarification_instructions(
        self, 
        base_instructions: str, 
        output_data_type: Optional[Type[Any]]
    ) -> str:
        """
        Build enhanced instructions for clarification process
        æ˜ç¢ºåŒ–ãƒ—ãƒ­ã‚»ã‚¹ç”¨ã®æ‹¡å¼µæŒ‡ç¤ºã‚’æ§‹ç¯‰ã™ã‚‹
        
        Args:
            base_instructions: Base generation instructions / ãƒ™ãƒ¼ã‚¹ç”ŸæˆæŒ‡ç¤º
            output_data_type: Output data type for schema reference / ã‚¹ã‚­ãƒ¼ãƒå‚ç…§ç”¨å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å‹
            
        Returns:
            str: Enhanced instructions / æ‹¡å¼µæŒ‡ç¤º
        """
        schema_info = ""
        if output_data_type is not None:
            try:
                # English: Try to get schema information if available
                # æ—¥æœ¬èª: åˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—ã‚’è©¦è¡Œ
                if hasattr(output_data_type, 'model_json_schema'):
                    schema = output_data_type.model_json_schema()
                    schema_info = f"\n\nå¿…è¦ãªå‡ºåŠ›å½¢å¼ã®ã‚¹ã‚­ãƒ¼ãƒ:\n{json.dumps(schema, indent=2, ensure_ascii=False)}"
                elif hasattr(output_data_type, '__annotations__'):
                    annotations = output_data_type.__annotations__
                    schema_info = f"\n\nå¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {list(annotations.keys())}"
            except Exception:
                pass
        
        enhanced_instructions = f"""
{base_instructions}

ã‚ãªãŸã¯è¦ä»¶æ˜ç¢ºåŒ–ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ãã ã•ã„ï¼š

1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ç†è§£ã—ã€ä¸æ˜ç¢ºãªç‚¹ã‚„ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã‚’ç‰¹å®šã™ã‚‹
2. è¦ä»¶ãŒä¸å®Œå…¨ãªå ´åˆã¯ã€clarityã‚’falseã«ã—ã¦ã€å¿…è¦ãªè¿½åŠ æƒ…å ±ã‚’è³ªå•ã™ã‚‹
3. ã™ã¹ã¦ã®å¿…è¦ãªæƒ…å ±ãŒæƒã„ã€è¦ä»¶ãŒæ˜ç¢ºã«ãªã£ãŸå ´åˆã®ã¿ã€clarityã‚’trueã«ã—ã¦ç¢ºå®šã™ã‚‹
4. è³ªå•ã¯ä¸€åº¦ã«ä¸€ã¤ãšã¤ã€åˆ†ã‹ã‚Šã‚„ã™ãè¡Œã†
5. æœ€å¤§{self.clerify_max_turns}ã‚¿ãƒ¼ãƒ³ã¾ã§è³ªå•ã§ãã‚‹
{schema_info}

å‡ºåŠ›å½¢å¼ï¼š
- clarity: è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆã¯trueã€è¿½åŠ è³ªå•ãŒå¿…è¦ãªå ´åˆã¯false
- user_requirement: è¦ä»¶ãŒç¢ºå®šã—ãŸå ´åˆã®ã¿ã€å®Œå…¨ãªè¦æ±‚ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹
"""
        
        return enhanced_instructions
    
    def run(self, user_input: str) -> Any:
        """
        Execute the clarification pipeline
        æ˜ç¢ºåŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹
        
        Args:
            user_input: User input for clarification / æ˜ç¢ºåŒ–ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            
        Returns:
            Any: Clarification result or question / æ˜ç¢ºåŒ–çµæœã¾ãŸã¯è³ªå•
        """
        # English: Check if max turns reached
        # æ—¥æœ¬èª: æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ãŸã‹ã‚’ç¢ºèª
        if self._turn_count >= self.clerify_max_turns:
            return ClarificationQuestion(
                question="æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ã¾ã—ãŸã€‚è¦ä»¶æ˜ç¢ºåŒ–ã‚’çµ‚äº†ã—ã¾ã™ã€‚",
                turn=self._turn_count,
                remaining_turns=0
            )
        
        return self._process_input(user_input)
    
    def continue_clarification(self, user_response: str) -> Any:
        """
        Continue the clarification process with user response
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”ã§æ˜ç¢ºåŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¶™ç¶šã™ã‚‹
        
        Args:
            user_response: User response to previous question / å‰ã®è³ªå•ã¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”
            
        Returns:
            Any: Next clarification result or question / æ¬¡ã®æ˜ç¢ºåŒ–çµæœã¾ãŸã¯è³ªå•
        """
        return self._process_input(user_response)
    
    def _process_input(self, user_input: str) -> Any:
        """
        Process user input and generate clarification response
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†ã—ã¦æ˜ç¢ºåŒ–å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹
        
        Args:
            user_input: User input text / ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            Any: Clarification response / æ˜ç¢ºåŒ–å¿œç­”
        """
        try:
            # English: Increment turn count
            # æ—¥æœ¬èª: ã‚¿ãƒ¼ãƒ³æ•°ã‚’å¢—åŠ 
            self._turn_count += 1
            
            # English: Build context with conversation history
            # æ—¥æœ¬èª: ä¼šè©±å±¥æ­´ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
            context_prompt = self._build_conversation_context()
            full_prompt = f"{context_prompt}\n\næ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: {user_input}"
            
            # English: Run the internal LLMPipeline directly (no async issues)
            # æ—¥æœ¬èª: å†…éƒ¨LLMPipelineã‚’ç›´æ¥å®Ÿè¡Œï¼ˆéåŒæœŸå•é¡Œãªã—ï¼‰
            llm_result = self.llm_pipeline.run(full_prompt)
            result = llm_result.content if llm_result.success else None
            
            # English: Store interaction in history
            # æ—¥æœ¬èª: å¯¾è©±ã‚’å±¥æ­´ã«ä¿å­˜
            self._store_interaction(user_input, result)
            
            # English: Check if clarification is complete
            # æ—¥æœ¬èª: æ˜ç¢ºåŒ–ãŒå®Œäº†ã—ãŸã‹ã‚’ç¢ºèª
            if hasattr(result, 'clearity') and result.clearity:
                # English: Clarification complete, return final data
                # æ—¥æœ¬èª: æ˜ç¢ºåŒ–å®Œäº†ã€æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                if hasattr(result, 'user_requirement') and result.user_requirement is not None:
                    return result.user_requirement
                else:
                    return result
            else:
                # English: Continue clarification, create question
                # æ—¥æœ¬èª: æ˜ç¢ºåŒ–ã‚’ç¶™ç¶šã€è³ªå•ã‚’ä½œæˆ
                question_text = str(result) if result else "è¿½åŠ æƒ…å ±ãŒå¿…è¦ã§ã™ã€‚è©³ç´°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
                return ClarificationQuestion(
                    question=question_text,
                    turn=self._turn_count,
                    remaining_turns=max(0, self.clerify_max_turns - self._turn_count)
                )
                
        except Exception as e:
            # English: Handle errors gracefully
            # æ—¥æœ¬èª: ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«å‡¦ç†
            return ClarificationQuestion(
                question=f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}ã€‚å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                turn=self._turn_count,
                remaining_turns=max(0, self.clerify_max_turns - self._turn_count)
            )
    
    def _build_conversation_context(self) -> str:
        """
        Build conversation context from history
        å±¥æ­´ã‹ã‚‰ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹
        
        Returns:
            str: Conversation context / ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self._conversation_history:
            return "ã“ã‚Œã¯æœ€åˆã®å¯¾è©±ã§ã™ã€‚"
        
        context_parts = ["ã“ã‚Œã¾ã§ã®ä¼šè©±:"]
        for i, interaction in enumerate(self._conversation_history, 1):
            user_input = interaction.get('user_input', '')
            ai_response = str(interaction.get('ai_response', ''))
            context_parts.append(f"{i}. ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}")
            context_parts.append(f"   AI: {ai_response}")
        
        return "\n".join(context_parts)
    
    def _store_interaction(self, user_input: str, ai_result: Any) -> None:
        """
        Store interaction in conversation history
        å¯¾è©±ã‚’ä¼šè©±å±¥æ­´ã«ä¿å­˜ã™ã‚‹
        
        Args:
            user_input: User input / ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            ai_result: AI response / AIå¿œç­”
        """
        interaction = {
            'user_input': user_input,
            'ai_response': ai_result,
            'turn': self._turn_count,
            'timestamp': json.dumps({"turn": self._turn_count}, ensure_ascii=False)
        }
        self._conversation_history.append(interaction)
    
    def reset_turns(self) -> None:
        """
        Reset turn counter
        ã‚¿ãƒ¼ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹
        """
        self._turn_count = 0
    
    def reset_session(self) -> None:
        """
        Reset the entire clarification session
        æ˜ç¢ºåŒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹
        """
        self._turn_count = 0
        self._conversation_history = []
    
    @property
    def is_complete(self) -> bool:
        """
        Check if clarification is complete
        æ˜ç¢ºåŒ–ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹
        
        Returns:
            bool: True if complete / å®Œäº†ã—ã¦ã„ã‚‹å ´åˆTrue
        """
        # English: Complete if we have a successful result in history
        # æ—¥æœ¬èª: å±¥æ­´ã«æˆåŠŸçµæœãŒã‚ã‚‹å ´åˆã¯å®Œäº†
        if not self._conversation_history:
            return False
        
        last_result = self._conversation_history[-1].get('ai_response')
        return (hasattr(last_result, 'clearity') and last_result.clearity) or \
               (hasattr(last_result, 'user_requirement') and last_result.user_requirement is not None)
    
    @property
    def conversation_history(self) -> List[Dict[str, Any]]:
        """
        Get conversation history
        ä¼šè©±å±¥æ­´ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            List[Dict[str, Any]]: Conversation history / ä¼šè©±å±¥æ­´
        """
        return self._conversation_history.copy()
    
    @property
    def current_turn(self) -> int:
        """
        Get current turn number
        ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            int: Current turn / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³
        """
        return self._turn_count
    
    @property
    def remaining_turns(self) -> int:
        """
        Get remaining turns
        æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            int: Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°
        """
        return max(0, self.clerify_max_turns - self._turn_count)
    
    @property 
    def threshold(self) -> float:
        """
        Get evaluation threshold from internal LLMPipeline
        å†…éƒ¨LLMPipelineã‹ã‚‰è©•ä¾¡é–¾å€¤ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            float: Evaluation threshold / è©•ä¾¡é–¾å€¤
        """
        return self.llm_pipeline.threshold
    
    @property
    def retries(self) -> int:
        """
        Get retry count from internal LLMPipeline
        å†…éƒ¨LLMPipelineã‹ã‚‰ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’å–å¾—ã™ã‚‹
        
        Returns:
            int: Retry count / ãƒªãƒˆãƒ©ã‚¤å›æ•°
        """
        return self.llm_pipeline.max_retries
    
    def get_session_history(self) -> Optional[List[str]]:
        """
        Get session history as string list
        ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—ã™ã‚‹
        
        Returns:
            Optional[List[str]]: Session history / ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´
        """
        if not self._conversation_history:
            return None
        
        # English: Use LLMPipeline's session history
        # æ—¥æœ¬èª: LLMPipelineã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ä½¿ç”¨
        history = self.llm_pipeline.session_history
        return history if history else None


@dataclass
class ClarificationResult:
    """
    Result of clarification process
    æ˜ç¢ºåŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®çµæœ
    
    Attributes:
        is_complete: True if clarification is complete / æ˜ç¢ºåŒ–ãŒå®Œäº†ã—ãŸå ´åˆTrue
        data: Clarified data or next question / æ˜ç¢ºåŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯æ¬¡ã®è³ªå•
        turn: Current turn number / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·
        remaining_turns: Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°
    """
    is_complete: bool  # True if clarification is complete / æ˜ç¢ºåŒ–ãŒå®Œäº†ã—ãŸå ´åˆTrue
    data: Any  # Clarified data or next question / æ˜ç¢ºåŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯æ¬¡ã®è³ªå•
    turn: int  # Current turn number / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·
    remaining_turns: int  # Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°


class ClearifyAgent(Step):
    """
    Step implementation for interactive requirements clarification
    å¯¾è©±çš„è¦ä»¶æ˜ç¢ºåŒ–ã®ãŸã‚ã®Stepå®Ÿè£…
    
    This class allows clarifying user requirements through interactive dialog
    within Flow workflows, providing structured data collection capabilities.
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯Flowãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†…ã§å¯¾è©±çš„ãªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’æ˜ç¢ºåŒ–ã—ã€
    æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        name: str,
        generation_instructions: str,
        output_data: Optional[Type[Any]] = None,
        *,
        clerify_max_turns: int = 20,
        evaluation_instructions: Optional[str] = None,
        input_guardrails: Optional[list] = None,
        output_guardrails: Optional[list] = None,
        model: str | None = None,
        evaluation_model: str | None = None,
        generation_tools: Optional[list] = None,
        evaluation_tools: Optional[list] = None,
        routing_func: Optional[Callable[[Any], Any]] = None,
        session_history: Optional[list] = None,
        history_size: int = 10,
        threshold: int = 85,
        retries: int = 3,
        improvement_callback: Optional[Callable[[Any, Any], None]] = None,
        dynamic_prompt: Optional[Callable[[str], str]] = None,
        retry_comment_importance: Optional[list[str]] = None,
        locale: str = "en",
        next_step: Optional[str] = None,
        store_result_key: Optional[str] = None,
        conversation_key: Optional[str] = None,
    ) -> None:
        """
        Initialize ClearifyAgent with clarification configuration
        æ˜ç¢ºåŒ–è¨­å®šã§ClearifyAgentã‚’åˆæœŸåŒ–ã™ã‚‹

        Args:
            name: Step name / ã‚¹ãƒ†ãƒƒãƒ—å
            generation_instructions: System prompt for clarification / æ˜ç¢ºåŒ–ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            output_data: Target data model type / ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å‹
            clerify_max_turns: Maximum number of clarification turns / æœ€å¤§æ˜ç¢ºåŒ–ã‚¿ãƒ¼ãƒ³æ•°
            evaluation_instructions: System prompt for evaluation / è©•ä¾¡ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            input_guardrails: Guardrails for generation / ç”Ÿæˆç”¨ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«
            output_guardrails: Guardrails for evaluation / è©•ä¾¡ç”¨ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«
            model: LLM model name / LLMãƒ¢ãƒ‡ãƒ«å
            evaluation_model: Optional LLM model name for evaluation / è©•ä¾¡ç”¨LLMãƒ¢ãƒ‡ãƒ«åï¼ˆä»»æ„ï¼‰
            generation_tools: Tools for generation / ç”Ÿæˆç”¨ãƒ„ãƒ¼ãƒ«
            evaluation_tools: Tools for evaluation / è©•ä¾¡ç”¨ãƒ„ãƒ¼ãƒ«
            routing_func: Function for output routing / å‡ºåŠ›ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨é–¢æ•°
            session_history: Session history / ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´
            history_size: Size of history to keep / ä¿æŒã™ã‚‹å±¥æ­´ã‚µã‚¤ã‚º
            threshold: Evaluation score threshold / è©•ä¾¡ã‚¹ã‚³ã‚¢é–¾å€¤
            retries: Number of retry attempts / ãƒªãƒˆãƒ©ã‚¤è©¦è¡Œå›æ•°
            improvement_callback: Callback for improvement suggestions / æ”¹å–„ææ¡ˆç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            dynamic_prompt: Optional function to dynamically build prompt / å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆé–¢æ•°ï¼ˆä»»æ„ï¼‰
            retry_comment_importance: Importance levels of comments to include on retry / ãƒªãƒˆãƒ©ã‚¤æ™‚ã‚³ãƒ¡ãƒ³ãƒˆé‡è¦åº¦ãƒ¬ãƒ™ãƒ«
            locale: Language code for localized messages / ãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨è¨€èªã‚³ãƒ¼ãƒ‰
            next_step: Next step after clarification completion / æ˜ç¢ºåŒ–å®Œäº†å¾Œã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—
            store_result_key: Key to store result in context shared_state / ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå…±æœ‰çŠ¶æ…‹ã«çµæœã‚’æ ¼ç´ã™ã‚‹ã‚­ãƒ¼
            conversation_key: Key to store conversation state / ä¼šè©±çŠ¶æ…‹ã‚’æ ¼ç´ã™ã‚‹ã‚­ãƒ¼
        """
        # Initialize Step base class
        # StepåŸºåº•ã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
        super().__init__(name)
        
        # Store flow-specific configuration
        # ãƒ•ãƒ­ãƒ¼å›ºæœ‰ã®è¨­å®šã‚’ä¿å­˜
        self.next_step = next_step
        self.store_result_key = store_result_key or f"{name}_result"
        self.conversation_key = conversation_key or f"{name}_conversation"
        
        # Create internal ClearifyPipeline instance
        # å†…éƒ¨ClearifyPipelineã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        self.pipeline = ClearifyPipeline(
            name=f"{name}_pipeline",
            generation_instructions=generation_instructions,
            evaluation_instructions=evaluation_instructions,
            output_data=output_data,
            clerify_max_turns=clerify_max_turns,
            input_guardrails=input_guardrails,
            output_guardrails=output_guardrails,
            model=model,
            evaluation_model=evaluation_model,
            generation_tools=generation_tools,
            evaluation_tools=evaluation_tools,
            routing_func=routing_func,
            session_history=session_history,
            history_size=history_size,
            threshold=threshold,
            retries=retries,
            improvement_callback=improvement_callback,
            dynamic_prompt=dynamic_prompt,
            retry_comment_importance=retry_comment_importance,
            locale=locale,
        )

    async def run(self, user_input: Optional[str], ctx: Context) -> Context:
        """
        Execute ClearifyAgent step using ClearifyPipeline
        ClearifyPipelineã‚’ä½¿ç”¨ã—ã¦ClearifyAgentã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            user_input: User input for clarification / æ˜ç¢ºåŒ–ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            ctx: Current workflow context / ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            Context: Updated context with clarification results / æ˜ç¢ºåŒ–çµæœä»˜ãæ›´æ–°æ¸ˆã¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # English: Update step information in context
        # æ—¥æœ¬èª: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ±ã‚’æ›´æ–°
        ctx.update_step_info(self.name)
        
        try:
            # English: Determine input text for clarification
            # æ—¥æœ¬èª: æ˜ç¢ºåŒ–ç”¨å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’æ±ºå®š
            input_text = user_input or ctx.last_user_input or ""
            
            if not input_text:
                # English: If no input available, add system message and continue
                # æ—¥æœ¬èª: å…¥åŠ›ãŒãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã¦ç¶šè¡Œ
                ctx.add_system_message(f"ClearifyAgent {self.name}: No input available, skipping clarification")
                result = ClarificationResult(
                    is_complete=False,
                    data=None,
                    turn=0,
                    remaining_turns=self.pipeline.clerify_max_turns
                )
            else:
                # English: Check if this is a continuation of existing conversation
                # æ—¥æœ¬èª: æ—¢å­˜ã®ä¼šè©±ã®ç¶™ç¶šã‹ã‚’ç¢ºèª
                existing_conversation = ctx.shared_state.get(self.conversation_key)
                
                # English: Execute clarification using GenAgent-based pipeline
                # æ—¥æœ¬èª: GenAgentãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦æ˜ç¢ºåŒ–ã‚’å®Ÿè¡Œ
                if existing_conversation and not self.pipeline.is_complete:
                    # English: Continue existing clarification
                    # æ—¥æœ¬èª: æ—¢å­˜ã®æ˜ç¢ºåŒ–ã‚’ç¶™ç¶š
                    pipeline_result = self.pipeline.continue_clarification(input_text)
                else:
                    # English: Start new clarification
                    # æ—¥æœ¬èª: æ–°ã—ã„æ˜ç¢ºåŒ–ã‚’é–‹å§‹
                    pipeline_result = self.pipeline.run(input_text)
                
                # English: Wrap pipeline result in ClarificationResult
                # æ—¥æœ¬èª: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµæœã‚’ClarificationResultã«ãƒ©ãƒƒãƒ—
                result = ClarificationResult(
                    is_complete=self.pipeline.is_complete,
                    data=pipeline_result,
                    turn=self.pipeline.current_turn,
                    remaining_turns=self.pipeline.remaining_turns
                )
            
            # English: Store conversation state
            # æ—¥æœ¬èª: ä¼šè©±çŠ¶æ…‹ã‚’ä¿å­˜
            ctx.shared_state[self.conversation_key] = {
                "is_complete": result.is_complete,
                "turn": result.turn,
                "remaining_turns": result.remaining_turns,
                "conversation_history": self.pipeline.conversation_history
            }
            
            # English: Handle result based on completion status
            # æ—¥æœ¬èª: å®Œäº†çŠ¶æ…‹ã«åŸºã¥ã„ã¦çµæœã‚’å‡¦ç†
            if result.is_complete:
                # English: Clarification completed - store final result
                # æ—¥æœ¬èª: æ˜ç¢ºåŒ–å®Œäº† - æœ€çµ‚çµæœã‚’ä¿å­˜
                ctx.shared_state[self.store_result_key] = result.data
                ctx.prev_outputs[self.name] = result.data
                
                # English: Add completion message
                # æ—¥æœ¬èª: å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                ctx.add_assistant_message(f"è¦æ±‚æ˜ç¢ºåŒ–å®Œäº†: {str(result.data)}")
                ctx.add_system_message(f"ClearifyAgent {self.name}: Clarification completed successfully")
                
                # English: Set next step if specified
                # æ—¥æœ¬èª: æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨­å®š
                if self.next_step:
                    ctx.goto(self.next_step)
                    
            else:
                # English: Clarification in progress - store question
                # æ—¥æœ¬èª: æ˜ç¢ºåŒ–é€²è¡Œä¸­ - è³ªå•ã‚’ä¿å­˜
                if isinstance(result.data, ClarificationQuestion):
                    question_text = str(result.data)
                    ctx.add_assistant_message(question_text)
                    ctx.add_system_message(f"ClearifyAgent {self.name}: Clarification question asked (Turn {result.turn})")
                else:
                    ctx.add_assistant_message(str(result.data))
                    ctx.add_system_message(f"ClearifyAgent {self.name}: Clarification in progress")
                
                # English: Store intermediate result for potential continuation
                # æ—¥æœ¬èª: ç¶™ç¶šå¯èƒ½æ€§ã®ãŸã‚ä¸­é–“çµæœã‚’ä¿å­˜
                ctx.shared_state[self.store_result_key] = result
                ctx.prev_outputs[self.name] = result
                
                # English: Check if max turns reached and force completion
                # æ—¥æœ¬èª: æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ãŸå ´åˆã¯å¼·åˆ¶å®Œäº†
                if result.remaining_turns <= 0 and self.next_step:
                    ctx.add_system_message(f"ClearifyAgent {self.name}: Maximum turns reached, proceeding to next step")
                    ctx.goto(self.next_step)
                
                # English: Do not advance to next step - wait for user response
                # æ—¥æœ¬èª: æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã¾ãªã„ - ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”ã‚’å¾…æ©Ÿ
                
        except Exception as e:
            # English: Handle execution errors
            # æ—¥æœ¬èª: å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†
            error_msg = f"ClearifyAgent {self.name} execution error: {str(e)}"
            ctx.add_system_message(error_msg)
            
            # English: Store error result
            # æ—¥æœ¬èª: ã‚¨ãƒ©ãƒ¼çµæœã‚’ä¿å­˜
            error_result = ClarificationResult(
                is_complete=False,
                data=None,
                turn=0,
                remaining_turns=0
            )
            ctx.shared_state[self.store_result_key] = error_result
            ctx.prev_outputs[self.name] = error_result
            
            # English: Log error for debugging
            # æ—¥æœ¬èª: ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            print(f"ğŸš¨ {error_msg}")
        
        return ctx

    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """
        Get the conversation history from the internal pipeline
        å†…éƒ¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ä¼šè©±å±¥æ­´ã‚’å–å¾—ã™ã‚‹

        Returns:
            List[Dict[str, Any]]: Conversation history / ä¼šè©±å±¥æ­´
        """
        return self.pipeline.conversation_history

    def get_session_history(self) -> Optional[List[str]]:
        """
        Get the session history from the internal pipeline
        å†…éƒ¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’å–å¾—ã™ã‚‹

        Returns:
            Optional[List[str]]: Session history / ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´
        """
        return self.pipeline.get_session_history()

    def reset_clarification(self) -> None:
        """
        Reset the clarification session
        æ˜ç¢ºåŒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹
        """
        self.pipeline.reset_session()

    def is_clarification_complete(self) -> bool:
        """
        Check if the clarification process is complete
        æ˜ç¢ºåŒ–ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹

        Returns:
            bool: True if complete / å®Œäº†ã—ã¦ã„ã‚‹å ´åˆTrue
        """
        return self.pipeline.is_complete

    @property
    def current_turn(self) -> int:
        """
        Get current turn number
        ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·ã‚’å–å¾—ã™ã‚‹

        Returns:
            int: Current turn number / ç¾åœ¨ã®ã‚¿ãƒ¼ãƒ³ç•ªå·
        """
        return self.pipeline.current_turn

    @property
    def remaining_turns(self) -> int:
        """
        Get remaining turn count
        æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°ã‚’å–å¾—ã™ã‚‹

        Returns:
            int: Remaining turns / æ®‹ã‚Šã‚¿ãƒ¼ãƒ³æ•°
        """
        return self.pipeline.remaining_turns

    def __str__(self) -> str:
        return f"ClearifyAgent(name={self.name}, turns={self.current_turn}/{self.pipeline.clerify_max_turns})"

    def __repr__(self) -> str:
        return self.__str__()


def create_simple_clearify_agent(
    name: str,
    instructions: str,
    output_data: Optional[Type[Any]] = None,
    max_turns: int = 20,
    model: Optional[str] = None,
    next_step: Optional[str] = None
) -> ClearifyAgent:
    """
    Create a simple ClearifyAgent with basic configuration
    åŸºæœ¬è¨­å®šã§ã‚·ãƒ³ãƒ—ãƒ«ãªClearifyAgentã‚’ä½œæˆã™ã‚‹

    Args:
        name: Agent name / ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå
        instructions: Clarification instructions / æ˜ç¢ºåŒ–æŒ‡ç¤º
        output_data: Target data model type / ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å‹
        max_turns: Maximum clarification turns / æœ€å¤§æ˜ç¢ºåŒ–ã‚¿ãƒ¼ãƒ³æ•°
        model: LLM model name / LLMãƒ¢ãƒ‡ãƒ«å
        next_step: Next step after completion / å®Œäº†å¾Œã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—

    Returns:
        ClearifyAgent: Configured ClearifyAgent instance / è¨­å®šæ¸ˆã¿ClearifyAgentã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return ClearifyAgent(
        name=name,
        generation_instructions=instructions,
        output_data=output_data,
        clerify_max_turns=max_turns,
        model=model,
        next_step=next_step
    )


def create_evaluated_clearify_agent(
    name: str,
    generation_instructions: str,
    evaluation_instructions: str,
    output_data: Optional[Type[Any]] = None,
    max_turns: int = 20,
    model: Optional[str] = None,
    evaluation_model: Optional[str] = None,
    next_step: Optional[str] = None,
    threshold: int = 85,
    retries: int = 3
) -> ClearifyAgent:
    """
    Create a ClearifyAgent with evaluation capabilities
    è©•ä¾¡æ©Ÿèƒ½ä»˜ãClearifyAgentã‚’ä½œæˆã™ã‚‹

    Args:
        name: Agent name / ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå
        generation_instructions: Generation instructions / ç”ŸæˆæŒ‡ç¤º
        evaluation_instructions: Evaluation instructions / è©•ä¾¡æŒ‡ç¤º
        output_data: Target data model type / ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å‹
        max_turns: Maximum clarification turns / æœ€å¤§æ˜ç¢ºåŒ–ã‚¿ãƒ¼ãƒ³æ•°
        model: LLM model name / LLMãƒ¢ãƒ‡ãƒ«å
        evaluation_model: Evaluation model name / è©•ä¾¡ãƒ¢ãƒ‡ãƒ«å
        next_step: Next step after completion / å®Œäº†å¾Œã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—
        threshold: Evaluation threshold / è©•ä¾¡é–¾å€¤
        retries: Number of retries / ãƒªãƒˆãƒ©ã‚¤å›æ•°

    Returns:
        ClearifyAgent: Configured ClearifyAgent instance / è¨­å®šæ¸ˆã¿ClearifyAgentã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return ClearifyAgent(
        name=name,
        generation_instructions=generation_instructions,
        evaluation_instructions=evaluation_instructions,
        output_data=output_data,
        clerify_max_turns=max_turns,
        model=model,
        evaluation_model=evaluation_model,
        next_step=next_step,
        threshold=threshold,
        retries=retries
    )