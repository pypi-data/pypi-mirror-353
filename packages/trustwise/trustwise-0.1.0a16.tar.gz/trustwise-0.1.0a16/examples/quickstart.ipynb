{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¦‰ Trustwise SDK Demo\n",
                "\n",
                "This notebook provides a comprehensive demonstration of the Trustwise SDK's capabilities for evaluating AI-generated content. We'll cover everything from basic setup to advanced features and best practices."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation and Environment Setup\n",
                "\n",
                "First, let's set up our environment and install the necessary packages."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install the latest version of Trustwise SDK\n",
                "# !pip install trustwise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required packages\n",
                "import os\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from trustwise.sdk import TrustwiseSDK\n",
                "from trustwise.sdk.config import TrustwiseConfig\n",
                "from trustwise.sdk.exceptions import TrustwiseValidationError\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "# Verify API key is set\n",
                "api_key = os.environ.get(\"TW_API_KEY\")\n",
                "assert api_key is not None, \"TW_API_KEY is not set in environment variables\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. SDK Configuration and Initialization\n",
                "\n",
                "The Trustwise SDK offers flexible configuration options. Let's explore different ways to initialize it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Method 1: Using environment variable (recommended)\n",
                "config = TrustwiseConfig()  # Automatically uses TW_API_KEY from environment\n",
                "trustwise = TrustwiseSDK(config)\n",
                "\n",
                "# Method 2: Direct initialization with API key\n",
                "config_direct = TrustwiseConfig(api_key=os.environ[\"TW_API_KEY\"])\n",
                "trustwise_direct = TrustwiseSDK(config_direct)\n",
                "\n",
                "# Method 3: Custom configuration with specific base URL\n",
                "config_custom = TrustwiseConfig(\n",
                "    api_key=os.environ[\"TW_API_KEY\"],\n",
                "    base_url=\"https://api.trustwise.ai\"\n",
                ")\n",
                "trustwise_custom = TrustwiseSDK(config_custom)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Understanding API Versioning\n",
                "\n",
                "The SDK uses a path-based versioning system that makes it easy to work with different API versions. Let's explore this feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "V3 Result: score=99.995575 facts=[Fact(statement='The capital of France is Paris.', label='Safe', prob=0.9999557, sentence_span=[0, 30])]\n",
                        "Default Version Result: score=99.995575 facts=[Fact(statement='The capital of France is Paris.', label='Safe', prob=0.9999557, sentence_span=[0, 30])]\n"
                    ]
                }
            ],
            "source": [
                "# Example context for our evaluations\n",
                "context = [{\n",
                "    \"node_text\": \"Paris is the capital of France. It is known for the Eiffel Tower and the Louvre Museum.\",\n",
                "    \"node_score\": 0.95,\n",
                "    \"node_id\": \"doc:idx:1\"\n",
                "}]\n",
                "\n",
                "# Using explicit version path (v3) - Recommended\n",
                "result_v3 = trustwise.metrics.v3.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=context\n",
                ")\n",
                "print(\"V3 Result:\", result_v3)\n",
                "\n",
                "# Using default version (backward compatibility)\n",
                "result_default = trustwise.metrics.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=context\n",
                ")\n",
                "print(\"Default Version Result:\", result_default)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Safety Metrics\n",
                "\n",
                "Let's explore the comprehensive safety metrics available in the SDK."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Faithfulness Score: 99.995575\n",
                        "Facts: [Fact(statement='The capital of France is Paris.', label='Safe', prob=0.9999557, sentence_span=[0, 30])]\n",
                        "\n",
                        "PII Detection Results:\n",
                        "Identified PII: [PIIEntity(interval=[45, 57], string='123-456-7890', category='blocklist')]\n",
                        "\n",
                        "Answer Relevancy Score: 96.38003\n",
                        "Generated Question: What is the capital of France?\n"
                    ]
                }
            ],
            "source": [
                "# 4.1 Faithfulness Evaluation\n",
                "faithfulness = trustwise.metrics.v3.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=context\n",
                ")\n",
                "print(\"Faithfulness Score:\", faithfulness.score)\n",
                "print(\"Facts:\", faithfulness.facts)\n",
                "\n",
                "# 4.2 PII Detection\n",
                "pii_text = \"My email is john@example.com and my phone is 123-456-7890\"\n",
                "pii_result = trustwise.metrics.v3.pii.evaluate(\n",
                "    text=pii_text,\n",
                "    allowlist=[\"john@example.com\"],  # Allowed PII patterns\n",
                "    blocklist=[\"123-456-7890\"]      # Blocked PII patterns\n",
                ")\n",
                "print(\"\\nPII Detection Results:\")\n",
                "print(\"Identified PII:\", pii_result.identified_pii)\n",
                "\n",
                "# 4.3 Answer Relevancy\n",
                "relevancy = trustwise.metrics.v3.answer_relevancy.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=context\n",
                ")\n",
                "print(\"\\nAnswer Relevancy Score:\", relevancy.score)\n",
                "print(\"Generated Question:\", relevancy.generated_question)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Alignment Metrics\n",
                "\n",
                "Now let's look at the alignment metrics that help evaluate the quality and appropriateness of responses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Clarity Score: 73.84502\n",
                        "\n",
                        "Tone Analysis:\n",
                        "neutral: 89.11%\n",
                        "happiness: 6.63%\n",
                        "realization: 3.54%\n",
                        "\n",
                        "Formality Score: 89.2255\n",
                        "Sentence Scores: {'The capital of France is Paris.': 89.2255}\n"
                    ]
                }
            ],
            "source": [
                "# 5.1 Clarity Evaluation\n",
                "clarity = trustwise.metrics.v3.clarity.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\"\n",
                ")\n",
                "print(\"Clarity Score:\", clarity.score)\n",
                "\n",
                "# 5.2 Tone Analysis\n",
                "tone = trustwise.metrics.v3.tone.evaluate(\n",
                "    response=\"The capital of France is Paris.\"\n",
                ")\n",
                "print(\"\\nTone Analysis:\")\n",
                "for label, score in zip(tone.labels, tone.scores, strict=False):\n",
                "    print(f\"{label}: {score:.2f}%\")\n",
                "\n",
                "# 5.3 Formality Check\n",
                "formality = trustwise.metrics.v3.formality.evaluate(\n",
                "    response=\"The capital of France is Paris.\"\n",
                ")\n",
                "print(\"\\nFormality Score:\", formality.score)\n",
                "print(\"Sentence Scores:\", dict(zip(formality.sentences, formality.scores, strict=False)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Performance Metrics\n",
                "\n",
                "Let's explore the performance metrics for monitoring costs and environmental impact."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cost Analysis:\n",
                        "Cost per run: $0.0006\n",
                        "Total project cost: $1.1000\n",
                        "\n",
                        "Carbon Emissions:\n",
                        "Carbon emissions: 0.0066 kg CO2e\n"
                    ]
                }
            ],
            "source": [
                "# 6.1 Cost Evaluation\n",
                "cost_result = trustwise.performance.v1.cost.evaluate(\n",
                "    model_name=\"gpt-3.5-turbo\",\n",
                "    model_type=\"LLM\",\n",
                "    model_provider=\"OpenAI\",\n",
                "    number_of_queries=5,\n",
                "    total_prompt_tokens=950,\n",
                "    total_completion_tokens=50\n",
                ")\n",
                "print(\"Cost Analysis:\")\n",
                "print(f\"Cost per run: ${cost_result.cost_estimate_per_run:.4f}\")\n",
                "print(f\"Total project cost: ${cost_result.total_project_cost_estimate:.4f}\")\n",
                "\n",
                "# 6.2 Carbon Emissions\n",
                "carbon_result = trustwise.performance.v1.carbon.evaluate(\n",
                "    processor_name=\"AMD A10-9700\",\n",
                "    provider_name=\"aws\",\n",
                "    provider_region=\"us-east-1\",\n",
                "    instance_type=\"p4d.24xlarge\",\n",
                "    average_latency=100\n",
                ")\n",
                "print(\"\\nCarbon Emissions:\")\n",
                "print(f\"Carbon emissions: {carbon_result.carbon_emitted:.4f} kg CO2e\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Types, JSON and auto-complete support\n",
                "\n",
                "Trustwise SDK supports both Response types and JSON for developer's ease of use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Carbon Result: <class 'trustwise.sdk.types.CarbonResponse'> carbon_emitted=0.006640833333333334 sci_per_api_call=0.014528571522713153 sci_per_10k_calls=145.28571522713153\n",
                        "Carbon Emitted: 0.006640833333333334\n",
                        "Carbon Result JSON: {\"carbon_emitted\":0.006640833333333334,\"sci_per_api_call\":0.014528571522713153,\"sci_per_10k_calls\":145.28571522713153}\n"
                    ]
                }
            ],
            "source": [
                "print(\"Carbon Result:\", type(carbon_result), carbon_result)\n",
                "print(\"Carbon Emitted:\", carbon_result.carbon_emitted)\n",
                "print(\"Carbon Result JSON:\", carbon_result.to_json())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Guardrails (Experimental) and Validation\n",
                "\n",
                "Let's implement guardrails to automatically validate responses against multiple metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/mk/work/github/trustwise/src/trustwise/sdk/sdk.py:89: UserWarning: The guardrails feature is currently in beta. The API and functionality may change in future releases.\n",
                        "  return Guardrail(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Good Response Evaluation:\n",
                        "{\"passed\": true, \"blocked\": false, \"results\": {\"faithfulness\": {\"passed\": true, \"result\": {\"score\": 99.995575, \"facts\": [{\"statement\": \"The capital of France is Paris.\", \"label\": \"Safe\", \"prob\": 0.9999557, \"sentence_span\": [0, 30]}]}}, \"answer_relevancy\": {\"passed\": true, \"result\": {\"score\": 96.38003, \"generated_question\": \"What is the capital of France?\"}}, \"clarity\": {\"passed\": true, \"result\": {\"score\": 73.84502}}}}\n",
                        "\n",
                        "Poor Response Evaluation:\n",
                        "{\"passed\": false, \"blocked\": true, \"results\": {\"faithfulness\": {\"passed\": false, \"result\": {\"score\": 0.0, \"facts\": [{\"statement\": \"There are no relevant statements in the response\", \"label\": \"neutral\", \"prob\": 1.0, \"sentence_span\": [0, 0]}]}}}}\n"
                    ]
                }
            ],
            "source": [
                "# Create a multi-metric guardrail\n",
                "guardrail = trustwise.guardrails(\n",
                "    thresholds={\n",
                "        \"faithfulness\": 80,\n",
                "        \"answer_relevancy\": 70,\n",
                "        \"clarity\": 70\n",
                "    },\n",
                "    block_on_failure=True\n",
                ")\n",
                "\n",
                "# Test the guardrail with a good response\n",
                "good_response = \"The capital of France is Paris.\"\n",
                "good_evaluation = guardrail.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=good_response,\n",
                "    context=context\n",
                ")\n",
                "print(\"Good Response Evaluation:\")\n",
                "print(good_evaluation.to_json())\n",
                "\n",
                "# Test the guardrail with a poor response\n",
                "poor_response = \"I don't know the answer to that question.\"\n",
                "poor_evaluation = guardrail.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=poor_response,\n",
                "    context=context\n",
                ")\n",
                "print(\"\\nPoor Response Evaluation:\")\n",
                "print(poor_evaluation.to_json())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Error Handling and Best Practices\n",
                "\n",
                "Let's explore different types of errors you might encounter when using the SDK and how to handle them properly."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.1 SDK Validation Errors\n",
                "\n",
                "The SDK uses Pydantic for input validation. Let's see how it handles invalid inputs:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TrustwiseValidationError",
                    "evalue": "Error in 'FaithfulnessRequest': Invalid arguments: 'response' (invalid value: expected type: str, got: NoneType [value: None]). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/base.py:107\u001b[39m, in \u001b[36mBaseMetric.validate_request_model\u001b[39m\u001b[34m(model_cls, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py311/lib/python3.11/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
                        "\u001b[31mValidationError\u001b[39m: 1 validation error for FaithfulnessRequest\nresponse\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mTrustwiseValidationError\u001b[39m                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Try to evaluate with invalid input (missing required field)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mtrustwise\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mv3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Missing 'response' parameter\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/safety/v3/metrics/faithfulness.py:39\u001b[39m, in \u001b[36mFaithfulnessMetric.evaluate\u001b[39m\u001b[34m(self, query, response, context, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     19\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     **kwargs\n\u001b[32m     24\u001b[39m ) -> FaithfulnessResponse:\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m    Evaluate the faithfulness of a response against its context.\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m        TrustwiseValidationError: If not all of query, response, and context are provided\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     req = \u001b[43mBaseMetric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_request_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFaithfulnessRequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.client._post(\n\u001b[32m     41\u001b[39m         endpoint=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/faithfulness\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m         data=req.to_dict()\n\u001b[32m     43\u001b[39m     )\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FaithfulnessResponse(**result)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/base.py:109\u001b[39m, in \u001b[36mBaseMetric.validate_request_model\u001b[39m\u001b[34m(model_cls, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_cls(**kwargs)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TrustwiseValidationError(SDKBaseModel.format_validation_error(model_cls, ve)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mve\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m te:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Detect missing required arguments\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n",
                        "\u001b[31mTrustwiseValidationError\u001b[39m: Error in 'FaithfulnessRequest': Invalid arguments: 'response' (invalid value: expected type: str, got: NoneType [value: None]). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro"
                    ]
                }
            ],
            "source": [
                "# Try to evaluate with invalid input (missing required field)\n",
                "result = trustwise.metrics.v3.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    # Missing 'response' parameter\n",
                "    context=context\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try to evaluate with invalid input type\n",
                "try:\n",
                "    result = trustwise.metrics.v3.faithfulness.evaluate(\n",
                "        query=123,  # Invalid type: should be string\n",
                "        response=\"The capital of France is Paris.\",\n",
                "        context=context\n",
                "    )\n",
                "    raise ValueError(\"Should not reach this point\")\n",
                "except TrustwiseValidationError as e:\n",
                "    # print(e)\n",
                "    assert isinstance(e, TrustwiseValidationError)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.2 Backend API Errors\n",
                "\n",
                "When the backend API returns a non-200 response, the SDK will raise a `TrustwiseError` with the backend's error message. Let's see some examples:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TrustwiseAPIError",
                    "evalue": "Error code: 401 - {'message': 'Authorization error. API key is invalid'}",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mTrustwiseAPIError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m invalid_config = TrustwiseConfig(api_key=\u001b[33m\"\u001b[39m\u001b[33minvalid_key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m invalid_sdk = TrustwiseSDK(invalid_config)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result = \u001b[43minvalid_sdk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mv3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe capital of France is Paris.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/safety/v3/metrics/faithfulness.py:40\u001b[39m, in \u001b[36mFaithfulnessMetric.evaluate\u001b[39m\u001b[34m(self, query, response, context, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03mEvaluate the faithfulness of a response against its context.\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    TrustwiseValidationError: If not all of query, response, and context are provided\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m req = BaseMetric.validate_request_model(FaithfulnessRequest, query=query, response=response, context=context, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/faithfulness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FaithfulnessResponse(**result)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/client.py:69\u001b[39m, in \u001b[36mTrustwiseClient._post\u001b[39m\u001b[34m(self, endpoint, data)\u001b[39m\n\u001b[32m     67\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mResponse headers: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mdict\u001b[39m(response.headers))\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m make_status_error_from_response(response)\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "\u001b[31mTrustwiseAPIError\u001b[39m: Error code: 401 - {'message': 'Authorization error. API key is invalid'}"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Import required packages\n",
                "import os\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from trustwise.sdk import TrustwiseSDK\n",
                "from trustwise.sdk.config import TrustwiseConfig\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "config = TrustwiseConfig()  # Automatically uses TW_API_KEY from environment\n",
                "trustwise = TrustwiseSDK(config)\n",
                "\n",
                "# Try to evaluate with invalid API key\n",
                "invalid_config = TrustwiseConfig(api_key=\"invalid_key\")\n",
                "invalid_sdk = TrustwiseSDK(invalid_config)\n",
                "result = invalid_sdk.metrics.v3.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=[]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TrustwiseValidationError",
                    "evalue": "Error in 'FaithfulnessRequest': Invalid or missing arguments: 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (invalid value: expected type: list[ContextNode], got: str [value: 'This is not a valid context format']). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/base.py:107\u001b[39m, in \u001b[36mBaseMetric.validate_request_model\u001b[39m\u001b[34m(model_cls, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py311/lib/python3.11/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
                        "\u001b[31mValidationError\u001b[39m: 4 validation errors for FaithfulnessRequest\ncontext.0.node_id\n  Field required [type=missing, input_value={'invalid_field': 'This i...a valid context format'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ncontext.0.node_score\n  Field required [type=missing, input_value={'invalid_field': 'This i...a valid context format'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ncontext.0.node_text\n  Field required [type=missing, input_value={'invalid_field': 'This i...a valid context format'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ncontext.0.invalid_field\n  Extra inputs are not permitted [type=extra_forbidden, input_value='This is not a valid context format', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mTrustwiseValidationError\u001b[39m                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Try to evaluate with invalid context format\u001b[39;00m\n\u001b[32m      2\u001b[39m invalid_context = [{\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minvalid_field\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mThis is not a valid context format\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m }]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mtrustwise\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mv3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital of France?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe capital of France is Paris.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43minvalid_context\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/safety/v3/metrics/faithfulness.py:39\u001b[39m, in \u001b[36mFaithfulnessMetric.evaluate\u001b[39m\u001b[34m(self, query, response, context, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     19\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     **kwargs\n\u001b[32m     24\u001b[39m ) -> FaithfulnessResponse:\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m    Evaluate the faithfulness of a response against its context.\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m        TrustwiseValidationError: If not all of query, response, and context are provided\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     req = \u001b[43mBaseMetric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_request_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFaithfulnessRequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.client._post(\n\u001b[32m     41\u001b[39m         endpoint=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/faithfulness\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m         data=req.to_dict()\n\u001b[32m     43\u001b[39m     )\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FaithfulnessResponse(**result)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/trustwise/src/trustwise/sdk/metrics/base.py:109\u001b[39m, in \u001b[36mBaseMetric.validate_request_model\u001b[39m\u001b[34m(model_cls, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_cls(**kwargs)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TrustwiseValidationError(SDKBaseModel.format_validation_error(model_cls, ve)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mve\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m te:\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Detect missing required arguments\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n",
                        "\u001b[31mTrustwiseValidationError\u001b[39m: Error in 'FaithfulnessRequest': Invalid or missing arguments: 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (invalid value: expected type: list[ContextNode], got: str [value: 'This is not a valid context format']). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro"
                    ]
                }
            ],
            "source": [
                "# Try to evaluate with invalid context format\n",
                "invalid_context = [{\n",
                "    \"invalid_field\": \"This is not a valid context format\"\n",
                "}]\n",
                "result = trustwise.metrics.v3.faithfulness.evaluate(\n",
                "    query=\"What is the capital of France?\",\n",
                "    response=\"The capital of France is Paris.\",\n",
                "    context=invalid_context\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.3 Comprehensive Error Handling\n",
                "\n",
                "Here's a practical example of how to handle both SDK validation errors and backend API errors in a production environment:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Testing: Valid input\n",
                        "Result: {'success': True, 'score': 99.995575, 'details': '{\"score\":99.995575,\"facts\":[{\"statement\":\"The capital of France is Paris.\",\"label\":\"Safe\",\"prob\":0.9999557,\"sentence_span\":[0,30]}]}'}\n",
                        "\n",
                        "Testing: Invalid query type\n",
                        "Trustwise Validation Error: Error in 'FaithfulnessRequest': Invalid arguments: 'query' (invalid value: expected type: str, got: int [value: 123]). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro\n",
                        "Result: {'success': False, 'error_type': 'trustwise_validation_error', 'error_message': \"Error in 'FaithfulnessRequest': Invalid arguments: 'query' (invalid value: expected type: str, got: int [value: 123]). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro\"}\n",
                        "\n",
                        "Testing: Invalid context format\n",
                        "Trustwise Validation Error: Error in 'FaithfulnessRequest': Invalid or missing arguments: 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (invalid value: expected type: list[ContextNode], got: str [value: 'format']). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro\n",
                        "Result: {'success': False, 'error_type': 'trustwise_validation_error', 'error_message': \"Error in 'FaithfulnessRequest': Invalid or missing arguments: 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (missing required argument, expected type: list[ContextNode]), 'context' (invalid value: expected type: list[ContextNode], got: str [value: 'format']). Refer to the documentation: https://trustwiseai.github.io/tw-docs/docs/intro\"}\n"
                    ]
                }
            ],
            "source": [
                "from typing import Any\n",
                "\n",
                "from trustwise.sdk.exceptions import TrustwiseValidationError\n",
                "\n",
                "\n",
                "def safe_evaluate_with_error_handling(\n",
                "    query: str,\n",
                "    response: str,\n",
                "    context: list,\n",
                "    metric: str = \"faithfulness\"\n",
                ") -> dict[str, Any] | None:\n",
                "    \"\"\"\n",
                "    Safely evaluate a response with comprehensive error handling.\n",
                "    \n",
                "    Args:\n",
                "        query: The user's query\n",
                "        response: The AI's response\n",
                "        context: The context used for evaluation\n",
                "        metric: The metric to evaluate (default: faithfulness)\n",
                "        \n",
                "    Returns:\n",
                "        Optional[Dict[str, Any]]: Evaluation results or error details\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Get the appropriate evaluator based on the metric\n",
                "        evaluator = getattr(trustwise.metrics.v3, metric)\n",
                "        \n",
                "        # Perform the evaluation\n",
                "        result = evaluator.evaluate(\n",
                "            query=query,\n",
                "            response=response,\n",
                "            context=context\n",
                "        )\n",
                "        \n",
                "        return {\n",
                "            \"success\": True,\n",
                "            \"score\": result.score,\n",
                "            \"details\": result.to_json()\n",
                "        }\n",
                "        \n",
                "    except TrustwiseValidationError as e:\n",
                "        print(f\"Trustwise Validation Error: {e!s}\")\n",
                "        return {\n",
                "            \"success\": False,\n",
                "            \"error_type\": \"trustwise_validation_error\",\n",
                "            \"error_message\": str(e)\n",
                "        }\n",
                "    except Exception as e:\n",
                "        print(f\"Unexpected Error: {e!s}\")\n",
                "        return {\n",
                "            \"success\": False,\n",
                "            \"error_type\": \"unexpected_error\",\n",
                "            \"error_message\": str(e)\n",
                "        }\n",
                "\n",
                "# Test the error handling with various scenarios\n",
                "test_cases = [\n",
                "    # Valid case\n",
                "    {\n",
                "        \"query\": \"What is the capital of France?\",\n",
                "        \"response\": \"The capital of France is Paris.\",\n",
                "        \"context\": context,\n",
                "        \"description\": \"Valid input\"\n",
                "    },\n",
                "    # Invalid query type\n",
                "    {\n",
                "        \"query\": 123,  # Invalid type\n",
                "        \"response\": \"The capital of France is Paris.\",\n",
                "        \"context\": context,\n",
                "        \"description\": \"Invalid query type\"\n",
                "    },\n",
                "    # Invalid context format\n",
                "    {\n",
                "        \"query\": \"What is the capital of France?\",\n",
                "        \"response\": \"The capital of France is Paris.\",\n",
                "        \"context\": [{\"invalid\": \"format\"}],\n",
                "        \"description\": \"Invalid context format\"\n",
                "    }\n",
                "]\n",
                "\n",
                "for case in test_cases:\n",
                "    print(f\"\\nTesting: {case['description']}\")\n",
                "    result = safe_evaluate_with_error_handling(\n",
                "        query=case[\"query\"],\n",
                "        response=case[\"response\"],\n",
                "        context=case[\"context\"]\n",
                "    )\n",
                "    print(\"Result:\", result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Features\n",
                "\n",
                "This notebook has demonstrated the key features and capabilities of the Trustwise SDK:\n",
                "\n",
                "1. Flexible configuration and initialization\n",
                "2. Path-based API versioning\n",
                "3. Full test coverage for SDK + Installation\n",
                "4. Automated documentation support\n",
                "5. Guardrails (Experimental) and validation\n",
                "6. Structured Error handling\n",
                "7. Extensibility of .explain() / .batch_evaluate() features for future"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "py311",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}