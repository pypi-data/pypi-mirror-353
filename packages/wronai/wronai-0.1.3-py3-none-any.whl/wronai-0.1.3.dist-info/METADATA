Metadata-Version: 2.3
Name: wronai
Version: 0.1.3
Summary: End-to-end LLM model building, fine-tuning, and deployment toolkit
License: Apache-2.0
Keywords: llm,ai,machine-learning,huggingface,ollama,fine-tuning
Author: WronAI Team
Author-email: info@softreck.dev
Requires-Python: >=3.8,<4.0
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Dist: accelerate (>=0.25.0,<0.26.0)
Requires-Dist: bitsandbytes (>=0.41.0,<0.42.0)
Requires-Dist: click (>=8.1.7,<9.0.0)
Requires-Dist: huggingface-hub (>=0.19.4,<0.20.0)
Requires-Dist: jinja2 (>=3.1.2,<4.0.0)
Requires-Dist: loguru (>=0.7.2,<0.8.0)
Requires-Dist: peft (>=0.7.0,<0.8.0)
Requires-Dist: pydantic (>=2.4.2,<3.0.0)
Requires-Dist: python-dotenv (>=1.0.0,<2.0.0)
Requires-Dist: pyyaml (>=6.0.1,<7.0.0)
Requires-Dist: requests (>=2.31.0,<3.0.0)
Requires-Dist: rich (>=13.7.0,<14.0.0)
Requires-Dist: torch (>=2.0.0,<3.0.0)
Requires-Dist: transformers (>=4.35.0,<5.0.0)
Project-URL: Bug Tracker, https://github.com/wronai/llm-demo/issues
Project-URL: Documentation, https://github.com/wronai/llm-demo#readme
Project-URL: Homepage, https://github.com/wronai/llm-demo
Project-URL: Repository, https://github.com/wronai/llm-demo
Project-URL: Source Code, https://github.com/wronai/llm-demo
Description-Content-Type: text/markdown

---
license: apache-2.0
base_model:
- mistralai/Mistral-7B-Instruct-v0.3
pipeline_tag: translation
tags:
- llm
- devops
- development
- polish
- english
- python
- iac
---

# üöÄ WronAI - End-to-End LLM Toolkit

[![PyPI Version](https://img.shields.io/pypi/v/wronai.svg)](https://pypi.org/project/wronai/)
[![Python Version](https://img.shields.io/pypi/pyversions/wronai.svg)](https://python.org)
[![License](https://img.shields.io/pypi/l/wronai.svg)](https://github.com/wronai/llm-demo/blob/main/LICENSE)
[![Tests](https://github.com/wronai/llm-demo/actions/workflows/tests.yml/badge.svg)](https://github.com/wronai/llm-demo/actions)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Documentation](https://img.shields.io/badge/docs-readthedocs-blue.svg)](https://wronai.readthedocs.io/)
[![Docker Pulls](https://img.shields.io/docker/pulls/wronai/wronai)](https://hub.docker.com/r/wronai/wronai)

> A comprehensive toolkit for creating, fine-tuning, and deploying large language models with support for both Polish and English.

## üåü Features

- **Ready-to-use WronAI package** - All functionality available through the `wronai` package
- **Model Management** - Easy installation and management of LLM models
- **Multiple Model Support** - Works with various models via Ollama
- **Optimizations** - 4-bit quantization, LoRA, FP16 support
- **CLI Tools** - Command-line interface for all operations
- **Production Ready** - Easy deployment with Docker
- **Web Interface** - User-friendly Streamlit-based web UI

## üöÄ Quick Start

### Prerequisites
- Python 3.8+
- [Ollama](https://ollama.ai/) installed and running
- CUDA (optional, for GPU acceleration)

### Installation

```bash
# Install the package
pip install wronai

# Start Ollama (if not already running)
ollama serve &

# Pull the required model (e.g., mistral:7b-instruct)
ollama pull mistral:7b-instruct
```

### Basic Usage

#### Using Python Package

```python
from wronai import WronAI

# Initialize with default settings
wron = WronAI()

# Chat with the model
response = wron.chat("Explain quantum computing in simple terms")
print(response)
```

#### Command Line Interface

```bash
# Start interactive chat
wronai chat

# Run a single query
wronai query "Explain quantum computing in simple terms"
```

#### Web Interface

```bash
# Start the web UI
wronai web
```

## üîß Model Management

List available models:
```bash
ollama list
```

Pull a model (if not already available):
```bash
ollama pull mistral:7b-instruct
```

## üê≥ Docker Support

Run with Docker:
```bash
docker run -p 8501:8501 wronai/wronai web
```

## üõ†Ô∏è Development

### Installation from Source

```bash
# Clone the repository
git clone https://github.com/wronai/llm-demo.git
cd llm-demo

# Install in development mode
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=wronai --cov-report=term-missing
```

## ü§ù Contributing

Contributions are welcome! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## üìú License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

## üìß Contact

For questions or support, please open an issue on GitHub or contact us at [email protected]

