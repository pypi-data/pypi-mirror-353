framework:
  name: simple_evals
  pkg_name: simple_evals
  full_name: simple-evals
  description: simple-evals This repository contains a lightweight library for evaluating language models.
  url: https://github.com/openai/simple-evals
  source: https://gitlab-master.nvidia.com/dl/JoC/competitive_evaluation/simple-evals
defaults:
  command: >-
    {% if target.api_endpoint.api_key is not none %}export API_KEY=${{target.api_endpoint.api_key}} && {% endif %}
    simple_evals --model {{target.api_endpoint.model_id}} --eval_name {{config.params.task}}
    --url {{target.api_endpoint.url}} --temperature {{config.params.temperature}} --top_p {{config.params.top_p}}
    --max_tokens {{config.params.max_new_tokens}} --out_dir {{config.output_dir}} --cache_dir {{config.output_dir}}/cache
    --num_threads {{config.params.parallelism}} --max_retries {{config.params.max_retries}} --timeout {{config.params.request_timeout}}
    {% if config.params.extra.n_samples is defined %} --num_repeats {{config.params.extra.n_samples}}{% endif %}
    {% if config.params.limit_samples is not none %} --first_n {{config.params.limit_samples}}{% endif %}
    {% if config.params.extra.add_system_prompt  %} --add_system_prompt {% endif %}
    {% if config.params.extra.downsampling_ratio is not none %} --downsampling_ratio {{config.params.extra.downsampling_ratio}}{% endif %}
    {% if config.params.extra.args is defined %} {{ config.params.extra.args }} {% endif %}
    {% if config.params.extra.judge.url is not none %} --judge_url {{config.params.extra.judge.url}}{% endif %}
    {% if config.params.extra.judge.model_id is not none %} --judge_model_id {{config.params.extra.judge.model_id}}{% endif %}
    {% if config.params.extra.judge.api_key is not none %} --judge_api_key_name {{config.params.extra.judge.api_key}}{% endif %}
    {% if config.params.extra.judge.backend is not none %} --judge_backend {{config.params.extra.judge.backend}}{% endif %}
    {% if config.params.extra.judge.request_timeout is not none %} --judge_request_timeout {{config.params.extra.judge.request_timeout}}{% endif %}
    {% if config.params.extra.judge.max_retries is not none %} --judge_max_retries {{config.params.extra.judge.max_retries}}{% endif %}
    {% if config.params.extra.judge.temperature is not none %} --judge_temperature {{config.params.extra.judge.temperature}}{% endif %}
    {% if config.params.extra.judge.top_p is not none %} --judge_top_p {{config.params.extra.judge.top_p}}{% endif %}
    {% if config.params.extra.judge.max_tokens is not none %} --judge_max_tokens {{config.params.extra.judge.max_tokens}}{% endif %}
  config:
    params:
      limit_samples: null
      max_new_tokens: 4096
      temperature: 0
      top_p: 0.00001
      parallelism: 10
      max_retries: 5
      request_timeout: 60
      extra:
        downsampling_ratio: null
        add_system_prompt: false
        judge:
          url: null
          model_id: null
          api_key: null
          backend: "openai"  # "openai" for OpenAI compatible judges; "generic" for direct calls via aiohttp
          request_timeout: 600
          max_retries: 16
          temperature: 0.0
          top_p: 0.0001
          max_tokens: 1024
  target:
    api_endpoint: {} # required to add: url, model_id, api_key
evaluations:
- name: AIME_2025
  description: AIME 2025 questions, math
  defaults:
    config:
      type: AIME_2025
      supported_endpoint_types:
      - chat
      params:
        task: AIME_2025
        extra:
          judge:
            api_key: JUDGE_API_KEY
- name: AIME_2024
  description: AIME 2024 questions, math
  defaults:
    config:
      type: AIME_2024
      supported_endpoint_types:
      - chat
      params:
        task: AIME_2024  
- name: AA_AIME_2024
  description: AA AIME 2024 questions, math
  defaults:
    config:
      type: AA_AIME_2024
      supported_endpoint_types:
      - chat
      params:
        task: AA_AIME_2024
        extra:
          judge:
            api_key: JUDGE_API_KEY
- name: AA_math_test_500
  description: AA Open Ai math test 500
  defaults:
    config:
      type: AA_math_test_500
      supported_endpoint_types:
      - chat
      params:
        task: AA_math_test_500
        extra:
          judge:
            api_key: JUDGE_API_KEY
- name: math_test_500
  description: Open Ai math test 500
  defaults:
    config:
      type: math_test_500
      supported_endpoint_types:
      - chat
      params:
        task: math_test_500
- name: mgsm
  description: MGSM is a benchmark of grade-school math problems. The same 250 problems from GSM8K are each translated via human annotators in 10 languages.
  defaults:
    config:
      type: mgsm
      supported_endpoint_types:
      - chat
      params:
        task: mgsm
- name: humaneval
  description:  HumanEval evaluates the performance in Python code generation tasks. It used to measure functional correctness for synthesizing programs from docstrings. It consists of 164 original programming problems, assessing language comprehension, algorithms, and simple mathematics, with some comparable to simple software interview questions.
  defaults:
    config:
      type: humaneval
      supported_endpoint_types:
      - chat
      params:
        task: humaneval
        n_repeats: 1
- name: humanevalplus
  description: HumanEvalPlus is a dataset of 164 programming problems, assessing language comprehension, algorithms, and simple mathematics, with some comparable to simple software interview questions.
  defaults:
    config:
      type: humanevalplus
      supported_endpoint_types:
      - chat
      params:
        task: humanevalplus
        n_repeats: 1
- name: mmlu_pro
  description: MMLU-Pro dataset is a more robust and challenging massive multi-task understanding dataset tailored to more rigorously benchmark large language models' capabilities. This dataset contains 12K complex questions across various disciplines.
  defaults:
    config:
      type: mmlu_pro
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_pro
- name: mmlu
  description: mmlu 0-shot CoT.
  defaults:
    config:
      type: mmlu
      supported_endpoint_types:
      - chat
      params:
        task: mmlu
- name: mmlu_EN-US
  description: mmlu_EN-US 0-shot CoT
  defaults:
    config:
      type: mmlu_EN-US
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_EN-US
- name: mmlu_AR-XY
  description: mmlu_AR-XY 0-shot CoT
  defaults:
    config:
      type: mmlu_AR-XY
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_AR-XY
- name: mmlu_BN-BD
  description: mmlu_BN-BD 0-shot CoT
  defaults:
    config:
      type: mmlu_BN-BD
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_BN-BD
- name: mmlu_DE-DE
  description: mmlu_DE-DE 0-shot CoT
  defaults:
    config:
      type: mmlu_DE-DE
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_DE-DE
- name: mmlu_ES-LA
  description: mmlu_ES-LA 0-shot CoT
  defaults:
    config:
      type: mmlu_ES-LA
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_ES-LA
- name: mmlu_FR-FR
  description: mmlu_FR-FR 0-shot CoT
  defaults:
    config:
      type: mmlu_FR-FR
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_FR-FR
- name: mmlu_HI-IN
  description: mmlu_HI-IN 0-shot CoT
  defaults:
    config:
      type: mmlu_HI-IN
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_HI-IN
- name: mmlu_ID-ID
  description: mmlu_ID-ID 0-shot CoT
  defaults:
    config:
      type: mmlu_ID-ID
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_ID-ID
- name: mmlu_IT-IT
  description: mmlu_IT-IT 0-shot CoT
  defaults:
    config:
      type: mmlu_IT-IT
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_IT-IT
- name: mmlu_JA-JP
  description: mmlu_JA-JP 0-shot CoT
  defaults:
    config:
      type: mmlu_JA-JP
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_JA-JP
- name: mmlu_KO-KR
  description: mmlu_KO-KR 0-shot CoT
  defaults:
    config:
      type: mmlu_KO-KR
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_KO-KR
- name: mmlu_PT-BR
  description: mmlu_PT-BR 0-shot CoT
  defaults:
    config:
      type: mmlu_PT-BR
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_PT-BR
- name: mmlu_ZH-CN
  description: mmlu_ZH-CN 0-shot CoT
  defaults:
    config:
      type: mmlu_ZH-CN
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_ZH-CN
- name: mmlu_SW-KE
  description: mmlu_SW-KE 0-shot CoT
  defaults:
    config:
      type: mmlu_SW-KE
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_SW-KE
- name: mmlu_YO-NG
  description: mmlu_YO-NG 0-shot CoT
  defaults:
    config:
      type: mmlu_YO-NG
      supported_endpoint_types:
      - chat
      params:
        task: mmlu_YO-NG
- name: gpqa_diamond
  description: gpqa_diamond 0-shot CoT
  defaults:
    config:
      type: gpqa_diamond
      supported_endpoint_types:
      - chat
      params:
        task: gpqa_diamond
- name: gpqa_experts
  description: gpqa_experts 0-shot CoT
  defaults:
    config:
      type: gpqa_experts
      supported_endpoint_types:
      - chat
      params:
        task: gpqa_experts
- name: gpqa_extended
  description: gpqa_extended 0-shot CoT
  defaults:
    config:
      type: gpqa_extended
      supported_endpoint_types:
      - chat
      params:
        task: gpqa_extended
- name: gpqa_main
  description: gpqa_main 0-shot CoT
  defaults:
    config:
      type: gpqa_main
      supported_endpoint_types:
      - chat
      params:
        task: gpqa_main
- name: simpleqa
  description: A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.
  defaults:
    config:
      type: simpleqa
      supported_endpoint_types:
      - chat
      params:
        task: simpleqa


# NeMo alignment tasks
- name: aime_2025_nemo
  description: AIME 2025 questions, math, using NeMo's alignment template
  defaults:
    config:
      type: aime_2025_nemo
      supported_endpoint_types:
      - chat
      params:
        task: aime_2025_nemo
- name: aime_2024_nemo
  description: AIME 2024 questions, math, using NeMo's alignment template
  defaults:
    config:
      type: aime_2024_nemo
      supported_endpoint_types:
      - chat
      params:
        task: aime_2024_nemo
- name: math_test_500_nemo
  description: math_test_500 questions, math, using NeMo's alignment template
  defaults:
    config:
      type: math_test_500_nemo
      supported_endpoint_types:
      - chat
      params:
        task: math_test_500_nemo
- name: gpqa_diamond_nemo
  description: gpqa_diamond questions, reasoning, using NeMo's alignment template
  defaults:
    config:
      type: gpqa_diamond_nemo
      supported_endpoint_types:
      - chat
      params:
        task: gpqa_diamond_nemo